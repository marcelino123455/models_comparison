{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3dda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH =\"../../data\"\n",
    "\n",
    "path_lb_embb = os.path.join(DATA_PATH, \"lb_npy.npy\")\n",
    "path_dataset = os.path.join(DATA_PATH, \"spotify_dataset_sin_duplicados_4.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d4920",
   "metadata": {},
   "source": [
    "## Revisando que sean embbedings iguales en khipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b21a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 8.5982e-02, -1.9938e-01,  3.1403e-01, -2.1909e-01, -3.9347e-04,\n",
      "          2.8418e-01,  1.1639e+00, -2.5347e-01, -5.9031e-01,  2.8978e-01,\n",
      "         -4.3361e-01,  2.6265e-01,  1.2186e-02, -2.1822e-01,  1.0540e-01,\n",
      "          1.8403e-01,  5.8598e-01, -1.6739e-01, -2.6611e-01,  3.8995e-01,\n",
      "         -1.9267e-01,  3.5165e-01,  5.3251e-01,  4.8379e-01,  5.9596e-01,\n",
      "         -1.0685e+00,  3.0516e-01, -4.1388e-01,  3.8347e-01, -3.3050e-01,\n",
      "         -3.3174e-01,  4.0777e-01,  1.8344e-01, -2.9582e-01, -1.4029e-01,\n",
      "         -4.2408e-01,  2.6159e-01, -2.7347e-01, -7.7970e-02, -3.2933e-01,\n",
      "          3.9029e-01,  8.3547e-02,  1.7815e-01, -4.2287e-01,  2.5291e-02,\n",
      "          5.4537e-01, -3.9749e-01,  1.0715e-01, -1.1429e+00,  4.7099e-01,\n",
      "          2.0548e-01,  1.8556e-01, -3.1428e-01,  6.5785e-01,  2.4795e-01,\n",
      "          5.3135e-01, -1.9034e-01,  3.3224e-01,  4.9253e-01, -1.7496e-02,\n",
      "          4.9282e-01,  5.9564e-01,  2.2089e-01,  1.9639e-01, -1.7313e-01,\n",
      "         -2.4567e-01, -2.8542e-01, -1.4741e-01, -1.7384e-02,  3.5515e-01,\n",
      "         -8.3135e-02, -6.3132e-02,  2.9226e-01,  6.3939e-01, -2.9777e-01,\n",
      "         -9.7521e-02, -6.0739e-02,  2.5673e-01, -3.0768e-01, -2.2224e-01,\n",
      "         -2.5321e-01,  3.4734e-01,  1.0203e+00,  1.9196e-01, -9.1606e-02,\n",
      "         -4.5693e-01,  3.3026e-01, -2.2074e-01, -6.0526e-02,  3.9479e-01,\n",
      "         -2.7525e-01,  6.0574e-01, -9.6178e-03, -2.3490e-01,  3.3226e-01,\n",
      "         -2.9552e-01, -1.8357e-01,  3.3977e-01, -3.9793e-01,  2.8528e-01,\n",
      "         -9.7769e-02,  1.8406e-01,  2.3932e-01, -2.5663e-01,  1.2102e-01,\n",
      "         -1.1334e-01, -4.7447e-01,  5.8402e-01, -5.0222e-01,  5.5676e-02,\n",
      "         -2.3052e-01, -1.7998e-01, -2.4742e-01,  4.9252e-01, -3.1728e-01,\n",
      "         -3.8005e-01, -3.6834e-02,  6.1935e-01,  4.5879e-01, -1.1285e-02,\n",
      "         -8.1743e-01, -1.5657e-01, -2.2445e-01,  2.6995e-02,  6.0124e-01,\n",
      "          4.5618e-01,  5.0829e-01, -4.4134e-02, -6.2951e-01,  5.7058e-02,\n",
      "         -3.2004e-01,  8.4487e-01, -4.1202e-01, -9.3632e-02, -3.3231e-01,\n",
      "          8.0646e-02, -9.0269e-02, -7.9957e-02,  1.5627e-01, -2.4454e-01,\n",
      "         -7.8198e-02, -7.3007e-01,  3.4790e-01, -7.0381e-02,  2.4043e-01,\n",
      "         -3.9198e-01, -3.3993e-01, -2.2476e-01,  1.6756e-01,  6.1990e-01,\n",
      "          1.6506e-01, -1.7112e-02, -2.6266e-01, -4.4491e-01,  8.5385e-02,\n",
      "         -1.0234e+00,  1.4751e-02,  6.6274e-01,  7.9915e-02, -3.5930e-01,\n",
      "          1.5881e-01, -3.4966e-01, -2.2996e-03, -4.9989e-01, -2.3276e-01,\n",
      "          2.5108e-01, -1.6013e-01,  3.0339e-02,  1.2239e-01,  2.2526e-01,\n",
      "         -5.7139e-01,  1.5721e-01,  4.0606e-01,  5.2835e-01,  4.1934e-01,\n",
      "         -9.2094e-02, -1.8845e-01,  4.0464e-01, -3.8726e-01,  2.7759e-02,\n",
      "          3.4773e-01, -7.7780e-02,  3.8785e-01,  8.1375e-02,  1.4306e-01,\n",
      "          3.7101e-01, -3.4955e-01,  9.9817e-02, -4.5038e-02,  4.2395e-02,\n",
      "         -5.4337e-01, -5.7880e-03,  3.9858e-02, -2.4195e-01, -1.8601e-01,\n",
      "         -6.1422e-02, -2.0549e-01,  9.6923e-01, -4.1731e-01,  2.2264e-01,\n",
      "          9.8880e-02, -5.0703e-01,  4.4393e-02, -8.6652e-01,  2.2599e-01,\n",
      "          1.9653e-01, -7.9508e-02,  1.0202e-01, -3.3823e-01, -6.1861e-01,\n",
      "          2.5656e-01, -6.1935e-01,  1.5115e-01,  7.1349e-02, -1.6747e-02,\n",
      "          2.9823e-01, -4.8073e-01,  3.7778e-01, -1.0376e+00, -6.7299e-01,\n",
      "         -1.9395e-01, -4.9116e-01, -1.5958e-01, -1.7036e-01, -3.5001e-03,\n",
      "         -1.2437e-01, -2.7077e-01,  9.6722e-02,  1.9883e-01,  1.9982e-01,\n",
      "         -2.2514e-01,  1.4580e-01,  7.6273e-02,  2.7559e-01, -3.4379e-01,\n",
      "          3.3641e-01, -3.7492e-01,  6.8472e-02,  7.1614e-01, -8.7140e-01,\n",
      "         -1.3807e-01,  3.7063e-01, -7.8194e-02,  3.6888e-01, -2.4814e-01,\n",
      "          2.4197e-01,  2.3086e-01,  6.3857e-01,  2.2130e-02, -4.1341e-01,\n",
      "         -2.2392e-01, -4.3592e-01,  7.5251e-02, -2.5254e-01, -2.5270e-01,\n",
      "          5.2911e-01, -4.9042e-01,  9.3977e-02,  7.0798e-01,  1.1315e-01,\n",
      "         -1.2777e-01, -5.3069e-01,  2.5840e-01, -5.4220e-01,  3.6502e-01,\n",
      "         -1.7641e-01, -5.5217e-01, -3.2474e-01,  2.6816e-01,  6.9207e-02,\n",
      "         -1.3044e-01, -1.6432e-01, -7.7984e-02, -4.3597e-01,  5.2860e-01,\n",
      "         -4.4020e-01,  6.3608e-01, -1.8013e-01,  1.0452e-01,  9.2711e-02,\n",
      "          2.8882e-01, -3.7297e-01,  1.1613e-01,  1.4239e-01,  1.2496e-01,\n",
      "          4.6682e-01, -2.6213e-01, -1.8380e-01,  3.8388e-02,  2.7842e-01,\n",
      "          3.8825e-01,  9.9131e-02,  3.6541e-01,  2.2169e-01, -6.4273e-02,\n",
      "         -1.4846e-01, -3.8930e-01,  4.1290e-02, -1.4719e-01,  1.7134e-01],\n",
      "        [-1.8556e-01, -2.3414e-01,  6.9767e-01, -5.9317e-01,  4.1742e-02,\n",
      "          6.4290e-01,  7.2030e-01, -2.7653e-02, -2.8739e-01,  1.5241e-01,\n",
      "         -4.2843e-01,  9.2531e-02,  4.7558e-02, -3.9465e-01,  5.5514e-02,\n",
      "         -5.1168e-02,  4.3439e-01,  2.2112e-01,  3.6437e-02,  8.2028e-03,\n",
      "         -2.4122e-01,  8.6939e-02, -1.5564e-01,  5.8968e-01,  8.5847e-02,\n",
      "         -7.4826e-01, -1.6808e-01, -5.1483e-01,  2.0089e-01, -8.9687e-01,\n",
      "         -8.7315e-02, -3.0170e-02,  4.4630e-01, -9.3042e-02,  1.7543e-01,\n",
      "          6.9105e-02, -2.1615e-01,  2.7740e-01, -2.8637e-01, -5.3099e-01,\n",
      "         -3.4070e-01,  2.9618e-02,  1.1835e-02, -4.3073e-01, -3.9812e-01,\n",
      "          2.5667e-01,  5.8097e-02,  6.5925e-02, -5.1549e-01,  3.6404e-01,\n",
      "         -5.0626e-02,  5.8025e-01, -2.9077e-02,  1.2362e-01,  3.2774e-01,\n",
      "          4.7578e-01, -2.3779e-01,  1.0257e-01,  3.0880e-01, -7.6611e-02,\n",
      "          6.5769e-02,  3.0900e-01,  6.0790e-01,  2.2069e-01,  1.1033e-01,\n",
      "         -3.1599e-01, -1.4517e-01, -1.7289e-01, -5.1651e-01, -2.2595e-01,\n",
      "          3.5468e-01, -3.5386e-01,  2.2534e-01,  3.2495e-01, -4.6008e-01,\n",
      "         -1.3179e-01, -4.1913e-01,  3.8582e-01, -3.3780e-01,  4.6620e-02,\n",
      "         -2.2575e-01, -3.1442e-02,  8.1278e-01,  3.8404e-01,  3.6150e-01,\n",
      "         -1.9062e-01,  8.8800e-02, -1.4353e-01,  2.9068e-01, -2.3676e-03,\n",
      "         -2.8496e-01,  3.9493e-01,  1.0401e-01,  2.2580e-01,  1.0948e-02,\n",
      "         -2.6930e-01, -2.8779e-01,  1.9514e-02, -2.8700e-01, -4.0525e-01,\n",
      "          2.3328e-02,  9.6536e-02, -2.7494e-01,  1.4102e-01,  6.4354e-03,\n",
      "         -2.3677e-02, -4.6965e-01,  4.8585e-01, -1.6564e-01, -8.3012e-02,\n",
      "         -4.7720e-01, -1.9912e-01, -5.9300e-01,  1.9116e-01,  8.5618e-03,\n",
      "          9.5205e-02, -2.0540e-01,  2.7894e-01,  1.4698e-01, -9.5836e-02,\n",
      "         -4.2669e-01, -2.4652e-01, -5.3677e-02, -3.1679e-01,  5.4954e-01,\n",
      "          4.1546e-01,  1.4417e-01, -2.5318e-01, -1.1009e-01, -6.7664e-02,\n",
      "          4.5918e-02,  4.1470e-01, -1.2796e-01,  1.5244e-01, -1.6676e-01,\n",
      "         -9.3694e-02,  2.7664e-01, -5.0372e-02,  2.8108e-01, -1.3317e-02,\n",
      "          4.6536e-02, -9.3524e-01,  7.5057e-01, -9.7263e-02,  1.2152e-01,\n",
      "         -1.9416e-01,  3.8080e-02, -2.7422e-01,  4.6427e-01,  7.7246e-01,\n",
      "          1.7658e-01,  2.1876e-01, -3.8301e-02, -1.0317e+00,  1.7213e-01,\n",
      "         -3.1510e-01, -2.4518e-02,  9.2497e-01,  7.5101e-02, -3.5740e-02,\n",
      "          1.4949e-01, -1.5926e-01,  5.6959e-02, -3.8221e-01, -3.0832e-01,\n",
      "          1.2010e-01,  8.1529e-02, -4.9017e-01,  1.6145e-01, -4.7504e-02,\n",
      "         -1.3135e-01,  3.6154e-01,  3.8953e-01,  2.8907e-01,  3.0981e-01,\n",
      "          5.6216e-01,  3.0213e-01,  7.4494e-02, -1.9247e-01,  4.7317e-02,\n",
      "         -2.0462e-01,  1.1924e-01,  4.0228e-01, -4.4200e-01, -2.8812e-01,\n",
      "          3.7329e-01, -1.8125e-01,  4.3832e-01,  6.0617e-02,  7.1732e-02,\n",
      "         -3.1154e-01, -7.6242e-01, -1.6706e-01, -1.8356e-01,  2.2914e-01,\n",
      "         -5.5761e-02, -2.0641e-01,  6.7781e-01, -3.2683e-01, -3.0420e-01,\n",
      "          5.0281e-02, -4.1753e-01,  1.5901e-01, -6.1253e-01,  1.8099e-01,\n",
      "          3.7711e-01, -6.6657e-02, -1.9884e-01, -5.9226e-01, -7.5436e-02,\n",
      "          5.8123e-01, -5.4815e-01,  7.6522e-01, -2.5977e-01,  2.3490e-01,\n",
      "          2.5078e-01, -1.1813e-01,  2.2829e-01, -8.1220e-01, -7.3786e-01,\n",
      "         -2.7705e-01, -1.0638e-01, -2.7551e-01, -2.1730e-01,  6.9398e-02,\n",
      "          2.9412e-01,  2.9370e-01,  2.1655e-01,  4.2540e-01, -6.4420e-03,\n",
      "         -2.5713e-01, -5.3957e-02,  1.5795e-01, -5.6318e-01, -8.5588e-02,\n",
      "          7.2471e-01,  4.0842e-01, -2.0714e-01,  4.5418e-01, -3.4961e-01,\n",
      "          2.9817e-01,  3.5192e-01,  1.1789e-03,  4.2360e-01,  1.2787e-01,\n",
      "          1.0356e-01, -5.1026e-01,  6.7822e-01,  3.0800e-01, -4.8840e-01,\n",
      "         -3.6930e-01, -6.3272e-01, -3.1579e-03, -1.9691e-01, -3.7475e-01,\n",
      "          2.9680e-01, -8.5276e-01, -1.3666e-01,  4.4409e-01, -4.2051e-02,\n",
      "          3.3312e-02, -3.6514e-02, -1.7959e-01, -3.1418e-01,  3.7233e-01,\n",
      "         -4.4793e-03, -1.2049e-01, -2.3109e-01,  7.4618e-02, -6.2734e-01,\n",
      "          3.8622e-01,  6.3858e-02, -2.8429e-02, -4.7838e-01,  8.1511e-01,\n",
      "         -4.1438e-01,  2.2357e-01,  2.1366e-01, -1.7401e-01, -1.7124e-01,\n",
      "          3.2326e-01,  5.0160e-02, -2.6319e-01, -3.1630e-03, -5.4008e-01,\n",
      "          2.1738e-01,  2.8207e-01, -3.4864e-01,  6.6520e-02,  3.9670e-01,\n",
      "          8.0074e-01, -3.7280e-02,  3.5032e-01,  4.8999e-01,  1.9968e-01,\n",
      "          1.8769e-01, -4.4721e-01,  9.2358e-02,  6.3430e-02,  3.7120e-01]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "MODEL_NAME = 'brunokreiner/lyrics-bert'\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea1717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando filas 0 a 499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 5.92 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 0-499\n",
      "\n",
      "Procesando filas 500 a 999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.54 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 500-999\n",
      "\n",
      "Procesando filas 1000 a 1499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 1000-1499\n",
      "\n",
      "Procesando filas 1500 a 1999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 1500-1999\n",
      "\n",
      "Procesando filas 2000 a 2499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 2000-2499\n",
      "\n",
      "Procesando filas 2500 a 2999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 2500-2999\n",
      "\n",
      "Procesando filas 3000 a 3499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 3000-3499\n",
      "\n",
      "Procesando filas 3500 a 3999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 3500-3999\n",
      "\n",
      "Procesando filas 4000 a 4499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 4000-4499\n",
      "\n",
      "Procesando filas 4500 a 4999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 4500-4999\n",
      "\n",
      "Procesando filas 5000 a 5499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 5000-5499\n",
      "\n",
      "Procesando filas 5500 a 5999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 5500-5999\n",
      "\n",
      "Procesando filas 6000 a 6499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 6000-6499\n",
      "\n",
      "Procesando filas 6500 a 6999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 6500-6999\n",
      "\n",
      "Procesando filas 7000 a 7499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.66 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 7000-7499\n",
      "\n",
      "Procesando filas 7500 a 7999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 7500-7999\n",
      "\n",
      "Procesando filas 8000 a 8499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 8000-8499\n",
      "\n",
      "Procesando filas 8500 a 8999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 8500-8999\n",
      "\n",
      "Procesando filas 9000 a 9499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 9000-9499\n",
      "\n",
      "Procesando filas 9500 a 9999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 9500-9999\n",
      "\n",
      "Procesando filas 10000 a 10499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 10000-10499\n",
      "\n",
      "Procesando filas 10500 a 10999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 10500-10999\n",
      "\n",
      "Procesando filas 11000 a 11499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 11000-11499\n",
      "\n",
      "Procesando filas 11500 a 11999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 11500-11999\n",
      "\n",
      "Procesando filas 12000 a 12499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 12000-12499\n",
      "\n",
      "Procesando filas 12500 a 12999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 12500-12999\n",
      "\n",
      "Procesando filas 13000 a 13499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 13000-13499\n",
      "\n",
      "Procesando filas 13500 a 13999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 13500-13999\n",
      "\n",
      "Procesando filas 14000 a 14499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 14000-14499\n",
      "\n",
      "Procesando filas 14500 a 14999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 14500-14999\n",
      "\n",
      "Procesando filas 15000 a 15499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 15000-15499\n",
      "\n",
      "Procesando filas 15500 a 15999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 15500-15999\n",
      "\n",
      "Procesando filas 16000 a 16499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 16000-16499\n",
      "\n",
      "Procesando filas 16500 a 16999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 16500-16999\n",
      "\n",
      "Procesando filas 17000 a 17499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 17000-17499\n",
      "\n",
      "Procesando filas 17500 a 17999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 17500-17999\n",
      "\n",
      "Procesando filas 18000 a 18499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 18000-18499\n",
      "\n",
      "Procesando filas 18500 a 18999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 18500-18999\n",
      "\n",
      "Procesando filas 19000 a 19499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 19000-19499\n",
      "\n",
      "Procesando filas 19500 a 19999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.43 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 19500-19999\n",
      "\n",
      "Procesando filas 20000 a 20499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 20000-20499\n",
      "\n",
      "Procesando filas 20500 a 20999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 20500-20999\n",
      "\n",
      "Procesando filas 21000 a 21499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 21000-21499\n",
      "\n",
      "Procesando filas 21500 a 21999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.55 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 21500-21999\n",
      "\n",
      "Procesando filas 22000 a 22499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 22000-22499\n",
      "\n",
      "Procesando filas 22500 a 22999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 22500-22999\n",
      "\n",
      "Procesando filas 23000 a 23499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 23000-23499\n",
      "\n",
      "Procesando filas 23500 a 23999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 23500-23999\n",
      "\n",
      "Procesando filas 24000 a 24499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 24000-24499\n",
      "\n",
      "Procesando filas 24500 a 24999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 24500-24999\n",
      "\n",
      "Procesando filas 25000 a 25499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 25000-25499\n",
      "\n",
      "Procesando filas 25500 a 25999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 25500-25999\n",
      "\n",
      "Procesando filas 26000 a 26499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 26000-26499\n",
      "\n",
      "Procesando filas 26500 a 26999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 26500-26999\n",
      "\n",
      "Procesando filas 27000 a 27499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 27000-27499\n",
      "\n",
      "Procesando filas 27500 a 27999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 27500-27999\n",
      "\n",
      "Procesando filas 28000 a 28499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 28000-28499\n",
      "\n",
      "Procesando filas 28500 a 28999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.57 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 28500-28999\n",
      "\n",
      "Procesando filas 29000 a 29499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.56 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 29000-29499\n",
      "\n",
      "Procesando filas 29500 a 29999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 29500-29999\n",
      "\n",
      "Procesando filas 30000 a 30499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 30000-30499\n",
      "\n",
      "Procesando filas 30500 a 30999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 30500-30999\n",
      "\n",
      "Procesando filas 31000 a 31499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 31000-31499\n",
      "\n",
      "Procesando filas 31500 a 31999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.66 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 31500-31999\n",
      "\n",
      "Procesando filas 32000 a 32499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 32000-32499\n",
      "\n",
      "Procesando filas 32500 a 32999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 32500-32999\n",
      "\n",
      "Procesando filas 33000 a 33499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 33000-33499\n",
      "\n",
      "Procesando filas 33500 a 33999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 33500-33999\n",
      "\n",
      "Procesando filas 34000 a 34499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.64 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 34000-34499\n",
      "\n",
      "Procesando filas 34500 a 34999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 34500-34999\n",
      "\n",
      "Procesando filas 35000 a 35499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 5.00 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 35000-35499\n",
      "\n",
      "Procesando filas 35500 a 35999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.55 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 35500-35999\n",
      "\n",
      "Procesando filas 36000 a 36499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 36000-36499\n",
      "\n",
      "Procesando filas 36500 a 36999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.93 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 36500-36999\n",
      "\n",
      "Procesando filas 37000 a 37499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.71 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 37000-37499\n",
      "\n",
      "Procesando filas 37500 a 37999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 37500-37999\n",
      "\n",
      "Procesando filas 38000 a 38499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.66 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 38000-38499\n",
      "\n",
      "Procesando filas 38500 a 38999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.58 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 38500-38999\n",
      "\n",
      "Procesando filas 39000 a 39499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 39000-39499\n",
      "\n",
      "Procesando filas 39500 a 39999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 39500-39999\n",
      "\n",
      "Procesando filas 40000 a 40499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 40000-40499\n",
      "\n",
      "Procesando filas 40500 a 40999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 40500-40999\n",
      "\n",
      "Procesando filas 41000 a 41499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.54 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 41000-41499\n",
      "\n",
      "Procesando filas 41500 a 41999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 41500-41999\n",
      "\n",
      "Procesando filas 42000 a 42499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 42000-42499\n",
      "\n",
      "Procesando filas 42500 a 42999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 42500-42999\n",
      "\n",
      "Procesando filas 43000 a 43499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 43000-43499\n",
      "\n",
      "Procesando filas 43500 a 43999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.55 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 43500-43999\n",
      "\n",
      "Procesando filas 44000 a 44499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 44000-44499\n",
      "\n",
      "Procesando filas 44500 a 44999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 44500-44999\n",
      "\n",
      "Procesando filas 45000 a 45499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 45000-45499\n",
      "\n",
      "Procesando filas 45500 a 45999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 45500-45999\n",
      "\n",
      "Procesando filas 46000 a 46499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 46000-46499\n",
      "\n",
      "Procesando filas 46500 a 46999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 46500-46999\n",
      "\n",
      "Procesando filas 47000 a 47499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 47000-47499\n",
      "\n",
      "Procesando filas 47500 a 47999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 47500-47999\n",
      "\n",
      "Procesando filas 48000 a 48499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 48000-48499\n",
      "\n",
      "Procesando filas 48500 a 48999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 48500-48999\n",
      "\n",
      "Procesando filas 49000 a 49499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 49000-49499\n",
      "\n",
      "Procesando filas 49500 a 49999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 49500-49999\n",
      "\n",
      "Procesando filas 50000 a 50499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 50000-50499\n",
      "\n",
      "Procesando filas 50500 a 50999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 50500-50999\n",
      "\n",
      "Procesando filas 51000 a 51499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 51000-51499\n",
      "\n",
      "Procesando filas 51500 a 51999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 51500-51999\n",
      "\n",
      "Procesando filas 52000 a 52499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 52000-52499\n",
      "\n",
      "Procesando filas 52500 a 52999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 52500-52999\n",
      "\n",
      "Procesando filas 53000 a 53499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 53000-53499\n",
      "\n",
      "Procesando filas 53500 a 53999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 53500-53999\n",
      "\n",
      "Procesando filas 54000 a 54499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 54000-54499\n",
      "\n",
      "Procesando filas 54500 a 54999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 54500-54999\n",
      "\n",
      "Procesando filas 55000 a 55499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 55000-55499\n",
      "\n",
      "Procesando filas 55500 a 55999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 55500-55999\n",
      "\n",
      "Procesando filas 56000 a 56499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 56000-56499\n",
      "\n",
      "Procesando filas 56500 a 56999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.58 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 56500-56999\n",
      "\n",
      "Procesando filas 57000 a 57499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.56 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 57000-57499\n",
      "\n",
      "Procesando filas 57500 a 57999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 57500-57999\n",
      "\n",
      "Procesando filas 58000 a 58499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 58000-58499\n",
      "\n",
      "Procesando filas 58500 a 58999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 58500-58999\n",
      "\n",
      "Procesando filas 59000 a 59499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 59000-59499\n",
      "\n",
      "Procesando filas 59500 a 59999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 59500-59999\n",
      "\n",
      "Procesando filas 60000 a 60499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 60000-60499\n",
      "\n",
      "Procesando filas 60500 a 60999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 60500-60999\n",
      "\n",
      "Procesando filas 61000 a 61499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 61000-61499\n",
      "\n",
      "Procesando filas 61500 a 61999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 61500-61999\n",
      "\n",
      "Procesando filas 62000 a 62499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 62000-62499\n",
      "\n",
      "Procesando filas 62500 a 62999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 62500-62999\n",
      "\n",
      "Procesando filas 63000 a 63499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 63000-63499\n",
      "\n",
      "Procesando filas 63500 a 63999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 63500-63999\n",
      "\n",
      "Procesando filas 64000 a 64499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 64000-64499\n",
      "\n",
      "Procesando filas 64500 a 64999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 64500-64999\n",
      "\n",
      "Procesando filas 65000 a 65499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 65000-65499\n",
      "\n",
      "Procesando filas 65500 a 65999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 65500-65999\n",
      "\n",
      "Procesando filas 66000 a 66499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 66000-66499\n",
      "\n",
      "Procesando filas 66500 a 66999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 66500-66999\n",
      "\n",
      "Procesando filas 67000 a 67499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 67000-67499\n",
      "\n",
      "Procesando filas 67500 a 67999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.56 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 67500-67999\n",
      "\n",
      "Procesando filas 68000 a 68499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.54 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 68000-68499\n",
      "\n",
      "Procesando filas 68500 a 68999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 68500-68999\n",
      "\n",
      "Procesando filas 69000 a 69499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 69000-69499\n",
      "\n",
      "Procesando filas 69500 a 69999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 69500-69999\n",
      "\n",
      "Procesando filas 70000 a 70499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 70000-70499\n",
      "\n",
      "Procesando filas 70500 a 70999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 70500-70999\n",
      "\n",
      "Procesando filas 71000 a 71499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 71000-71499\n",
      "\n",
      "Procesando filas 71500 a 71999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 71500-71999\n",
      "\n",
      "Procesando filas 72000 a 72499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 72000-72499\n",
      "\n",
      "Procesando filas 72500 a 72999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 72500-72999\n",
      "\n",
      "Procesando filas 73000 a 73499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 73000-73499\n",
      "\n",
      "Procesando filas 73500 a 73999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 73500-73999\n",
      "\n",
      "Procesando filas 74000 a 74499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 74000-74499\n",
      "\n",
      "Procesando filas 74500 a 74999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 74500-74999\n",
      "\n",
      "Procesando filas 75000 a 75499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 75000-75499\n",
      "\n",
      "Procesando filas 75500 a 75999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 75500-75999\n",
      "\n",
      "Procesando filas 76000 a 76499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 76000-76499\n",
      "\n",
      "Procesando filas 76500 a 76999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 76500-76999\n",
      "\n",
      "Procesando filas 77000 a 77499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 77000-77499\n",
      "\n",
      "Procesando filas 77500 a 77999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 77500-77999\n",
      "\n",
      "Procesando filas 78000 a 78499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 78000-78499\n",
      "\n",
      "Procesando filas 78500 a 78999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 78500-78999\n",
      "\n",
      "Procesando filas 79000 a 79499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 79000-79499\n",
      "\n",
      "Procesando filas 79500 a 79999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 79500-79999\n",
      "\n",
      "Procesando filas 80000 a 80499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 80000-80499\n",
      "\n",
      "Procesando filas 80500 a 80999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 80500-80999\n",
      "\n",
      "Procesando filas 81000 a 81499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 81000-81499\n",
      "\n",
      "Procesando filas 81500 a 81999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 81500-81999\n",
      "\n",
      "Procesando filas 82000 a 82499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 82000-82499\n",
      "\n",
      "Procesando filas 82500 a 82999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 82500-82999\n",
      "\n",
      "Procesando filas 83000 a 83499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 83000-83499\n",
      "\n",
      "Procesando filas 83500 a 83999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 83500-83999\n",
      "\n",
      "Procesando filas 84000 a 84499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.54 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 84000-84499\n",
      "\n",
      "Procesando filas 84500 a 84999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 84500-84999\n",
      "\n",
      "Procesando filas 85000 a 85499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 85000-85499\n",
      "\n",
      "Procesando filas 85500 a 85999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 85500-85999\n",
      "\n",
      "Procesando filas 86000 a 86499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 86000-86499\n",
      "\n",
      "Procesando filas 86500 a 86999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 86500-86999\n",
      "\n",
      "Procesando filas 87000 a 87499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 87000-87499\n",
      "\n",
      "Procesando filas 87500 a 87999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 87500-87999\n",
      "\n",
      "Procesando filas 88000 a 88499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 88000-88499\n",
      "\n",
      "Procesando filas 88500 a 88999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 88500-88999\n",
      "\n",
      "Procesando filas 89000 a 89499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 89000-89499\n",
      "\n",
      "Procesando filas 89500 a 89999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 89500-89999\n",
      "\n",
      "Procesando filas 90000 a 90499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 90000-90499\n",
      "\n",
      "Procesando filas 90500 a 90999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 90500-90999\n",
      "\n",
      "Procesando filas 91000 a 91499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 91000-91499\n",
      "\n",
      "Procesando filas 91500 a 91999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 91500-91999\n",
      "\n",
      "Procesando filas 92000 a 92499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.52 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 92000-92499\n",
      "\n",
      "Procesando filas 92500 a 92999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.54 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 92500-92999\n",
      "\n",
      "Procesando filas 93000 a 93499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 93000-93499\n",
      "\n",
      "Procesando filas 93500 a 93999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.66 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 93500-93999\n",
      "\n",
      "Procesando filas 94000 a 94499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 94000-94499\n",
      "\n",
      "Procesando filas 94500 a 94999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 94500-94999\n",
      "\n",
      "Procesando filas 95000 a 95499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 95000-95499\n",
      "\n",
      "Procesando filas 95500 a 95999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 95500-95999\n",
      "\n",
      "Procesando filas 96000 a 96499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 96000-96499\n",
      "\n",
      "Procesando filas 96500 a 96999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 96500-96999\n",
      "\n",
      "Procesando filas 97000 a 97499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 97000-97499\n",
      "\n",
      "Procesando filas 97500 a 97999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 97500-97999\n",
      "\n",
      "Procesando filas 98000 a 98499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 98000-98499\n",
      "\n",
      "Procesando filas 98500 a 98999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 98500-98999\n",
      "\n",
      "Procesando filas 99000 a 99499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 99000-99499\n",
      "\n",
      "Procesando filas 99500 a 99999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 99500-99999\n",
      "\n",
      "Procesando filas 100000 a 100499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 100000-100499\n",
      "\n",
      "Procesando filas 100500 a 100999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.59 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 100500-100999\n",
      "\n",
      "Procesando filas 101000 a 101499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 101000-101499\n",
      "\n",
      "Procesando filas 101500 a 101999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 101500-101999\n",
      "\n",
      "Procesando filas 102000 a 102499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.49 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 102000-102499\n",
      "\n",
      "Procesando filas 102500 a 102999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.47 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 102500-102999\n",
      "\n",
      "Procesando filas 103000 a 103499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.46 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 103000-103499\n",
      "\n",
      "Procesando filas 103500 a 103999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 103500-103999\n",
      "\n",
      "Procesando filas 104000 a 104499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.45 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 104000-104499\n",
      "\n",
      "Procesando filas 104500 a 104999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 104500-104999\n",
      "\n",
      "Procesando filas 105000 a 105499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.44 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 105000-105499\n",
      "\n",
      "Procesando filas 105500 a 105999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 105500-105999\n",
      "\n",
      "Procesando filas 106000 a 106499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.50 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 106000-106499\n",
      "\n",
      "Procesando filas 106500 a 106999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.51 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 106500-106999\n",
      "\n",
      "Procesando filas 107000 a 107499...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.53 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 107000-107499\n",
      "\n",
      "Procesando filas 107500 a 107999...\n",
      "shape de sentences:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 4.48 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([500, 300])\n",
      "Guardado batch 107500-107999\n",
      "\n",
      "Procesando filas 108000 a 108137...\n",
      "shape de sentences:  138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total: 1.29 segundos\n",
      "Iniciando guardado de los vectores: \n",
      "Sentence embeddings:\n",
      "torch.Size([138, 300])\n",
      "Guardado batch 108000-108137\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 500 # Porque nos quedamos sin RAM :(\n",
    "INIT = 0\n",
    "TOTAL_ROWS = 108138\n",
    "# TOTAL_ROWS = 1000\n",
    "\n",
    "# To save vectors\n",
    "# save_dir = \"/content/drive/MyDrive/embeddings_lyricsbert_to_fusion/\"\n",
    "save_dir = os.path.join(DATA_PATH, \"embbedings_khipu\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# start = 0\n",
    "# end = 5000\n",
    "# ROWS = end - start\n",
    "A = ['text', 'song', 'Artist(s)', 'Album', 'Similar Artist 1', 'Genre']\n",
    "\n",
    "\n",
    "for start in range(INIT, TOTAL_ROWS, BATCH_SIZE):\n",
    "  end = min(start + BATCH_SIZE, TOTAL_ROWS)\n",
    "  print(f\"\\nProcesando filas {start} a {end-1}...\")\n",
    "  df = pd.read_csv(path_dataset, skiprows=range(1, start + 1), nrows=end - start)\n",
    "  \n",
    "  df['combined_text'] = df[A].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "  df_sentences = df['combined_text'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "  print(\"shape de sentences: \", len(df_sentences))\n",
    "\n",
    "  # Tokenize input\n",
    "  start_time = time.time()\n",
    "\n",
    "  encoded_df_input = tokenizer(df_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "  # Compute embeddings\n",
    "  with torch.no_grad():\n",
    "      model_output = model(**encoded_df_input)\n",
    "\n",
    "  # Pooling (mean)\n",
    "  sentence_df_embeddings = mean_pooling(model_output, encoded_df_input['attention_mask'])\n",
    "\n",
    "\n",
    "\n",
    "  # Print results\n",
    "  end_time = time.time()\n",
    "  print(f\"\\nTiempo total: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "  print(\"Iniciando guardado de los vectores: \")\n",
    "  embeddings_np = sentence_df_embeddings.numpy()\n",
    "\n",
    "  # Guardar en formato binario .npy\n",
    "  npy_filename = f\"embeddings_lyricsbert_{start}_{end-1}.npy\"\n",
    "  np.save(os.path.join(save_dir, npy_filename), embeddings_np)\n",
    "\n",
    "  # # Guardar en CSV\n",
    "  # csv_filename = f\"embeddings_lyricsbert_{start}_{end-1}.csv\"\n",
    "  # np.savetxt(os.path.join(save_dir, csv_filename), embeddings_np, delimiter=\",\")\n",
    "  print(\"Sentence embeddings:\")\n",
    "  # print(sentence_df_embeddings)\n",
    "  print(sentence_df_embeddings.shape)\n",
    "  print(f\"Guardado batch {start}-{end-1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8484f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ledo: embeddings_lyricsbert_0_499.npy - Shape: (500, 300)\n",
      "Total: 1\n",
      "Ledo: embeddings_lyricsbert_500_999.npy - Shape: (500, 300)\n",
      "Total: 2\n",
      "Ledo: embeddings_lyricsbert_1000_1499.npy - Shape: (500, 300)\n",
      "Total: 3\n",
      "Ledo: embeddings_lyricsbert_1500_1999.npy - Shape: (500, 300)\n",
      "Total: 4\n",
      "Ledo: embeddings_lyricsbert_2000_2499.npy - Shape: (500, 300)\n",
      "Total: 5\n",
      "Ledo: embeddings_lyricsbert_2500_2999.npy - Shape: (500, 300)\n",
      "Total: 6\n",
      "Ledo: embeddings_lyricsbert_3000_3499.npy - Shape: (500, 300)\n",
      "Total: 7\n",
      "Ledo: embeddings_lyricsbert_3500_3999.npy - Shape: (500, 300)\n",
      "Total: 8\n",
      "Ledo: embeddings_lyricsbert_4000_4499.npy - Shape: (500, 300)\n",
      "Total: 9\n",
      "Ledo: embeddings_lyricsbert_4500_4999.npy - Shape: (500, 300)\n",
      "Total: 10\n",
      "Ledo: embeddings_lyricsbert_5000_5499.npy - Shape: (500, 300)\n",
      "Total: 11\n",
      "Ledo: embeddings_lyricsbert_5500_5999.npy - Shape: (500, 300)\n",
      "Total: 12\n",
      "Ledo: embeddings_lyricsbert_6000_6499.npy - Shape: (500, 300)\n",
      "Total: 13\n",
      "Ledo: embeddings_lyricsbert_6500_6999.npy - Shape: (500, 300)\n",
      "Total: 14\n",
      "Ledo: embeddings_lyricsbert_7000_7499.npy - Shape: (500, 300)\n",
      "Total: 15\n",
      "Ledo: embeddings_lyricsbert_7500_7999.npy - Shape: (500, 300)\n",
      "Total: 16\n",
      "Ledo: embeddings_lyricsbert_8000_8499.npy - Shape: (500, 300)\n",
      "Total: 17\n",
      "Ledo: embeddings_lyricsbert_8500_8999.npy - Shape: (500, 300)\n",
      "Total: 18\n",
      "Ledo: embeddings_lyricsbert_9000_9499.npy - Shape: (500, 300)\n",
      "Total: 19\n",
      "Ledo: embeddings_lyricsbert_9500_9999.npy - Shape: (500, 300)\n",
      "Total: 20\n",
      "Ledo: embeddings_lyricsbert_10000_10499.npy - Shape: (500, 300)\n",
      "Total: 21\n",
      "Ledo: embeddings_lyricsbert_10500_10999.npy - Shape: (500, 300)\n",
      "Total: 22\n",
      "Ledo: embeddings_lyricsbert_11000_11499.npy - Shape: (500, 300)\n",
      "Total: 23\n",
      "Ledo: embeddings_lyricsbert_11500_11999.npy - Shape: (500, 300)\n",
      "Total: 24\n",
      "Ledo: embeddings_lyricsbert_12000_12499.npy - Shape: (500, 300)\n",
      "Total: 25\n",
      "Ledo: embeddings_lyricsbert_12500_12999.npy - Shape: (500, 300)\n",
      "Total: 26\n",
      "Ledo: embeddings_lyricsbert_13000_13499.npy - Shape: (500, 300)\n",
      "Total: 27\n",
      "Ledo: embeddings_lyricsbert_13500_13999.npy - Shape: (500, 300)\n",
      "Total: 28\n",
      "Ledo: embeddings_lyricsbert_14000_14499.npy - Shape: (500, 300)\n",
      "Total: 29\n",
      "Ledo: embeddings_lyricsbert_14500_14999.npy - Shape: (500, 300)\n",
      "Total: 30\n",
      "Ledo: embeddings_lyricsbert_15000_15499.npy - Shape: (500, 300)\n",
      "Total: 31\n",
      "Ledo: embeddings_lyricsbert_15500_15999.npy - Shape: (500, 300)\n",
      "Total: 32\n",
      "Ledo: embeddings_lyricsbert_16000_16499.npy - Shape: (500, 300)\n",
      "Total: 33\n",
      "Ledo: embeddings_lyricsbert_16500_16999.npy - Shape: (500, 300)\n",
      "Total: 34\n",
      "Ledo: embeddings_lyricsbert_17000_17499.npy - Shape: (500, 300)\n",
      "Total: 35\n",
      "Ledo: embeddings_lyricsbert_17500_17999.npy - Shape: (500, 300)\n",
      "Total: 36\n",
      "Ledo: embeddings_lyricsbert_18000_18499.npy - Shape: (500, 300)\n",
      "Total: 37\n",
      "Ledo: embeddings_lyricsbert_18500_18999.npy - Shape: (500, 300)\n",
      "Total: 38\n",
      "Ledo: embeddings_lyricsbert_19000_19499.npy - Shape: (500, 300)\n",
      "Total: 39\n",
      "Ledo: embeddings_lyricsbert_19500_19999.npy - Shape: (500, 300)\n",
      "Total: 40\n",
      "Ledo: embeddings_lyricsbert_20000_20499.npy - Shape: (500, 300)\n",
      "Total: 41\n",
      "Ledo: embeddings_lyricsbert_20500_20999.npy - Shape: (500, 300)\n",
      "Total: 42\n",
      "Ledo: embeddings_lyricsbert_21000_21499.npy - Shape: (500, 300)\n",
      "Total: 43\n",
      "Ledo: embeddings_lyricsbert_21500_21999.npy - Shape: (500, 300)\n",
      "Total: 44\n",
      "Ledo: embeddings_lyricsbert_22000_22499.npy - Shape: (500, 300)\n",
      "Total: 45\n",
      "Ledo: embeddings_lyricsbert_22500_22999.npy - Shape: (500, 300)\n",
      "Total: 46\n",
      "Ledo: embeddings_lyricsbert_23000_23499.npy - Shape: (500, 300)\n",
      "Total: 47\n",
      "Ledo: embeddings_lyricsbert_23500_23999.npy - Shape: (500, 300)\n",
      "Total: 48\n",
      "Ledo: embeddings_lyricsbert_24000_24499.npy - Shape: (500, 300)\n",
      "Total: 49\n",
      "Ledo: embeddings_lyricsbert_24500_24999.npy - Shape: (500, 300)\n",
      "Total: 50\n",
      "Ledo: embeddings_lyricsbert_25000_25499.npy - Shape: (500, 300)\n",
      "Total: 51\n",
      "Ledo: embeddings_lyricsbert_25500_25999.npy - Shape: (500, 300)\n",
      "Total: 52\n",
      "Ledo: embeddings_lyricsbert_26000_26499.npy - Shape: (500, 300)\n",
      "Total: 53\n",
      "Ledo: embeddings_lyricsbert_26500_26999.npy - Shape: (500, 300)\n",
      "Total: 54\n",
      "Ledo: embeddings_lyricsbert_27000_27499.npy - Shape: (500, 300)\n",
      "Total: 55\n",
      "Ledo: embeddings_lyricsbert_27500_27999.npy - Shape: (500, 300)\n",
      "Total: 56\n",
      "Ledo: embeddings_lyricsbert_28000_28499.npy - Shape: (500, 300)\n",
      "Total: 57\n",
      "Ledo: embeddings_lyricsbert_28500_28999.npy - Shape: (500, 300)\n",
      "Total: 58\n",
      "Ledo: embeddings_lyricsbert_29000_29499.npy - Shape: (500, 300)\n",
      "Total: 59\n",
      "Ledo: embeddings_lyricsbert_29500_29999.npy - Shape: (500, 300)\n",
      "Total: 60\n",
      "Ledo: embeddings_lyricsbert_30000_30499.npy - Shape: (500, 300)\n",
      "Total: 61\n",
      "Ledo: embeddings_lyricsbert_30500_30999.npy - Shape: (500, 300)\n",
      "Total: 62\n",
      "Ledo: embeddings_lyricsbert_31000_31499.npy - Shape: (500, 300)\n",
      "Total: 63\n",
      "Ledo: embeddings_lyricsbert_31500_31999.npy - Shape: (500, 300)\n",
      "Total: 64\n",
      "Ledo: embeddings_lyricsbert_32000_32499.npy - Shape: (500, 300)\n",
      "Total: 65\n",
      "Ledo: embeddings_lyricsbert_32500_32999.npy - Shape: (500, 300)\n",
      "Total: 66\n",
      "Ledo: embeddings_lyricsbert_33000_33499.npy - Shape: (500, 300)\n",
      "Total: 67\n",
      "Ledo: embeddings_lyricsbert_33500_33999.npy - Shape: (500, 300)\n",
      "Total: 68\n",
      "Ledo: embeddings_lyricsbert_34000_34499.npy - Shape: (500, 300)\n",
      "Total: 69\n",
      "Ledo: embeddings_lyricsbert_34500_34999.npy - Shape: (500, 300)\n",
      "Total: 70\n",
      "Ledo: embeddings_lyricsbert_35000_35499.npy - Shape: (500, 300)\n",
      "Total: 71\n",
      "Ledo: embeddings_lyricsbert_35500_35999.npy - Shape: (500, 300)\n",
      "Total: 72\n",
      "Ledo: embeddings_lyricsbert_36000_36499.npy - Shape: (500, 300)\n",
      "Total: 73\n",
      "Ledo: embeddings_lyricsbert_36500_36999.npy - Shape: (500, 300)\n",
      "Total: 74\n",
      "Ledo: embeddings_lyricsbert_37000_37499.npy - Shape: (500, 300)\n",
      "Total: 75\n",
      "Ledo: embeddings_lyricsbert_37500_37999.npy - Shape: (500, 300)\n",
      "Total: 76\n",
      "Ledo: embeddings_lyricsbert_38000_38499.npy - Shape: (500, 300)\n",
      "Total: 77\n",
      "Ledo: embeddings_lyricsbert_38500_38999.npy - Shape: (500, 300)\n",
      "Total: 78\n",
      "Ledo: embeddings_lyricsbert_39000_39499.npy - Shape: (500, 300)\n",
      "Total: 79\n",
      "Ledo: embeddings_lyricsbert_39500_39999.npy - Shape: (500, 300)\n",
      "Total: 80\n",
      "Ledo: embeddings_lyricsbert_40000_40499.npy - Shape: (500, 300)\n",
      "Total: 81\n",
      "Ledo: embeddings_lyricsbert_40500_40999.npy - Shape: (500, 300)\n",
      "Total: 82\n",
      "Ledo: embeddings_lyricsbert_41000_41499.npy - Shape: (500, 300)\n",
      "Total: 83\n",
      "Ledo: embeddings_lyricsbert_41500_41999.npy - Shape: (500, 300)\n",
      "Total: 84\n",
      "Ledo: embeddings_lyricsbert_42000_42499.npy - Shape: (500, 300)\n",
      "Total: 85\n",
      "Ledo: embeddings_lyricsbert_42500_42999.npy - Shape: (500, 300)\n",
      "Total: 86\n",
      "Ledo: embeddings_lyricsbert_43000_43499.npy - Shape: (500, 300)\n",
      "Total: 87\n",
      "Ledo: embeddings_lyricsbert_43500_43999.npy - Shape: (500, 300)\n",
      "Total: 88\n",
      "Ledo: embeddings_lyricsbert_44000_44499.npy - Shape: (500, 300)\n",
      "Total: 89\n",
      "Ledo: embeddings_lyricsbert_44500_44999.npy - Shape: (500, 300)\n",
      "Total: 90\n",
      "Ledo: embeddings_lyricsbert_45000_45499.npy - Shape: (500, 300)\n",
      "Total: 91\n",
      "Ledo: embeddings_lyricsbert_45500_45999.npy - Shape: (500, 300)\n",
      "Total: 92\n",
      "Ledo: embeddings_lyricsbert_46000_46499.npy - Shape: (500, 300)\n",
      "Total: 93\n",
      "Ledo: embeddings_lyricsbert_46500_46999.npy - Shape: (500, 300)\n",
      "Total: 94\n",
      "Ledo: embeddings_lyricsbert_47000_47499.npy - Shape: (500, 300)\n",
      "Total: 95\n",
      "Ledo: embeddings_lyricsbert_47500_47999.npy - Shape: (500, 300)\n",
      "Total: 96\n",
      "Ledo: embeddings_lyricsbert_48000_48499.npy - Shape: (500, 300)\n",
      "Total: 97\n",
      "Ledo: embeddings_lyricsbert_48500_48999.npy - Shape: (500, 300)\n",
      "Total: 98\n",
      "Ledo: embeddings_lyricsbert_49000_49499.npy - Shape: (500, 300)\n",
      "Total: 99\n",
      "Ledo: embeddings_lyricsbert_49500_49999.npy - Shape: (500, 300)\n",
      "Total: 100\n",
      "Ledo: embeddings_lyricsbert_50000_50499.npy - Shape: (500, 300)\n",
      "Total: 101\n",
      "Ledo: embeddings_lyricsbert_50500_50999.npy - Shape: (500, 300)\n",
      "Total: 102\n",
      "Ledo: embeddings_lyricsbert_51000_51499.npy - Shape: (500, 300)\n",
      "Total: 103\n",
      "Ledo: embeddings_lyricsbert_51500_51999.npy - Shape: (500, 300)\n",
      "Total: 104\n",
      "Ledo: embeddings_lyricsbert_52000_52499.npy - Shape: (500, 300)\n",
      "Total: 105\n",
      "Ledo: embeddings_lyricsbert_52500_52999.npy - Shape: (500, 300)\n",
      "Total: 106\n",
      "Ledo: embeddings_lyricsbert_53000_53499.npy - Shape: (500, 300)\n",
      "Total: 107\n",
      "Ledo: embeddings_lyricsbert_53500_53999.npy - Shape: (500, 300)\n",
      "Total: 108\n",
      "Ledo: embeddings_lyricsbert_54000_54499.npy - Shape: (500, 300)\n",
      "Total: 109\n",
      "Ledo: embeddings_lyricsbert_54500_54999.npy - Shape: (500, 300)\n",
      "Total: 110\n",
      "Ledo: embeddings_lyricsbert_55000_55499.npy - Shape: (500, 300)\n",
      "Total: 111\n",
      "Ledo: embeddings_lyricsbert_55500_55999.npy - Shape: (500, 300)\n",
      "Total: 112\n",
      "Ledo: embeddings_lyricsbert_56000_56499.npy - Shape: (500, 300)\n",
      "Total: 113\n",
      "Ledo: embeddings_lyricsbert_56500_56999.npy - Shape: (500, 300)\n",
      "Total: 114\n",
      "Ledo: embeddings_lyricsbert_57000_57499.npy - Shape: (500, 300)\n",
      "Total: 115\n",
      "Ledo: embeddings_lyricsbert_57500_57999.npy - Shape: (500, 300)\n",
      "Total: 116\n",
      "Ledo: embeddings_lyricsbert_58000_58499.npy - Shape: (500, 300)\n",
      "Total: 117\n",
      "Ledo: embeddings_lyricsbert_58500_58999.npy - Shape: (500, 300)\n",
      "Total: 118\n",
      "Ledo: embeddings_lyricsbert_59000_59499.npy - Shape: (500, 300)\n",
      "Total: 119\n",
      "Ledo: embeddings_lyricsbert_59500_59999.npy - Shape: (500, 300)\n",
      "Total: 120\n",
      "Ledo: embeddings_lyricsbert_60000_60499.npy - Shape: (500, 300)\n",
      "Total: 121\n",
      "Ledo: embeddings_lyricsbert_60500_60999.npy - Shape: (500, 300)\n",
      "Total: 122\n",
      "Ledo: embeddings_lyricsbert_61000_61499.npy - Shape: (500, 300)\n",
      "Total: 123\n",
      "Ledo: embeddings_lyricsbert_61500_61999.npy - Shape: (500, 300)\n",
      "Total: 124\n",
      "Ledo: embeddings_lyricsbert_62000_62499.npy - Shape: (500, 300)\n",
      "Total: 125\n",
      "Ledo: embeddings_lyricsbert_62500_62999.npy - Shape: (500, 300)\n",
      "Total: 126\n",
      "Ledo: embeddings_lyricsbert_63000_63499.npy - Shape: (500, 300)\n",
      "Total: 127\n",
      "Ledo: embeddings_lyricsbert_63500_63999.npy - Shape: (500, 300)\n",
      "Total: 128\n",
      "Ledo: embeddings_lyricsbert_64000_64499.npy - Shape: (500, 300)\n",
      "Total: 129\n",
      "Ledo: embeddings_lyricsbert_64500_64999.npy - Shape: (500, 300)\n",
      "Total: 130\n",
      "Ledo: embeddings_lyricsbert_65000_65499.npy - Shape: (500, 300)\n",
      "Total: 131\n",
      "Ledo: embeddings_lyricsbert_65500_65999.npy - Shape: (500, 300)\n",
      "Total: 132\n",
      "Ledo: embeddings_lyricsbert_66000_66499.npy - Shape: (500, 300)\n",
      "Total: 133\n",
      "Ledo: embeddings_lyricsbert_66500_66999.npy - Shape: (500, 300)\n",
      "Total: 134\n",
      "Ledo: embeddings_lyricsbert_67000_67499.npy - Shape: (500, 300)\n",
      "Total: 135\n",
      "Ledo: embeddings_lyricsbert_67500_67999.npy - Shape: (500, 300)\n",
      "Total: 136\n",
      "Ledo: embeddings_lyricsbert_68000_68499.npy - Shape: (500, 300)\n",
      "Total: 137\n",
      "Ledo: embeddings_lyricsbert_68500_68999.npy - Shape: (500, 300)\n",
      "Total: 138\n",
      "Ledo: embeddings_lyricsbert_69000_69499.npy - Shape: (500, 300)\n",
      "Total: 139\n",
      "Ledo: embeddings_lyricsbert_69500_69999.npy - Shape: (500, 300)\n",
      "Total: 140\n",
      "Ledo: embeddings_lyricsbert_70000_70499.npy - Shape: (500, 300)\n",
      "Total: 141\n",
      "Ledo: embeddings_lyricsbert_70500_70999.npy - Shape: (500, 300)\n",
      "Total: 142\n",
      "Ledo: embeddings_lyricsbert_71000_71499.npy - Shape: (500, 300)\n",
      "Total: 143\n",
      "Ledo: embeddings_lyricsbert_71500_71999.npy - Shape: (500, 300)\n",
      "Total: 144\n",
      "Ledo: embeddings_lyricsbert_72000_72499.npy - Shape: (500, 300)\n",
      "Total: 145\n",
      "Ledo: embeddings_lyricsbert_72500_72999.npy - Shape: (500, 300)\n",
      "Total: 146\n",
      "Ledo: embeddings_lyricsbert_73000_73499.npy - Shape: (500, 300)\n",
      "Total: 147\n",
      "Ledo: embeddings_lyricsbert_73500_73999.npy - Shape: (500, 300)\n",
      "Total: 148\n",
      "Ledo: embeddings_lyricsbert_74000_74499.npy - Shape: (500, 300)\n",
      "Total: 149\n",
      "Ledo: embeddings_lyricsbert_74500_74999.npy - Shape: (500, 300)\n",
      "Total: 150\n",
      "Ledo: embeddings_lyricsbert_75000_75499.npy - Shape: (500, 300)\n",
      "Total: 151\n",
      "Ledo: embeddings_lyricsbert_75500_75999.npy - Shape: (500, 300)\n",
      "Total: 152\n",
      "Ledo: embeddings_lyricsbert_76000_76499.npy - Shape: (500, 300)\n",
      "Total: 153\n",
      "Ledo: embeddings_lyricsbert_76500_76999.npy - Shape: (500, 300)\n",
      "Total: 154\n",
      "Ledo: embeddings_lyricsbert_77000_77499.npy - Shape: (500, 300)\n",
      "Total: 155\n",
      "Ledo: embeddings_lyricsbert_77500_77999.npy - Shape: (500, 300)\n",
      "Total: 156\n",
      "Ledo: embeddings_lyricsbert_78000_78499.npy - Shape: (500, 300)\n",
      "Total: 157\n",
      "Ledo: embeddings_lyricsbert_78500_78999.npy - Shape: (500, 300)\n",
      "Total: 158\n",
      "Ledo: embeddings_lyricsbert_79000_79499.npy - Shape: (500, 300)\n",
      "Total: 159\n",
      "Ledo: embeddings_lyricsbert_79500_79999.npy - Shape: (500, 300)\n",
      "Total: 160\n",
      "Ledo: embeddings_lyricsbert_80000_80499.npy - Shape: (500, 300)\n",
      "Total: 161\n",
      "Ledo: embeddings_lyricsbert_80500_80999.npy - Shape: (500, 300)\n",
      "Total: 162\n",
      "Ledo: embeddings_lyricsbert_81000_81499.npy - Shape: (500, 300)\n",
      "Total: 163\n",
      "Ledo: embeddings_lyricsbert_81500_81999.npy - Shape: (500, 300)\n",
      "Total: 164\n",
      "Ledo: embeddings_lyricsbert_82000_82499.npy - Shape: (500, 300)\n",
      "Total: 165\n",
      "Ledo: embeddings_lyricsbert_82500_82999.npy - Shape: (500, 300)\n",
      "Total: 166\n",
      "Ledo: embeddings_lyricsbert_83000_83499.npy - Shape: (500, 300)\n",
      "Total: 167\n",
      "Ledo: embeddings_lyricsbert_83500_83999.npy - Shape: (500, 300)\n",
      "Total: 168\n",
      "Ledo: embeddings_lyricsbert_84000_84499.npy - Shape: (500, 300)\n",
      "Total: 169\n",
      "Ledo: embeddings_lyricsbert_84500_84999.npy - Shape: (500, 300)\n",
      "Total: 170\n",
      "Ledo: embeddings_lyricsbert_85000_85499.npy - Shape: (500, 300)\n",
      "Total: 171\n",
      "Ledo: embeddings_lyricsbert_85500_85999.npy - Shape: (500, 300)\n",
      "Total: 172\n",
      "Ledo: embeddings_lyricsbert_86000_86499.npy - Shape: (500, 300)\n",
      "Total: 173\n",
      "Ledo: embeddings_lyricsbert_86500_86999.npy - Shape: (500, 300)\n",
      "Total: 174\n",
      "Ledo: embeddings_lyricsbert_87000_87499.npy - Shape: (500, 300)\n",
      "Total: 175\n",
      "Ledo: embeddings_lyricsbert_87500_87999.npy - Shape: (500, 300)\n",
      "Total: 176\n",
      "Ledo: embeddings_lyricsbert_88000_88499.npy - Shape: (500, 300)\n",
      "Total: 177\n",
      "Ledo: embeddings_lyricsbert_88500_88999.npy - Shape: (500, 300)\n",
      "Total: 178\n",
      "Ledo: embeddings_lyricsbert_89000_89499.npy - Shape: (500, 300)\n",
      "Total: 179\n",
      "Ledo: embeddings_lyricsbert_89500_89999.npy - Shape: (500, 300)\n",
      "Total: 180\n",
      "Ledo: embeddings_lyricsbert_90000_90499.npy - Shape: (500, 300)\n",
      "Total: 181\n",
      "Ledo: embeddings_lyricsbert_90500_90999.npy - Shape: (500, 300)\n",
      "Total: 182\n",
      "Ledo: embeddings_lyricsbert_91000_91499.npy - Shape: (500, 300)\n",
      "Total: 183\n",
      "Ledo: embeddings_lyricsbert_91500_91999.npy - Shape: (500, 300)\n",
      "Total: 184\n",
      "Ledo: embeddings_lyricsbert_92000_92499.npy - Shape: (500, 300)\n",
      "Total: 185\n",
      "Ledo: embeddings_lyricsbert_92500_92999.npy - Shape: (500, 300)\n",
      "Total: 186\n",
      "Ledo: embeddings_lyricsbert_93000_93499.npy - Shape: (500, 300)\n",
      "Total: 187\n",
      "Ledo: embeddings_lyricsbert_93500_93999.npy - Shape: (500, 300)\n",
      "Total: 188\n",
      "Ledo: embeddings_lyricsbert_94000_94499.npy - Shape: (500, 300)\n",
      "Total: 189\n",
      "Ledo: embeddings_lyricsbert_94500_94999.npy - Shape: (500, 300)\n",
      "Total: 190\n",
      "Ledo: embeddings_lyricsbert_95000_95499.npy - Shape: (500, 300)\n",
      "Total: 191\n",
      "Ledo: embeddings_lyricsbert_95500_95999.npy - Shape: (500, 300)\n",
      "Total: 192\n",
      "Ledo: embeddings_lyricsbert_96000_96499.npy - Shape: (500, 300)\n",
      "Total: 193\n",
      "Ledo: embeddings_lyricsbert_96500_96999.npy - Shape: (500, 300)\n",
      "Total: 194\n",
      "Ledo: embeddings_lyricsbert_97000_97499.npy - Shape: (500, 300)\n",
      "Total: 195\n",
      "Ledo: embeddings_lyricsbert_97500_97999.npy - Shape: (500, 300)\n",
      "Total: 196\n",
      "Ledo: embeddings_lyricsbert_98000_98499.npy - Shape: (500, 300)\n",
      "Total: 197\n",
      "Ledo: embeddings_lyricsbert_98500_98999.npy - Shape: (500, 300)\n",
      "Total: 198\n",
      "Ledo: embeddings_lyricsbert_99000_99499.npy - Shape: (500, 300)\n",
      "Total: 199\n",
      "Ledo: embeddings_lyricsbert_99500_99999.npy - Shape: (500, 300)\n",
      "Total: 200\n",
      "Ledo: embeddings_lyricsbert_100000_100499.npy - Shape: (500, 300)\n",
      "Total: 201\n",
      "Ledo: embeddings_lyricsbert_100500_100999.npy - Shape: (500, 300)\n",
      "Total: 202\n",
      "Ledo: embeddings_lyricsbert_101000_101499.npy - Shape: (500, 300)\n",
      "Total: 203\n",
      "Ledo: embeddings_lyricsbert_101500_101999.npy - Shape: (500, 300)\n",
      "Total: 204\n",
      "Ledo: embeddings_lyricsbert_102000_102499.npy - Shape: (500, 300)\n",
      "Total: 205\n",
      "Ledo: embeddings_lyricsbert_102500_102999.npy - Shape: (500, 300)\n",
      "Total: 206\n",
      "Ledo: embeddings_lyricsbert_103000_103499.npy - Shape: (500, 300)\n",
      "Total: 207\n",
      "Ledo: embeddings_lyricsbert_103500_103999.npy - Shape: (500, 300)\n",
      "Total: 208\n",
      "Ledo: embeddings_lyricsbert_104000_104499.npy - Shape: (500, 300)\n",
      "Total: 209\n",
      "Ledo: embeddings_lyricsbert_104500_104999.npy - Shape: (500, 300)\n",
      "Total: 210\n",
      "Ledo: embeddings_lyricsbert_105000_105499.npy - Shape: (500, 300)\n",
      "Total: 211\n",
      "Ledo: embeddings_lyricsbert_105500_105999.npy - Shape: (500, 300)\n",
      "Total: 212\n",
      "Ledo: embeddings_lyricsbert_106000_106499.npy - Shape: (500, 300)\n",
      "Total: 213\n",
      "Ledo: embeddings_lyricsbert_106500_106999.npy - Shape: (500, 300)\n",
      "Total: 214\n",
      "Ledo: embeddings_lyricsbert_107000_107499.npy - Shape: (500, 300)\n",
      "Total: 215\n",
      "Ledo: embeddings_lyricsbert_107500_107999.npy - Shape: (500, 300)\n",
      "Total: 216\n",
      "Ledo: embeddings_lyricsbert_108000_108137.npy - Shape: (138, 300)\n",
      "Total: 217\n",
      "Shape final: (108138, 300)\n",
      "Embeddings guardados en: ../../data/embbedings_khipu/lb_khipu_A.npy\n"
     ]
    }
   ],
   "source": [
    "## Make fusion of the embeddings of example\n",
    "save_dir_df_npy = os.path.join(save_dir, \"lb_khipu_A.npy\")\n",
    "# print(os.listdir(save_dir))\n",
    "\n",
    "embbedings_df_npy =os.listdir(save_dir)\n",
    "\n",
    "def get_start_number(filename):\n",
    "    match = re.search(r'embeddings_lyricsbert_(\\d+)_\\d+\\.npy', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "embbedings_df_npy = sorted(embbedings_df_npy, key=get_start_number)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for embb in embbedings_df_npy:\n",
    "  if embb.endswith('.npy'):\n",
    "    # print(embb)\n",
    "    file_path = os.path.join(save_dir, embb)\n",
    "    embeddings = np.load(file_path)\n",
    "    all_embeddings.append(embeddings)\n",
    "    print(f\"Ledo: {embb} - Shape: {embeddings.shape}\")\n",
    "    print(f\"Total: {len(all_embeddings)}\")\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)\n",
    "print(\"Shape final:\", final_embeddings.shape)\n",
    "\n",
    "# Guardar en .npy\n",
    "np.save(save_dir_df_npy, final_embeddings)\n",
    "print(f\"Embeddings guardados en: {save_dir_df_npy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43fee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/embbedings_khipu\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_1000_1499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_500_999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_36500_36999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_45500_45999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_63000_63499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_26500_26999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_42000_42499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_63500_63999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_58000_58499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_86500_86999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_68000_68499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_60500_60999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_69000_69499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_83000_83499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_10000_10499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_52500_52999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_94000_94499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_6500_6999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_56000_56499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_25000_25499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_61000_61499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_4500_4999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_15500_15999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_12000_12499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_77500_77999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_44000_44499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_2500_2999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_7500_7999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_0_499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_23500_23999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_17500_17999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_95500_95999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_40500_40999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_15000_15499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_70000_70499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_101500_101999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_93500_93999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_84000_84499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_77000_77499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_17000_17499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_42500_42999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_33500_33999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_16000_16499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_31500_31999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_102000_102499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_67000_67499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_5500_5999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_74500_74999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_41000_41499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_26000_26499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_98000_98499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_46500_46999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_51000_51499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_81500_81999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_39500_39999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_74000_74499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_75000_75499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_53000_53499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_58500_58999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_3500_3999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_21000_21499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_10500_10999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_11500_11999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_82000_82499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_99500_99999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_23000_23499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_101000_101499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_8000_8499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_57500_57999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_104000_104499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_9000_9499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_84500_84999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_75500_75999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_73000_73499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_90000_90499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_66000_66499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_34500_34999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_32500_32999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_93000_93499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_65500_65999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_55500_55999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_70500_70999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_88000_88499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_86000_86499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_54500_54999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_1500_1999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_28000_28499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_108000_108137.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_24000_24499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_104500_104999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_81000_81499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_2000_2499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_83500_83999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_20000_20499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_9500_9999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_37500_37999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_79500_79999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_106000_106499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_87000_87499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_91000_91499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_72000_72499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_44500_44999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_36000_36499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_31000_31499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_14500_14999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_94500_94999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_100000_100499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_38500_38999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_28500_28999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_50000_50499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_76000_76499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_55000_55499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_49000_49499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_45000_45499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_29500_29999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_85500_85999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_30000_30499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_92500_92999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_64500_64999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_47500_47999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_27000_27499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_67500_67999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_90500_90999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_13000_13499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_96000_96499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_22500_22999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_54000_54499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_80500_80999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_51500_51999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_61500_61999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_88500_88999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_78500_78999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_68500_68999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_89000_89499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_64000_64499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_30500_30999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_43000_43499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_18500_18999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_100500_100999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_69500_69999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_72500_72999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_71000_71499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_19000_19499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_89500_89999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_46000_46499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_4000_4499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_22000_22499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_66500_66999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_59500_59999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_37000_37499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_29000_29499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_7000_7499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_8500_8999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_62500_62999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_25500_25999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_21500_21999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_96500_96999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_85000_85499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_97000_97499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_14000_14499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_106500_106999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_48500_48999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_35500_35999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_24500_24999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_11000_11499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_78000_78499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_107000_107499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_97500_97999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_103000_103499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_71500_71999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_53500_53999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_3000_3499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_49500_49999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_6000_6499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_19500_19999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_59000_59499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_48000_48499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_50500_50999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_105000_105499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_34000_34499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_91500_91999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_27500_27999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_52000_52499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_13500_13999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_16500_16999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_5000_5499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_80000_80499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_41500_41999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_47000_47499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_56500_56999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_33000_33499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_87500_87999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_92000_92499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_20500_20999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_105500_105999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_38000_38499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_12500_12999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_99000_99499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_32000_32499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_57000_57499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_65000_65499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_60000_60499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_40000_40499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_102500_102999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_35000_35499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_39000_39499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_76500_76999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_103500_103999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_82500_82999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_79000_79499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_43500_43999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_73500_73999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_107500_107999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_18000_18499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_95000_95499.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_98500_98999.npy\n",
      "../../data/embbedings_khipu/embeddings_lyricsbert_62000_62499.npy\n"
     ]
    }
   ],
   "source": [
    "#Delete the butches files\n",
    "\n",
    "dir_clean = save_dir\n",
    "print(dir_clean)\n",
    "\n",
    "butches_embb = os.listdir(dir_clean)\n",
    "\n",
    "for butch in butches_embb:\n",
    "    if butch != \"lb_khipu_A.npy\" and butch != \"lb_khipu.npy\"  :\n",
    "        # Delete \n",
    "        file_path = os.path.join(dir_clean, butch)\n",
    "        print(file_path)\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401a864",
   "metadata": {},
   "source": [
    "## 1) LB KHIPU VS LB COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ac4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son exactamente iguales? False\n",
      "Son prcticamente iguales (con tolerancia)? True\n"
     ]
    }
   ],
   "source": [
    "# colab_embbeding = np.load(path_lb_embb) \n",
    "# khipu_embbeding = np.load(\"../data/embbedings_khipu/lb_khipu.npy\") \n",
    "# are_equal = np.array_equal(colab_embbeding, khipu_embbeding)\n",
    "# print(\"Son exactamente iguales?\", are_equal)\n",
    "\n",
    "# are_close = np.allclose(colab_embbeding, khipu_embbeding, atol=1e-6)\n",
    "# print(\"Son prcticamente iguales (con tolerancia)?\", are_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97433f",
   "metadata": {},
   "source": [
    "Son iguales pero diferentes, con tol de e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a88cdd",
   "metadata": {},
   "source": [
    "## 2) Comparing df 1000 VS 1000 primeras filas de Colab an khipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b489aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88638c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 41)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# df_data = df_data[: 1000]\n",
    "# print(df_data.shape)\n",
    "# list_text  = df_data['text'].fillna(\"\").astype(str).tolist()\n",
    "# print(len(list_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05466d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0043, -0.2640, -0.0681,  ..., -0.1682, -0.0212, -0.0591],\n",
      "        [ 0.0013, -0.1634, -0.1466,  ..., -0.1082, -0.0870,  0.0344],\n",
      "        [ 0.0144,  0.0016,  0.0267,  ..., -0.1320, -0.0767, -0.0183],\n",
      "        ...,\n",
      "        [ 0.1645, -0.0803, -0.1348,  ..., -0.2597, -0.2391,  0.0845],\n",
      "        [ 0.1008, -0.1003,  0.0754,  ..., -0.1176, -0.1607,  0.1153],\n",
      "        [ 0.0109, -0.2829,  0.1105,  ..., -0.0596, -0.1596,  0.0998]])\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# #Mean Pooling - Take attention mask into account for correct averaging\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# # Sentences we want sentence embeddings for\n",
    "# sentences = list_text\n",
    "\n",
    "# # Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling. In this case, mean pooling.\n",
    "# sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ad4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son casi iguales con Khipu\n",
      "Son casi iguales con Colab\n"
     ]
    }
   ],
   "source": [
    "# colab_embbeding_first = colab_embbeding[:1000]\n",
    "# khipu_embbeding_first = khipu_embbeding[:1000]\n",
    "# are_close_khipu = np.allclose(khipu_embbeding_first, sentence_embeddings, atol=1e-7)\n",
    "# print(\"Son casi iguales con Khipu\" if are_close_khipu else \"Son diferentes\")\n",
    "\n",
    "# are_close_colab = np.allclose(colab_embbeding_first, sentence_embeddings, atol=1e-7)\n",
    "# print(\"Son casi iguales con Colab\" if are_close_colab else \"Son diferentes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28995990",
   "metadata": {},
   "source": [
    "Ahora con los 1000 ultimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 41)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# # Actualziar df_data skdjksl\n",
    "\n",
    "# df_data = pd.read_csv(path_dataset)\n",
    "# df_data =df_data[-1000:] \n",
    "# print(df_data.shape)\n",
    "# list_text_last  = df_data['text'].fillna(\"\").astype(str).tolist()\n",
    "# print(len(list_text_last))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbf23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# #Mean Pooling - Take attention mask into account for correct averaging\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# # Sentences we want sentence embeddings for\n",
    "# sentences = list_text_last\n",
    "\n",
    "# # Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling. In this case, mean pooling.\n",
    "# sentence_embeddings_last = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# # print(sentence_embeddings)\n",
    "\n",
    "# #               total        used        free      shared  buff/cache   available\n",
    "# # Mem:          1.0Ti        23Gi       820Gi       3.2Gi       163Gi       975Gi\n",
    "# # Swap:            0B          0B          0B\n",
    "# # [marcelino.maita@ds001 sanity_check]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5413129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108138, 300)\n",
      "(108138, 300)\n"
     ]
    }
   ],
   "source": [
    "# print(colab_embbeding.shape)\n",
    "# print(khipu_embbeding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son casi iguales con Khipu\n",
      "Son casi iguales con Colab\n"
     ]
    }
   ],
   "source": [
    "# colab_embbeding_last = colab_embbeding[-1000:]\n",
    "# khipu_embbeding_last = khipu_embbeding[-1000:]\n",
    "# are_close_khipu = np.allclose(khipu_embbeding_last, sentence_embeddings_last, atol=1e-7)\n",
    "# print(\"Son casi iguales con Khipu\" if are_close_khipu else \"Son diferentes\")\n",
    "\n",
    "# are_close_colab = np.allclose(colab_embbeding_last, sentence_embeddings_last, atol=1e-7)\n",
    "# print(\"Son casi iguales con Colab\" if are_close_colab else \"Son diferentes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fba681",
   "metadata": {},
   "source": [
    "En resumen son iguales con almenos tolerancia de 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
