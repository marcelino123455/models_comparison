{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b069e46b",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997792f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T03:35:49.239929Z",
     "iopub.status.busy": "2025-08-10T03:35:49.239705Z",
     "iopub.status.idle": "2025-08-10T03:35:49.695100Z",
     "shell.execute_reply": "2025-08-10T03:35:49.694630Z"
    },
    "papermill": {
     "duration": 0.461733,
     "end_time": "2025-08-10T03:35:49.696323",
     "exception": false,
     "start_time": "2025-08-10T03:35:49.234590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3dda3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T03:35:49.705332Z",
     "iopub.status.busy": "2025-08-10T03:35:49.704482Z",
     "iopub.status.idle": "2025-08-10T03:35:49.708081Z",
     "shell.execute_reply": "2025-08-10T03:35:49.707706Z"
    },
    "papermill": {
     "duration": 0.008864,
     "end_time": "2025-08-10T03:35:49.708996",
     "exception": false,
     "start_time": "2025-08-10T03:35:49.700132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH =\"../../data\"\n",
    "\n",
    "path_lb_embb = os.path.join(DATA_PATH, \"lb_npy.npy\")\n",
    "path_dataset = os.path.join(DATA_PATH, \"spotify_dataset_sin_duplicados_4.csv\")\n",
    "# print(os.listdir(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d4920",
   "metadata": {
    "papermill": {
     "duration": 0.003321,
     "end_time": "2025-08-10T03:35:49.715793",
     "exception": false,
     "start_time": "2025-08-10T03:35:49.712472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Revisando que sean embbedings iguales en khipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa34f5",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b21a506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T03:35:49.723045Z",
     "iopub.status.busy": "2025-08-10T03:35:49.722653Z",
     "iopub.status.idle": "2025-08-10T03:36:06.333127Z",
     "shell.execute_reply": "2025-08-10T03:36:06.331406Z"
    },
    "papermill": {
     "duration": 16.614884,
     "end_time": "2025-08-10T03:36:06.333837",
     "exception": true,
     "start_time": "2025-08-10T03:35:49.718953",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 8.5982e-02, -1.9938e-01,  3.1403e-01, -2.1909e-01, -3.9347e-04,\n",
      "          2.8418e-01,  1.1639e+00, -2.5347e-01, -5.9031e-01,  2.8978e-01,\n",
      "         -4.3361e-01,  2.6265e-01,  1.2186e-02, -2.1822e-01,  1.0540e-01,\n",
      "          1.8403e-01,  5.8598e-01, -1.6739e-01, -2.6611e-01,  3.8995e-01,\n",
      "         -1.9267e-01,  3.5165e-01,  5.3251e-01,  4.8379e-01,  5.9596e-01,\n",
      "         -1.0685e+00,  3.0516e-01, -4.1388e-01,  3.8347e-01, -3.3050e-01,\n",
      "         -3.3174e-01,  4.0777e-01,  1.8344e-01, -2.9582e-01, -1.4029e-01,\n",
      "         -4.2408e-01,  2.6159e-01, -2.7347e-01, -7.7970e-02, -3.2933e-01,\n",
      "          3.9029e-01,  8.3547e-02,  1.7815e-01, -4.2287e-01,  2.5291e-02,\n",
      "          5.4537e-01, -3.9749e-01,  1.0715e-01, -1.1429e+00,  4.7099e-01,\n",
      "          2.0548e-01,  1.8556e-01, -3.1428e-01,  6.5785e-01,  2.4795e-01,\n",
      "          5.3135e-01, -1.9034e-01,  3.3224e-01,  4.9253e-01, -1.7496e-02,\n",
      "          4.9282e-01,  5.9564e-01,  2.2089e-01,  1.9639e-01, -1.7313e-01,\n",
      "         -2.4567e-01, -2.8542e-01, -1.4741e-01, -1.7384e-02,  3.5515e-01,\n",
      "         -8.3135e-02, -6.3132e-02,  2.9226e-01,  6.3939e-01, -2.9777e-01,\n",
      "         -9.7521e-02, -6.0739e-02,  2.5673e-01, -3.0768e-01, -2.2224e-01,\n",
      "         -2.5321e-01,  3.4734e-01,  1.0203e+00,  1.9196e-01, -9.1606e-02,\n",
      "         -4.5693e-01,  3.3026e-01, -2.2074e-01, -6.0526e-02,  3.9479e-01,\n",
      "         -2.7525e-01,  6.0574e-01, -9.6178e-03, -2.3490e-01,  3.3226e-01,\n",
      "         -2.9552e-01, -1.8357e-01,  3.3977e-01, -3.9793e-01,  2.8528e-01,\n",
      "         -9.7769e-02,  1.8406e-01,  2.3932e-01, -2.5663e-01,  1.2102e-01,\n",
      "         -1.1334e-01, -4.7447e-01,  5.8402e-01, -5.0222e-01,  5.5676e-02,\n",
      "         -2.3052e-01, -1.7998e-01, -2.4742e-01,  4.9252e-01, -3.1728e-01,\n",
      "         -3.8005e-01, -3.6834e-02,  6.1935e-01,  4.5879e-01, -1.1285e-02,\n",
      "         -8.1743e-01, -1.5657e-01, -2.2445e-01,  2.6995e-02,  6.0124e-01,\n",
      "          4.5618e-01,  5.0829e-01, -4.4134e-02, -6.2951e-01,  5.7058e-02,\n",
      "         -3.2004e-01,  8.4487e-01, -4.1202e-01, -9.3632e-02, -3.3231e-01,\n",
      "          8.0646e-02, -9.0269e-02, -7.9957e-02,  1.5627e-01, -2.4454e-01,\n",
      "         -7.8198e-02, -7.3007e-01,  3.4790e-01, -7.0381e-02,  2.4043e-01,\n",
      "         -3.9198e-01, -3.3993e-01, -2.2476e-01,  1.6756e-01,  6.1990e-01,\n",
      "          1.6506e-01, -1.7112e-02, -2.6266e-01, -4.4491e-01,  8.5385e-02,\n",
      "         -1.0234e+00,  1.4751e-02,  6.6274e-01,  7.9915e-02, -3.5930e-01,\n",
      "          1.5881e-01, -3.4966e-01, -2.2996e-03, -4.9989e-01, -2.3276e-01,\n",
      "          2.5108e-01, -1.6013e-01,  3.0339e-02,  1.2239e-01,  2.2526e-01,\n",
      "         -5.7139e-01,  1.5721e-01,  4.0606e-01,  5.2835e-01,  4.1934e-01,\n",
      "         -9.2094e-02, -1.8845e-01,  4.0464e-01, -3.8726e-01,  2.7759e-02,\n",
      "          3.4773e-01, -7.7780e-02,  3.8785e-01,  8.1375e-02,  1.4306e-01,\n",
      "          3.7101e-01, -3.4955e-01,  9.9817e-02, -4.5038e-02,  4.2395e-02,\n",
      "         -5.4337e-01, -5.7880e-03,  3.9858e-02, -2.4195e-01, -1.8601e-01,\n",
      "         -6.1422e-02, -2.0549e-01,  9.6923e-01, -4.1731e-01,  2.2264e-01,\n",
      "          9.8880e-02, -5.0703e-01,  4.4393e-02, -8.6652e-01,  2.2599e-01,\n",
      "          1.9653e-01, -7.9508e-02,  1.0202e-01, -3.3823e-01, -6.1861e-01,\n",
      "          2.5656e-01, -6.1935e-01,  1.5115e-01,  7.1349e-02, -1.6747e-02,\n",
      "          2.9823e-01, -4.8073e-01,  3.7778e-01, -1.0376e+00, -6.7299e-01,\n",
      "         -1.9395e-01, -4.9116e-01, -1.5958e-01, -1.7036e-01, -3.5001e-03,\n",
      "         -1.2437e-01, -2.7077e-01,  9.6722e-02,  1.9883e-01,  1.9982e-01,\n",
      "         -2.2514e-01,  1.4580e-01,  7.6273e-02,  2.7559e-01, -3.4379e-01,\n",
      "          3.3641e-01, -3.7492e-01,  6.8472e-02,  7.1614e-01, -8.7140e-01,\n",
      "         -1.3807e-01,  3.7063e-01, -7.8194e-02,  3.6888e-01, -2.4814e-01,\n",
      "          2.4197e-01,  2.3086e-01,  6.3857e-01,  2.2130e-02, -4.1341e-01,\n",
      "         -2.2392e-01, -4.3592e-01,  7.5251e-02, -2.5254e-01, -2.5270e-01,\n",
      "          5.2911e-01, -4.9042e-01,  9.3977e-02,  7.0798e-01,  1.1315e-01,\n",
      "         -1.2777e-01, -5.3069e-01,  2.5840e-01, -5.4220e-01,  3.6502e-01,\n",
      "         -1.7641e-01, -5.5217e-01, -3.2474e-01,  2.6816e-01,  6.9207e-02,\n",
      "         -1.3044e-01, -1.6432e-01, -7.7984e-02, -4.3597e-01,  5.2860e-01,\n",
      "         -4.4020e-01,  6.3608e-01, -1.8013e-01,  1.0452e-01,  9.2711e-02,\n",
      "          2.8882e-01, -3.7297e-01,  1.1613e-01,  1.4239e-01,  1.2496e-01,\n",
      "          4.6682e-01, -2.6213e-01, -1.8380e-01,  3.8388e-02,  2.7842e-01,\n",
      "          3.8825e-01,  9.9131e-02,  3.6541e-01,  2.2169e-01, -6.4273e-02,\n",
      "         -1.4846e-01, -3.8930e-01,  4.1290e-02, -1.4719e-01,  1.7134e-01],\n",
      "        [-1.8556e-01, -2.3414e-01,  6.9767e-01, -5.9317e-01,  4.1742e-02,\n",
      "          6.4290e-01,  7.2030e-01, -2.7653e-02, -2.8739e-01,  1.5241e-01,\n",
      "         -4.2843e-01,  9.2531e-02,  4.7558e-02, -3.9465e-01,  5.5514e-02,\n",
      "         -5.1168e-02,  4.3439e-01,  2.2112e-01,  3.6437e-02,  8.2028e-03,\n",
      "         -2.4122e-01,  8.6939e-02, -1.5564e-01,  5.8968e-01,  8.5847e-02,\n",
      "         -7.4826e-01, -1.6808e-01, -5.1483e-01,  2.0089e-01, -8.9687e-01,\n",
      "         -8.7315e-02, -3.0170e-02,  4.4630e-01, -9.3042e-02,  1.7543e-01,\n",
      "          6.9105e-02, -2.1615e-01,  2.7740e-01, -2.8637e-01, -5.3099e-01,\n",
      "         -3.4070e-01,  2.9618e-02,  1.1835e-02, -4.3073e-01, -3.9812e-01,\n",
      "          2.5667e-01,  5.8097e-02,  6.5925e-02, -5.1549e-01,  3.6404e-01,\n",
      "         -5.0626e-02,  5.8025e-01, -2.9077e-02,  1.2362e-01,  3.2774e-01,\n",
      "          4.7578e-01, -2.3779e-01,  1.0257e-01,  3.0880e-01, -7.6611e-02,\n",
      "          6.5769e-02,  3.0900e-01,  6.0790e-01,  2.2069e-01,  1.1033e-01,\n",
      "         -3.1599e-01, -1.4517e-01, -1.7289e-01, -5.1651e-01, -2.2595e-01,\n",
      "          3.5468e-01, -3.5386e-01,  2.2534e-01,  3.2495e-01, -4.6008e-01,\n",
      "         -1.3179e-01, -4.1913e-01,  3.8582e-01, -3.3780e-01,  4.6620e-02,\n",
      "         -2.2575e-01, -3.1442e-02,  8.1278e-01,  3.8404e-01,  3.6150e-01,\n",
      "         -1.9062e-01,  8.8800e-02, -1.4353e-01,  2.9068e-01, -2.3676e-03,\n",
      "         -2.8496e-01,  3.9493e-01,  1.0401e-01,  2.2580e-01,  1.0948e-02,\n",
      "         -2.6930e-01, -2.8779e-01,  1.9514e-02, -2.8700e-01, -4.0525e-01,\n",
      "          2.3328e-02,  9.6536e-02, -2.7494e-01,  1.4102e-01,  6.4354e-03,\n",
      "         -2.3677e-02, -4.6965e-01,  4.8585e-01, -1.6564e-01, -8.3012e-02,\n",
      "         -4.7720e-01, -1.9912e-01, -5.9300e-01,  1.9116e-01,  8.5618e-03,\n",
      "          9.5205e-02, -2.0540e-01,  2.7894e-01,  1.4698e-01, -9.5836e-02,\n",
      "         -4.2669e-01, -2.4652e-01, -5.3677e-02, -3.1679e-01,  5.4954e-01,\n",
      "          4.1546e-01,  1.4417e-01, -2.5318e-01, -1.1009e-01, -6.7664e-02,\n",
      "          4.5918e-02,  4.1470e-01, -1.2796e-01,  1.5244e-01, -1.6676e-01,\n",
      "         -9.3694e-02,  2.7664e-01, -5.0372e-02,  2.8108e-01, -1.3317e-02,\n",
      "          4.6536e-02, -9.3524e-01,  7.5057e-01, -9.7263e-02,  1.2152e-01,\n",
      "         -1.9416e-01,  3.8080e-02, -2.7422e-01,  4.6427e-01,  7.7246e-01,\n",
      "          1.7658e-01,  2.1876e-01, -3.8301e-02, -1.0317e+00,  1.7213e-01,\n",
      "         -3.1510e-01, -2.4518e-02,  9.2497e-01,  7.5101e-02, -3.5740e-02,\n",
      "          1.4949e-01, -1.5926e-01,  5.6959e-02, -3.8221e-01, -3.0832e-01,\n",
      "          1.2010e-01,  8.1529e-02, -4.9017e-01,  1.6145e-01, -4.7504e-02,\n",
      "         -1.3135e-01,  3.6154e-01,  3.8953e-01,  2.8907e-01,  3.0981e-01,\n",
      "          5.6216e-01,  3.0213e-01,  7.4494e-02, -1.9247e-01,  4.7317e-02,\n",
      "         -2.0462e-01,  1.1924e-01,  4.0228e-01, -4.4200e-01, -2.8812e-01,\n",
      "          3.7329e-01, -1.8125e-01,  4.3832e-01,  6.0617e-02,  7.1732e-02,\n",
      "         -3.1154e-01, -7.6242e-01, -1.6706e-01, -1.8356e-01,  2.2914e-01,\n",
      "         -5.5761e-02, -2.0641e-01,  6.7781e-01, -3.2683e-01, -3.0420e-01,\n",
      "          5.0281e-02, -4.1753e-01,  1.5901e-01, -6.1253e-01,  1.8099e-01,\n",
      "          3.7711e-01, -6.6657e-02, -1.9884e-01, -5.9226e-01, -7.5436e-02,\n",
      "          5.8123e-01, -5.4815e-01,  7.6522e-01, -2.5977e-01,  2.3490e-01,\n",
      "          2.5078e-01, -1.1813e-01,  2.2829e-01, -8.1220e-01, -7.3786e-01,\n",
      "         -2.7705e-01, -1.0638e-01, -2.7551e-01, -2.1730e-01,  6.9398e-02,\n",
      "          2.9412e-01,  2.9370e-01,  2.1655e-01,  4.2540e-01, -6.4420e-03,\n",
      "         -2.5713e-01, -5.3957e-02,  1.5795e-01, -5.6318e-01, -8.5588e-02,\n",
      "          7.2471e-01,  4.0842e-01, -2.0714e-01,  4.5418e-01, -3.4961e-01,\n",
      "          2.9817e-01,  3.5192e-01,  1.1789e-03,  4.2360e-01,  1.2787e-01,\n",
      "          1.0356e-01, -5.1026e-01,  6.7822e-01,  3.0800e-01, -4.8840e-01,\n",
      "         -3.6930e-01, -6.3272e-01, -3.1579e-03, -1.9691e-01, -3.7475e-01,\n",
      "          2.9680e-01, -8.5276e-01, -1.3666e-01,  4.4409e-01, -4.2051e-02,\n",
      "          3.3312e-02, -3.6514e-02, -1.7959e-01, -3.1418e-01,  3.7233e-01,\n",
      "         -4.4793e-03, -1.2049e-01, -2.3109e-01,  7.4618e-02, -6.2734e-01,\n",
      "          3.8622e-01,  6.3858e-02, -2.8429e-02, -4.7838e-01,  8.1511e-01,\n",
      "         -4.1438e-01,  2.2357e-01,  2.1366e-01, -1.7401e-01, -1.7124e-01,\n",
      "          3.2326e-01,  5.0160e-02, -2.6319e-01, -3.1630e-03, -5.4008e-01,\n",
      "          2.1738e-01,  2.8207e-01, -3.4864e-01,  6.6520e-02,  3.9670e-01,\n",
      "          8.0074e-01, -3.7280e-02,  3.5032e-01,  4.8999e-01,  1.9968e-01,\n",
      "          1.8769e-01, -4.4721e-01,  9.2358e-02,  6.3430e-02,  3.7120e-01]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "MODEL_NAME = 'brunokreiner/lyrics-bert'\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1717d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500 # Porque nos quedamos sin RAM :(\n",
    "INIT = 0\n",
    "# TOTAL_ROWS = 108138\n",
    "TOTAL_ROWS = 1000\n",
    "\n",
    "# To save vectors\n",
    "# save_dir = \"/content/drive/MyDrive/embeddings_lyricsbert_to_fusion/\"\n",
    "save_dir = os.path.join(DATA_PATH, \"embbedings_khipu\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# start = 0\n",
    "# end = 5000\n",
    "# ROWS = end - start\n",
    "A = ['text', 'song', 'Artist(s)', 'Album', 'Similar Artist 1', 'Genre']\n",
    "\n",
    "\n",
    "for start in range(INIT, TOTAL_ROWS, BATCH_SIZE):\n",
    "  end = min(start + BATCH_SIZE, TOTAL_ROWS)\n",
    "  print(f\"\\nProcesando filas {start} a {end-1}...\")\n",
    "  df = pd.read_csv(path_dataset, skiprows=range(1, start + 1), nrows=end - start)\n",
    "  \n",
    "  df['combined_text'] = df[A].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "  df_sentences = df['combined_text'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "  print(\"shape de sentences: \", len(df_sentences))\n",
    "\n",
    "  # Tokenize input\n",
    "  start_time = time.time()\n",
    "\n",
    "  encoded_df_input = tokenizer(df_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "  # Compute embeddings\n",
    "  with torch.no_grad():\n",
    "      model_output = model(**encoded_df_input)\n",
    "\n",
    "  # Pooling (mean)\n",
    "  sentence_df_embeddings = mean_pooling(model_output, encoded_df_input['attention_mask'])\n",
    "\n",
    "\n",
    "\n",
    "  # Print results\n",
    "  end_time = time.time()\n",
    "  print(f\"\\nTiempo total: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "  print(\"Iniciando guardado de los vectores: \")\n",
    "  embeddings_np = sentence_df_embeddings.numpy()\n",
    "\n",
    "  # Guardar en formato binario .npy\n",
    "  npy_filename = f\"embeddings_lyricsbert_{start}_{end-1}.npy\"\n",
    "  np.save(os.path.join(save_dir, npy_filename), embeddings_np)\n",
    "\n",
    "  # # Guardar en CSV\n",
    "  # csv_filename = f\"embeddings_lyricsbert_{start}_{end-1}.csv\"\n",
    "  # np.savetxt(os.path.join(save_dir, csv_filename), embeddings_np, delimiter=\",\")\n",
    "  print(\"Sentence embeddings:\")\n",
    "  # print(sentence_df_embeddings)\n",
    "  print(sentence_df_embeddings.shape)\n",
    "  print(f\"Guardado batch {start}-{end-1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484f9f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Make fusion of the embeddings of example\n",
    "save_dir_df_npy = os.path.join(save_dir, \"lb_khipu_A.npy\")\n",
    "# print(os.listdir(save_dir))\n",
    "\n",
    "embbedings_df_npy =os.listdir(save_dir)\n",
    "\n",
    "def get_start_number(filename):\n",
    "    match = re.search(r'embeddings_lyricsbert_(\\d+)_\\d+\\.npy', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "embbedings_df_npy = sorted(embbedings_df_npy, key=get_start_number)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for embb in embbedings_df_npy:\n",
    "  if embb.endswith('.npy'):\n",
    "    # print(embb)\n",
    "    file_path = os.path.join(save_dir, embb)\n",
    "    embeddings = np.load(file_path)\n",
    "    all_embeddings.append(embeddings)\n",
    "    print(f\"Leído: {embb} - Shape: {embeddings.shape}\")\n",
    "    print(f\"Total: {len(all_embeddings)}\")\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)\n",
    "print(\"Shape final:\", final_embeddings.shape)\n",
    "\n",
    "# Guardar en .npy\n",
    "np.save(save_dir_df_npy, final_embeddings)\n",
    "print(f\"Embeddings guardados en: {save_dir_df_npy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fee93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Delete the butches files\n",
    "\n",
    "dir_clean = save_dir\n",
    "print(dir_clean)\n",
    "\n",
    "butches_embb = os.listdir(dir_clean)\n",
    "\n",
    "for butch in butches_embb:\n",
    "    if butch != \"lb_khipu_A.npy\":\n",
    "        # Delete \n",
    "        file_path = os.path.join(dir_clean, butch)\n",
    "        print(file_path)\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401a864",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1) LB KHIPU VS LB COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ac4a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colab_embbeding = np.load(path_lb_embb) \n",
    "# khipu_embbeding = np.load(\"../data/embbedings_khipu/lb_khipu.npy\") \n",
    "# are_equal = np.array_equal(colab_embbeding, khipu_embbeding)\n",
    "# print(\"¿Son exactamente iguales?\", are_equal)\n",
    "\n",
    "# are_close = np.allclose(colab_embbeding, khipu_embbeding, atol=1e-6)\n",
    "# print(\"¿Son prácticamente iguales (con tolerancia)?\", are_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97433f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Son iguales pero diferentes, con tol de e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a88cdd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2) Comparing df 1000 VS 1000 primeras filas de Colab an khipu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b489aa6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88638c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_data = df_data[: 1000]\n",
    "# print(df_data.shape)\n",
    "# list_text  = df_data['text'].fillna(\"\").astype(str).tolist()\n",
    "# print(len(list_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05466d26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# #Mean Pooling - Take attention mask into account for correct averaging\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# # Sentences we want sentence embeddings for\n",
    "# sentences = list_text\n",
    "\n",
    "# # Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling. In this case, mean pooling.\n",
    "# sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ad4b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colab_embbeding_first = colab_embbeding[:1000]\n",
    "# khipu_embbeding_first = khipu_embbeding[:1000]\n",
    "# are_close_khipu = np.allclose(khipu_embbeding_first, sentence_embeddings, atol=1e-7)\n",
    "# print(\"Son casi iguales con Khipu\" if are_close_khipu else \"Son diferentes\")\n",
    "\n",
    "# are_close_colab = np.allclose(colab_embbeding_first, sentence_embeddings, atol=1e-7)\n",
    "# print(\"Son casi iguales con Colab\" if are_close_colab else \"Son diferentes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28995990",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Ahora con los 1000 ultimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2d094",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Actualziar df_data skdjksl\n",
    "\n",
    "# df_data = pd.read_csv(path_dataset)\n",
    "# df_data =df_data[-1000:] \n",
    "# print(df_data.shape)\n",
    "# list_text_last  = df_data['text'].fillna(\"\").astype(str).tolist()\n",
    "# print(len(list_text_last))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbf23a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# #Mean Pooling - Take attention mask into account for correct averaging\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# # Sentences we want sentence embeddings for\n",
    "# sentences = list_text_last\n",
    "\n",
    "# # Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Tokenize sentences\n",
    "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Compute token embeddings\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Perform pooling. In this case, mean pooling.\n",
    "# sentence_embeddings_last = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# print(\"Sentence embeddings:\")\n",
    "# # print(sentence_embeddings)\n",
    "\n",
    "# #               total        used        free      shared  buff/cache   available\n",
    "# # Mem:          1.0Ti        23Gi       820Gi       3.2Gi       163Gi       975Gi\n",
    "# # Swap:            0B          0B          0B\n",
    "# # [marcelino.maita@ds001 sanity_check]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5413129",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(colab_embbeding.shape)\n",
    "# print(khipu_embbeding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca9f56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colab_embbeding_last = colab_embbeding[-1000:]\n",
    "# khipu_embbeding_last = khipu_embbeding[-1000:]\n",
    "# are_close_khipu = np.allclose(khipu_embbeding_last, sentence_embeddings_last, atol=1e-7)\n",
    "# print(\"Son casi iguales con Khipu\" if are_close_khipu else \"Son diferentes\")\n",
    "\n",
    "# are_close_colab = np.allclose(colab_embbeding_last, sentence_embeddings_last, atol=1e-7)\n",
    "# print(\"Son casi iguales con Colab\" if are_close_colab else \"Son diferentes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fba681",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "En resumen son iguales con almenos tolerancia de 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.22828,
   "end_time": "2025-08-10T03:36:08.056632",
   "environment_variables": {},
   "exception": true,
   "input_path": "checking_LB_embb.ipynb",
   "output_path": "ejecutado_DT_20250809_223547.ipynb",
   "parameters": {},
   "start_time": "2025-08-10T03:35:47.828352",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
