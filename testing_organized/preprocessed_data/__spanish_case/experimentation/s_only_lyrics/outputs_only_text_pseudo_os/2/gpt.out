2025-10-30 04:16:29.414470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-30 04:16:29.414470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
For TF-IDF embbedings you are selecteing this columns:
--> ['lyrics']
Your are not adding cols numercis
You are executing with [ALL] dataset
--> PaTH:  ../../../../../data/spanish/LB_T/LB_fuss/lb_khipu_T.npy

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../../../../data/spanish/dataset/oficialDatasetEAIM2026_pseudolabeling.csv
Label distribution: {False: 6765, True: 554}
X shape: (7319, 1536)
y shape: (7319,)

Data con el spliting...
Label distribution en TRAIN: {0: 5412, 1: 443}
Label distribution en TEST: {0: 1353, 1: 111}




Aplicando SMOTE oversampling...
Nueva distribución de clases: {0: 5412, 1: 5412}
Resultados con MLP

Entrenando red 1 con capas [1536, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5418, Test Loss: 0.4301, F1: 0.3981, AUC: 0.8677
Epoch [10/30] Train Loss: 0.2484, Test Loss: 0.4480, F1: 0.4172, AUC: 0.8954
Epoch [20/30] Train Loss: 0.2054, Test Loss: 0.2354, F1: 0.5091, AUC: 0.8916
Mejores resultados en la época:  14
f1-score 0.5161290322580645
AUC según el mejor F1-score 0.8938162108893817
Confusion Matrix:
 [[1257   96]
 [  39   72]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9078
Precision:  0.4286
Recall:     0.6486
F1-score:   0.5161

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5229, Test Loss: 0.5058, F1: 0.3483, AUC: 0.8678
Epoch [10/30] Train Loss: 0.2483, Test Loss: 0.2730, F1: 0.4906, AUC: 0.8934
Epoch [20/30] Train Loss: 0.2075, Test Loss: 0.2536, F1: 0.4930, AUC: 0.8883
Mejores resultados en la época:  7
f1-score 0.5080645161290323
AUC según el mejor F1-score 0.8941757722245527
Confusion Matrix:
 [[1279   74]
 [  48   63]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9167
Precision:  0.4599
Recall:     0.5676
F1-score:   0.5081

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.4729, Test Loss: 0.5393, F1: 0.3451, AUC: 0.8757
Epoch [10/30] Train Loss: 0.2310, Test Loss: 0.3072, F1: 0.4762, AUC: 0.8927
Epoch [20/30] Train Loss: 0.1974, Test Loss: 0.5018, F1: 0.3991, AUC: 0.8883
Mejores resultados en la época:  2
f1-score 0.5103448275862069
AUC según el mejor F1-score 0.8900408168700851
Confusion Matrix:
 [[1248  105]
 [  37   74]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9030
Precision:  0.4134
Recall:     0.6667
F1-score:   0.5103

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5213, Test Loss: 0.3753, F1: 0.4353, AUC: 0.8672
Epoch [10/30] Train Loss: 0.2540, Test Loss: 0.3349, F1: 0.4659, AUC: 0.8934
Epoch [20/30] Train Loss: 0.2194, Test Loss: 0.3095, F1: 0.4734, AUC: 0.8889
Mejores resultados en la época:  17
f1-score 0.5020242914979757
AUC según el mejor F1-score 0.8901540121052316
Confusion Matrix:
 [[1279   74]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9160
Precision:  0.4559
Recall:     0.5586
F1-score:   0.5020
Tiempo total para red 1: 69.92 segundos

Entrenando red 2 con capas [1536, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4827, Test Loss: 0.4682, F1: 0.3682, AUC: 0.8761
Epoch [10/30] Train Loss: 0.2254, Test Loss: 0.2792, F1: 0.4788, AUC: 0.8926
Epoch [20/30] Train Loss: 0.1690, Test Loss: 0.5212, F1: 0.3857, AUC: 0.8875
Mejores resultados en la época:  18
f1-score 0.5188284518828452
AUC según el mejor F1-score 0.8903604269457929
Confusion Matrix:
 [[1287   66]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9214
Precision:  0.4844
Recall:     0.5586
F1-score:   0.5188

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4781, Test Loss: 0.3825, F1: 0.4194, AUC: 0.8767
Epoch [10/30] Train Loss: 0.2301, Test Loss: 0.5803, F1: 0.3673, AUC: 0.8917
Epoch [20/30] Train Loss: 0.1684, Test Loss: 0.2560, F1: 0.5038, AUC: 0.8883
Mejores resultados en la época:  5
f1-score 0.5119453924914675
AUC según el mejor F1-score 0.8946551873381141
Confusion Matrix:
 [[1246  107]
 [  36   75]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9023
Precision:  0.4121
Recall:     0.6757
F1-score:   0.5119

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4786, Test Loss: 0.3709, F1: 0.4323, AUC: 0.8776
Epoch [10/30] Train Loss: 0.2254, Test Loss: 0.2306, F1: 0.5094, AUC: 0.8935
Epoch [20/30] Train Loss: 0.1958, Test Loss: 0.3568, F1: 0.4375, AUC: 0.8906
Mejores resultados en la época:  17
f1-score 0.5267857142857143
AUC según el mejor F1-score 0.8915855989026721
Confusion Matrix:
 [[1299   54]
 [  52   59]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9276
Precision:  0.5221
Recall:     0.5315
F1-score:   0.5268

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4560, Test Loss: 0.2375, F1: 0.4794, AUC: 0.8782
Epoch [10/30] Train Loss: 0.2333, Test Loss: 0.3422, F1: 0.4562, AUC: 0.8923
Epoch [20/30] Train Loss: 0.1760, Test Loss: 0.3185, F1: 0.4593, AUC: 0.8897
Mejores resultados en la época:  5
f1-score 0.5232974910394266
AUC según el mejor F1-score 0.895181212254383
Confusion Matrix:
 [[1258   95]
 [  38   73]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9092
Precision:  0.4345
Recall:     0.6577
F1-score:   0.5233
Tiempo total para red 2: 80.24 segundos

Entrenando red 3 con capas [1536, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4718, Test Loss: 0.4895, F1: 0.3770, AUC: 0.8793
Epoch [10/30] Train Loss: 0.2227, Test Loss: 0.2830, F1: 0.4875, AUC: 0.8917
Epoch [20/30] Train Loss: 0.1859, Test Loss: 0.3326, F1: 0.4678, AUC: 0.8907
Mejores resultados en la época:  11
f1-score 0.5242718446601942
AUC según el mejor F1-score 0.8910529154431593
Confusion Matrix:
 [[1312   41]
 [  57   54]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9331
Precision:  0.5684
Recall:     0.4865
F1-score:   0.5243

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4724, Test Loss: 0.2554, F1: 0.4966, AUC: 0.8777
Epoch [10/30] Train Loss: 0.2195, Test Loss: 0.2398, F1: 0.5128, AUC: 0.8912
Epoch [20/30] Train Loss: 0.2140, Test Loss: 0.3326, F1: 0.4346, AUC: 0.8896
Mejores resultados en la época:  6
f1-score 0.5254237288135594
AUC según el mejor F1-score 0.8938694792353329
Confusion Matrix:
 [[1290   63]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9235
Precision:  0.4960
Recall:     0.5586
F1-score:   0.5254

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4474, Test Loss: 0.6295, F1: 0.3261, AUC: 0.8832
Epoch [10/30] Train Loss: 0.2141, Test Loss: 0.2491, F1: 0.5035, AUC: 0.8905
Epoch [20/30] Train Loss: 0.1778, Test Loss: 0.2705, F1: 0.5018, AUC: 0.8890
Mejores resultados en la época:  13
f1-score 0.5161290322580645
AUC según el mejor F1-score 0.8909996470972081
Confusion Matrix:
 [[1257   96]
 [  39   72]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9078
Precision:  0.4286
Recall:     0.6486
F1-score:   0.5161

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4765, Test Loss: 0.2053, F1: 0.4434, AUC: 0.8808
Epoch [10/30] Train Loss: 0.2243, Test Loss: 0.2740, F1: 0.4907, AUC: 0.8933
Epoch [20/30] Train Loss: 0.1882, Test Loss: 0.2391, F1: 0.5259, AUC: 0.8871
Mejores resultados en la época:  13
f1-score 0.5283018867924528
AUC según el mejor F1-score 0.8902538902538902
Confusion Matrix:
 [[1269   84]
 [  41   70]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9146
Precision:  0.4545
Recall:     0.6306
F1-score:   0.5283
For TF-IDF embbedings you are selecteing this columns:
--> ['lyrics']
Your are not adding cols numercis
You are executing with [ALL] dataset
--> PaTH:  ../../../../../data/spanish/LB_T/LB_fuss/lb_khipu_T.npy

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../../../../data/spanish/dataset/oficialDatasetEAIM2026_pseudolabeling.csv
Label distribution: {False: 6765, True: 554}
X shape: (7319, 1536)
y shape: (7319,)

Data con el spliting...
Label distribution en TRAIN: {0: 5412, 1: 443}
Label distribution en TEST: {0: 1353, 1: 111}




Aplicando SMOTE oversampling...
Nueva distribución de clases: {0: 5412, 1: 5412}
Resultados con MLP

Entrenando red 1 con capas [1536, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.4920, Test Loss: 0.3796, F1: 0.4260, AUC: 0.8727
Epoch [10/30] Train Loss: 0.2369, Test Loss: 0.2709, F1: 0.4936, AUC: 0.8925
Epoch [20/30] Train Loss: 0.2090, Test Loss: 0.2196, F1: 0.5000, AUC: 0.8882
Mejores resultados en la época:  12
f1-score 0.5128205128205128
AUC según el mejor F1-score 0.8910928667026228
Confusion Matrix:
 [[1290   63]
 [  51   60]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9221
Precision:  0.4878
Recall:     0.5405
F1-score:   0.5128

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.4919, Test Loss: 0.4199, F1: 0.3972, AUC: 0.8717
Epoch [10/30] Train Loss: 0.2368, Test Loss: 0.3625, F1: 0.4526, AUC: 0.8940
Epoch [20/30] Train Loss: 0.1951, Test Loss: 0.2766, F1: 0.4823, AUC: 0.8906
Mejores resultados en la época:  26
f1-score 0.5093632958801498
AUC según el mejor F1-score 0.8903404513160611
Confusion Matrix:
 [[1265   88]
 [  43   68]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9105
Precision:  0.4359
Recall:     0.6126
F1-score:   0.5094

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5580, Test Loss: 0.3691, F1: 0.4386, AUC: 0.8648
Epoch [10/30] Train Loss: 0.2573, Test Loss: 0.3566, F1: 0.4628, AUC: 0.8948
Epoch [20/30] Train Loss: 0.2132, Test Loss: 0.3242, F1: 0.4607, AUC: 0.8918
Mejores resultados en la época:  29
f1-score 0.5102880658436214
AUC según el mejor F1-score 0.8897078897078898
Confusion Matrix:
 [[1283   70]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9187
Precision:  0.4697
Recall:     0.5586
F1-score:   0.5103

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5987, Test Loss: 0.5467, F1: 0.3340, AUC: 0.8638
Epoch [10/30] Train Loss: 0.2717, Test Loss: 0.3765, F1: 0.4552, AUC: 0.8950
Epoch [20/30] Train Loss: 0.2286, Test Loss: 0.3392, F1: 0.4607, AUC: 0.8920
Mejores resultados en la época:  13
f1-score 0.5187713310580204
AUC según el mejor F1-score 0.8948216509192121
Confusion Matrix:
 [[1247  106]
 [  35   76]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_49217.png
Accuracy:   0.9037
Precision:  0.4176
Recall:     0.6847
F1-score:   0.5188
Tiempo total para red 1: 70.15 segundos

Entrenando red 2 con capas [1536, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4734, Test Loss: 0.2824, F1: 0.4792, AUC: 0.8770
Epoch [10/30] Train Loss: 0.2180, Test Loss: 0.2243, F1: 0.4940, AUC: 0.8914
Epoch [20/30] Train Loss: 0.1836, Test Loss: 0.2565, F1: 0.4797, AUC: 0.8895
Mejores resultados en la época:  8
f1-score 0.5229357798165137
AUC según el mejor F1-score 0.8920050871270384
Confusion Matrix:
 [[1303   50]
 [  54   57]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9290
Precision:  0.5327
Recall:     0.5135
F1-score:   0.5229

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4469, Test Loss: 0.6608, F1: 0.3060, AUC: 0.8799
Epoch [10/30] Train Loss: 0.2449, Test Loss: 0.2902, F1: 0.4709, AUC: 0.8933
Epoch [20/30] Train Loss: 0.1840, Test Loss: 0.2551, F1: 0.5078, AUC: 0.8903
Mejores resultados en la época:  25
f1-score 0.5126050420168067
AUC según el mejor F1-score 0.8887690351104984
Confusion Matrix:
 [[1287   66]
 [  50   61]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9208
Precision:  0.4803
Recall:     0.5495
F1-score:   0.5126

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4860, Test Loss: 0.7344, F1: 0.2798, AUC: 0.8755
Epoch [10/30] Train Loss: 0.2194, Test Loss: 0.4487, F1: 0.4130, AUC: 0.8921
Epoch [20/30] Train Loss: 0.1687, Test Loss: 0.3381, F1: 0.4646, AUC: 0.8902
Mejores resultados en la época:  21
f1-score 0.5168539325842697
AUC según el mejor F1-score 0.892391282635185
Confusion Matrix:
 [[1266   87]
 [  42   69]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9119
Precision:  0.4423
Recall:     0.6216
F1-score:   0.5169

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5014, Test Loss: 0.3713, F1: 0.4249, AUC: 0.8741
Epoch [10/30] Train Loss: 0.2447, Test Loss: 0.2679, F1: 0.4984, AUC: 0.8930
Epoch [20/30] Train Loss: 0.1794, Test Loss: 0.5282, F1: 0.3874, AUC: 0.8889
Mejores resultados en la época:  22
f1-score 0.5210727969348659
AUC según el mejor F1-score 0.8901473535619877
Confusion Matrix:
 [[1271   82]
 [  43   68]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_100481.png
Accuracy:   0.9146
Precision:  0.4533
Recall:     0.6126
F1-score:   0.5211
Tiempo total para red 2: 80.37 segundos

Entrenando red 3 con capas [1536, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4575, Test Loss: 0.4388, F1: 0.3861, AUC: 0.8814
Epoch [10/30] Train Loss: 0.2228, Test Loss: 0.2196, F1: 0.4870, AUC: 0.8931
Epoch [20/30] Train Loss: 0.1793, Test Loss: 0.2657, F1: 0.5071, AUC: 0.8897
Mejores resultados en la época:  18
f1-score 0.5232067510548524
AUC según el mejor F1-score 0.8902272560809147
Confusion Matrix:
 [[1289   64]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9228
Precision:  0.4921
Recall:     0.5586
F1-score:   0.5232

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4628, Test Loss: 0.3066, F1: 0.4661, AUC: 0.8787
Epoch [10/30] Train Loss: 0.2434, Test Loss: 0.2618, F1: 0.4921, AUC: 0.8929
Epoch [20/30] Train Loss: 0.1821, Test Loss: 0.2575, F1: 0.5038, AUC: 0.8895
Mejores resultados en la época:  27
f1-score 0.5232067510548524
AUC según el mejor F1-score 0.8875971314995705
Confusion Matrix:
 [[1289   64]
 [  49   62]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9228
Precision:  0.4921
Recall:     0.5586
F1-score:   0.5232

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4549, Test Loss: 0.4467, F1: 0.3836, AUC: 0.8826
Epoch [10/30] Train Loss: 0.2269, Test Loss: 0.2949, F1: 0.4689, AUC: 0.8918
Epoch [20/30] Train Loss: 0.1847, Test Loss: 0.2332, F1: 0.5081, AUC: 0.8887
Mejores resultados en la época:  4
f1-score 0.5177304964539007
AUC según el mejor F1-score 0.8930571369595759
Confusion Matrix:
 [[1255   98]
 [  38   73]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9071
Precision:  0.4269
Recall:     0.6577
F1-score:   0.5177

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4886, Test Loss: 0.2214, F1: 0.4444, AUC: 0.8781
Epoch [10/30] Train Loss: 0.2251, Test Loss: 0.2279, F1: 0.5062, AUC: 0.8906
Epoch [20/30] Train Loss: 0.1743, Test Loss: 0.4823, F1: 0.3957, AUC: 0.8878
Mejores resultados en la época:  8
f1-score 0.5152838427947598
AUC según el mejor F1-score 0.8914124767783305
Confusion Matrix:
 [[1294   59]
 [  52   59]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/gpt/confusion_matrix_param_207105.png
Accuracy:   0.9242
Precision:  0.5000
Recall:     0.5315
F1-score:   0.5153
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd-g001: error: *** JOB 17525 ON g001 CANCELLED AT 2025-10-30T04:26:01 ***
slurmstepd-g001: error: *** STEP 17525.0 ON g001 CANCELLED AT 2025-10-30T04:26:01 ***
