2025-10-30 04:40:32.112843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-30 04:40:32.112843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/__spanish_case/experimentation/s_only_lyrics/main_only_text_tfidf.py:273: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/__spanish_case/experimentation/s_only_lyrics/main_only_text_tfidf.py:273: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['lyrics']
Your are not adding cols numercis
You are executing with [ALL] dataset
--> PaTH:  ../../../../../data/spanish/LB_T/LB_fuss/lb_khipu_T.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 6077, 1: 1242}

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 4861, 1: 994}
Label distribution en TEST: {0: 1216, 1: 248}


==================================================
Data antes del undersampling ...
X: (5855, 5000)
y: (5855,)
Apliying UNDERSAMPLE
994
Label distribution: {0: 994, 1: 994}
X shape: (1988, 5000)
y shape: (1988,)
Resultados con MLP

Entrenando red 1 con capas [5000, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6718, Test Loss: 0.6429, F1: 0.5130, AUC: 0.8340
Epoch [10/30] Train Loss: 0.0765, Test Loss: 0.6514, F1: 0.4858, AUC: 0.8162
Epoch [20/30] Train Loss: 0.0178, Test Loss: 0.8693, F1: 0.4608, AUC: 0.8026
Mejores resultados en la época:  3
f1-score 0.5151515151515151
AUC según el mejor F1-score 0.8415249628607809
Confusion Matrix:
 [[925 291]
 [ 61 187]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.7596
Precision:  0.3912
Recall:     0.7540
F1-score:   0.5152

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6726, Test Loss: 0.6191, F1: 0.5604, AUC: 0.8377
Epoch [10/30] Train Loss: 0.0752, Test Loss: 0.6175, F1: 0.4914, AUC: 0.8204
Epoch [20/30] Train Loss: 0.0178, Test Loss: 0.8396, F1: 0.4763, AUC: 0.8081
Mejores resultados en la época:  0
f1-score 0.5604395604395604
AUC según el mejor F1-score 0.8377281409168081
Confusion Matrix:
 [[1071  145]
 [  95  153]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.8361
Precision:  0.5134
Recall:     0.6169
F1-score:   0.5604

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6723, Test Loss: 0.6144, F1: 0.5699, AUC: 0.8315
Epoch [10/30] Train Loss: 0.0757, Test Loss: 0.6128, F1: 0.4902, AUC: 0.8178
Epoch [20/30] Train Loss: 0.0177, Test Loss: 0.8234, F1: 0.4735, AUC: 0.8067
Mejores resultados en la época:  0
f1-score 0.5698729582577132
AUC según el mejor F1-score 0.8314642137096774
Confusion Matrix:
 [[1070  146]
 [  91  157]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.8381
Precision:  0.5182
Recall:     0.6331
F1-score:   0.5699

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6716, Test Loss: 0.6453, F1: 0.5041, AUC: 0.8319
Epoch [10/30] Train Loss: 0.0743, Test Loss: 0.6363, F1: 0.4856, AUC: 0.8176
Epoch [20/30] Train Loss: 0.0176, Test Loss: 0.8598, F1: 0.4753, AUC: 0.8057
Mejores resultados en la época:  1
f1-score 0.5163120567375886
AUC según el mejor F1-score 0.8380464770797963
Confusion Matrix:
 [[941 275]
 [ 66 182]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.7671
Precision:  0.3982
Recall:     0.7339
F1-score:   0.5163
Tiempo total para red 1: 44.40 segundos

Entrenando red 2 con capas [5000, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6781, Test Loss: 0.5984, F1: 0.5620, AUC: 0.8284
Epoch [10/30] Train Loss: 0.0065, Test Loss: 1.0554, F1: 0.4657, AUC: 0.7998
Epoch [20/30] Train Loss: 0.0011, Test Loss: 1.3603, F1: 0.4621, AUC: 0.7967
Mejores resultados en la época:  0
f1-score 0.5619834710743802
AUC según el mejor F1-score 0.8283737001273346
Confusion Matrix:
 [[1116  100]
 [ 112  136]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.8552
Precision:  0.5763
Recall:     0.5484
F1-score:   0.5620

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6726, Test Loss: 0.6552, F1: 0.4742, AUC: 0.8331
Epoch [10/30] Train Loss: 0.0046, Test Loss: 1.1377, F1: 0.4773, AUC: 0.8024
Epoch [20/30] Train Loss: 0.0005, Test Loss: 1.4802, F1: 0.4750, AUC: 0.7995
Mejores resultados en la época:  1
f1-score 0.5185185185185185
AUC según el mejor F1-score 0.8402681982173175
Confusion Matrix:
 [[944 272]
 [ 66 182]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7691
Precision:  0.4009
Recall:     0.7339
F1-score:   0.5185

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6799, Test Loss: 0.6571, F1: 0.5121, AUC: 0.8287
Epoch [10/30] Train Loss: 0.0038, Test Loss: 1.2183, F1: 0.4582, AUC: 0.7945
Epoch [20/30] Train Loss: 0.0005, Test Loss: 1.5929, F1: 0.4545, AUC: 0.7915
Mejores resultados en la época:  1
f1-score 0.5426356589147286
AUC según el mejor F1-score 0.8389119535229201
Confusion Matrix:
 [[994 222]
 [ 73 175]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7985
Precision:  0.4408
Recall:     0.7056
F1-score:   0.5426

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6784, Test Loss: 0.6474, F1: 0.5121, AUC: 0.8291
Epoch [10/30] Train Loss: 0.0027, Test Loss: 1.2277, F1: 0.4682, AUC: 0.8001
Epoch [20/30] Train Loss: 0.0005, Test Loss: 1.5431, F1: 0.4678, AUC: 0.7973
Mejores resultados en la época:  0
f1-score 0.5120910384068279
AUC según el mejor F1-score 0.82908664049236
Confusion Matrix:
 [[941 275]
 [ 68 180]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7657
Precision:  0.3956
Recall:     0.7258
F1-score:   0.5121
Tiempo total para red 2: 43.74 segundos

Entrenando red 3 con capas [5000, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6742, Test Loss: 0.6053, F1: 0.5672, AUC: 0.8373
Epoch [10/30] Train Loss: 0.0008, Test Loss: 1.5797, F1: 0.4600, AUC: 0.7971
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.1810, F1: 0.4623, AUC: 0.7945
Mejores resultados en la época:  0
f1-score 0.5671641791044776
AUC según el mejor F1-score 0.8372871126910018
Confusion Matrix:
 [[1032  184]
 [  77  171]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.8217
Precision:  0.4817
Recall:     0.6895
F1-score:   0.5672

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6762, Test Loss: 0.5923, F1: 0.5492, AUC: 0.8248
Epoch [10/30] Train Loss: 0.0014, Test Loss: 1.7604, F1: 0.4555, AUC: 0.7940
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.1730, F1: 0.4645, AUC: 0.7920
Mejores resultados en la época:  0
f1-score 0.5491525423728814
AUC según el mejor F1-score 0.8248123143039049
Confusion Matrix:
 [[1036  180]
 [  86  162]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.8183
Precision:  0.4737
Recall:     0.6532
F1-score:   0.5492

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6744, Test Loss: 0.6426, F1: 0.5082, AUC: 0.8377
Epoch [10/30] Train Loss: 0.0008, Test Loss: 1.7102, F1: 0.4535, AUC: 0.7917
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.0976, F1: 0.4533, AUC: 0.7910
Mejores resultados en la época:  0
f1-score 0.5081521739130435
AUC según el mejor F1-score 0.8376585048811545
Confusion Matrix:
 [[915 301]
 [ 61 187]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.7527
Precision:  0.3832
Recall:     0.7540
F1-score:   0.5082

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6746, Test Loss: 0.6280, F1: 0.5053, AUC: 0.8391
Epoch [10/30] Train Loss: 0.0010, Test Loss: 1.7123, F1: 0.4570, AUC: 0.7918
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.0224, F1: 0.4516, AUC: 0.7907
Mejores resultados en la época:  0
f1-score 0.5053475935828877
AUC según el mejor F1-score 0.8391042816213922
Confusion Matrix:
 [[905 311]
 [ 59 189]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.7473
Precision:  0.3780
Recall:     0.7621
For TF-IDF embbedings you are selecteing this columns:
--> ['lyrics']
Your are not adding cols numercis
You are executing with [ALL] dataset
--> PaTH:  ../../../../../data/spanish/LB_T/LB_fuss/lb_khipu_T.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 6077, 1: 1242}

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 4861, 1: 994}
Label distribution en TEST: {0: 1216, 1: 248}


==================================================
Data antes del undersampling ...
X: (5855, 5000)
y: (5855,)
Apliying UNDERSAMPLE
994
Label distribution: {0: 994, 1: 994}
X shape: (1988, 5000)
y shape: (1988,)
Resultados con MLP

Entrenando red 1 con capas [5000, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6760, Test Loss: 0.6140, F1: 0.5797, AUC: 0.8349
Epoch [10/30] Train Loss: 0.0746, Test Loss: 0.6181, F1: 0.4881, AUC: 0.8165
Epoch [20/30] Train Loss: 0.0182, Test Loss: 0.8437, F1: 0.4667, AUC: 0.8044
Mejores resultados en la época:  0
f1-score 0.5796545105566219
AUC según el mejor F1-score 0.8349327514855688
Confusion Matrix:
 [[1094  122]
 [  97  151]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.8504
Precision:  0.5531
Recall:     0.6089
F1-score:   0.5797

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6725, Test Loss: 0.6134, F1: 0.5580, AUC: 0.8255
Epoch [10/30] Train Loss: 0.0794, Test Loss: 0.6059, F1: 0.4848, AUC: 0.8154
Epoch [20/30] Train Loss: 0.0188, Test Loss: 0.8045, F1: 0.4772, AUC: 0.8039
Mejores resultados en la época:  0
f1-score 0.5579567779960707
AUC según el mejor F1-score 0.8254605926358234
Confusion Matrix:
 [[1097  119]
 [ 106  142]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.8463
Precision:  0.5441
Recall:     0.5726
F1-score:   0.5580

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6742, Test Loss: 0.6081, F1: 0.5610, AUC: 0.8312
Epoch [10/30] Train Loss: 0.0807, Test Loss: 0.6183, F1: 0.4869, AUC: 0.8188
Epoch [20/30] Train Loss: 0.0190, Test Loss: 0.8206, F1: 0.4731, AUC: 0.8061
Mejores resultados en la época:  0
f1-score 0.5609756097560976
AUC según el mejor F1-score 0.8311923015704584
Confusion Matrix:
 [[1110  106]
 [ 110  138]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.8525
Precision:  0.5656
Recall:     0.5565
F1-score:   0.5610

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6731, Test Loss: 0.6429, F1: 0.5224, AUC: 0.8349
Epoch [10/30] Train Loss: 0.0751, Test Loss: 0.6425, F1: 0.4785, AUC: 0.8152
Epoch [20/30] Train Loss: 0.0178, Test Loss: 0.8606, F1: 0.4635, AUC: 0.8042
Mejores resultados en la época:  0
f1-score 0.5223665223665224
AUC según el mejor F1-score 0.8349194874787778
Confusion Matrix:
 [[952 264]
 [ 67 181]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_160065.png
Accuracy:   0.7739
Precision:  0.4067
Recall:     0.7298
F1-score:   0.5224
Tiempo total para red 1: 44.56 segundos

Entrenando red 2 con capas [5000, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6767, Test Loss: 0.6693, F1: 0.4623, AUC: 0.8310
Epoch [10/30] Train Loss: 0.0043, Test Loss: 1.2460, F1: 0.4612, AUC: 0.7991
Epoch [20/30] Train Loss: 0.0009, Test Loss: 1.5570, F1: 0.4577, AUC: 0.7954
Mejores resultados en la época:  3
f1-score 0.4888888888888889
AUC según el mejor F1-score 0.8194934475806451
Confusion Matrix:
 [[886 330]
 [ 61 187]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7329
Precision:  0.3617
Recall:     0.7540
F1-score:   0.4889

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6773, Test Loss: 0.6477, F1: 0.5228, AUC: 0.8338
Epoch [10/30] Train Loss: 0.0037, Test Loss: 1.2090, F1: 0.4625, AUC: 0.7983
Epoch [20/30] Train Loss: 0.0005, Test Loss: 1.5375, F1: 0.4655, AUC: 0.7947
Mejores resultados en la época:  0
f1-score 0.5227606461086637
AUC según el mejor F1-score 0.8337986789049235
Confusion Matrix:
 [[961 255]
 [ 70 178]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7780
Precision:  0.4111
Recall:     0.7177
F1-score:   0.5228

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6740, Test Loss: 0.6214, F1: 0.5629, AUC: 0.8372
Epoch [10/30] Train Loss: 0.0045, Test Loss: 1.1287, F1: 0.4689, AUC: 0.8004
Epoch [20/30] Train Loss: 0.0004, Test Loss: 1.7020, F1: 0.4676, AUC: 0.7971
Mejores resultados en la época:  0
f1-score 0.5629139072847682
AUC según el mejor F1-score 0.8371810006366723
Confusion Matrix:
 [[1030  186]
 [  78  170]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.8197
Precision:  0.4775
Recall:     0.6855
F1-score:   0.5629

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6743, Test Loss: 0.6744, F1: 0.4337, AUC: 0.8305
Epoch [10/30] Train Loss: 0.0029, Test Loss: 1.2865, F1: 0.4533, AUC: 0.7987
Epoch [20/30] Train Loss: 0.0005, Test Loss: 1.5687, F1: 0.4579, AUC: 0.7960
Mejores resultados en la época:  1
f1-score 0.506155950752394
AUC según el mejor F1-score 0.8419958351018677
Confusion Matrix:
 [[918 298]
 [ 63 185]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_322177.png
Accuracy:   0.7534
Precision:  0.3830
Recall:     0.7460
F1-score:   0.5062
Tiempo total para red 2: 44.17 segundos

Entrenando red 3 con capas [5000, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6768, Test Loss: 0.6355, F1: 0.5102, AUC: 0.8327
Epoch [10/30] Train Loss: 0.0014, Test Loss: 1.7734, F1: 0.4531, AUC: 0.7924
Epoch [20/30] Train Loss: 0.0002, Test Loss: 1.9655, F1: 0.4591, AUC: 0.7909
Mejores resultados en la época:  0
f1-score 0.5102319236016372
AUC según el mejor F1-score 0.8326778703310697
Confusion Matrix:
 [[918 298]
 [ 61 187]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.7548
Precision:  0.3856
Recall:     0.7540
F1-score:   0.5102

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6730, Test Loss: 0.5837, F1: 0.5628, AUC: 0.8309
Epoch [10/30] Train Loss: 0.0028, Test Loss: 1.9102, F1: 0.4480, AUC: 0.7899
Epoch [20/30] Train Loss: 0.0002, Test Loss: 1.9415, F1: 0.4558, AUC: 0.7892
Mejores resultados en la época:  0
f1-score 0.5628140703517588
AUC según el mejor F1-score 0.8309303374363327
Confusion Matrix:
 [[1035  181]
 [  80  168]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.8217
Precision:  0.4814
Recall:     0.6774
F1-score:   0.5628

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6723, Test Loss: 0.6023, F1: 0.5325, AUC: 0.8340
Epoch [10/30] Train Loss: 0.0007, Test Loss: 1.6211, F1: 0.4513, AUC: 0.7911
Epoch [20/30] Train Loss: 0.0001, Test Loss: 1.9303, F1: 0.4530, AUC: 0.7911
Mejores resultados en la época:  0
f1-score 0.5325443786982249
AUC según el mejor F1-score 0.8340241670203735
Confusion Matrix:
 [[968 248]
 [ 68 180]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.7842
Precision:  0.4206
Recall:     0.7258
F1-score:   0.5325

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6717, Test Loss: 0.5737, F1: 0.5677, AUC: 0.8363
Epoch [10/30] Train Loss: 0.0010, Test Loss: 1.5850, F1: 0.4579, AUC: 0.7942
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.1301, F1: 0.4602, AUC: 0.7934
Mejores resultados en la época:  0
f1-score 0.567699836867863
AUC según el mejor F1-score 0.8363155241935485
Confusion Matrix:
 [[1025  191]
 [  74  174]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_650497.png
Accuracy:   0.8190
Precision:  0.4767
Recall:     0.7016
F1-score:   0.5053
Tiempo total para red 3: 46.58 segundos

Entrenando red 4 con capas [5000, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6753, Test Loss: 0.5136, F1: 0.5545, AUC: 0.8330
Epoch [10/30] Train Loss: 0.0016, Test Loss: 2.0908, F1: 0.4478, AUC: 0.7897
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.2555, F1: 0.4437, AUC: 0.7801
Mejores resultados en la época:  0
f1-score 0.5544933078393881
AUC según el mejor F1-score 0.8330492625212225
Confusion Matrix:
 [[1086  130]
 [ 103  145]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.8408
Precision:  0.5273
Recall:     0.5847
F1-score:   0.5545

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6777, Test Loss: 0.5367, F1: 0.5646, AUC: 0.8346
Epoch [10/30] Train Loss: 0.0003, Test Loss: 2.0558, F1: 0.4388, AUC: 0.7889
Epoch [20/30] Train Loss: 0.0000, Test Loss: 2.5958, F1: 0.4470, AUC: 0.7883
Mejores resultados en la época:  0
f1-score 0.5645756457564576
AUC según el mejor F1-score 0.834609441320034
Confusion Matrix:
 [[1075  141]
 [  95  153]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.8388
Precision:  0.5204
Recall:     0.6169
F1-score:   0.5646

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6780, Test Loss: 0.4909, F1: 0.5630, AUC: 0.8287
Epoch [10/30] Train Loss: 0.0060, Test Loss: 1.9244, F1: 0.4672, AUC: 0.7918
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.2951, F1: 0.4539, AUC: 0.7830
Mejores resultados en la época:  0
f1-score 0.562992125984252
AUC según el mejor F1-score 0.828748408319185
Confusion Matrix:
 [[1099  117]
 [ 105  143]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.8484
Precision:  0.5500
Recall:     0.5766
F1-score:   0.5630

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6769, Test Loss: 0.5923, F1: 0.5370, AUC: 0.8348
Epoch [10/30] Train Loss: 0.0014, Test Loss: 2.0132, F1: 0.4627, AUC: 0.7917
Epoch [20/30] Train Loss: 0.0000, Test Loss: 3.1670, F1: 0.4525, AUC: 0.7865
Mejores resultados en la época:  0
f1-score 0.5370370370370371
AUC según el mejor F1-score 0.8347735834040747
Confusion Matrix:
 [[990 226]
 [ 74 174]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.7951
Precision:  0.4350
Recall:     0.7016
F1-score:   0.5370
Tiempo total para red 4: 46.34 segundos

Entrenando red 5 con capas [5000, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6392, Test Loss: 0.5981, F1: 0.5435, AUC: 0.8296
Epoch [10/30] Train Loss: 0.0003, Test Loss: 3.9626, F1: 0.4502, AUC: 0.7934
Epoch [20/30] Train Loss: 0.0000, Test Loss: 6.0200, F1: 0.4486, AUC: 0.7829
Mejores resultados en la época:  0
f1-score 0.5434782608695652
AUC según el mejor F1-score 0.829647044779287
Confusion Matrix:
 [[995 221]
 [ 73 175]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7992
Precision:  0.4419
Recall:     0.7056
F1-score:   0.5435

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6239, Test Loss: 0.5860, F1: 0.5013, AUC: 0.8375
Epoch [10/30] Train Loss: 0.0023, Test Loss: 2.4415, F1: 0.4514, AUC: 0.7928
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.0529, F1: 0.4567, AUC: 0.7824
Mejores resultados en la época:  0
f1-score 0.5013333333333333
AUC según el mejor F1-score 0.8375441028225807
Confusion Matrix:
 [[902 314]
 [ 60 188]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7445
Precision:  0.3745
Recall:     0.7581
F1-score:   0.5013

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6357, Test Loss: 0.5258, F1: 0.4994, AUC: 0.8347
Epoch [10/30] Train Loss: 0.0004, Test Loss: 2.8276, F1: 0.4531, AUC: 0.7933
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.9348, F1: 0.4528, AUC: 0.7800
Mejores resultados en la época:  0
f1-score 0.4993788819875776
AUC según el mejor F1-score 0.8346641553480474
Confusion Matrix:
 [[860 356]
 [ 47 201]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7247
Precision:  0.3609
Recall:     0.8105
F1-score:   0.4994

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6248, Test Loss: 0.4773, F1: 0.4967, AUC: 0.8340
Epoch [10/30] Train Loss: 0.0008, Test Loss: 2.3322, F1: 0.4751, AUC: 0.8002
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.0872, F1: 0.4674, AUC: 0.7917
Mejores resultados en la época:  0
f1-score 0.4967148488830486
AUC según el mejor F1-score 0.8340142190152803
Confusion Matrix:
 [[892 324]
 [ 59 189]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7384
Precision:  0.3684
Recall:     0.7621
F1-score:   0.4967
Tiempo total para red 5: 47.80 segundos

Entrenando red 6 con capas [5000, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6452, Test Loss: 0.8082, F1: 0.4086, AUC: 0.8255
Epoch [10/30] Train Loss: 0.0001, Test Loss: 4.0900, F1: 0.4539, AUC: 0.7824
Epoch [20/30] Train Loss: 0.0000, Test Loss: 7.0150, F1: 0.4429, AUC: 0.7694
Mejores resultados en la época:  7
f1-score 0.46814404432132967
AUC según el mejor F1-score 0.7880743314940577
Confusion Matrix:
 [[911 305]
 [ 79 169]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.7377
Precision:  0.3565
Recall:     0.6815
F1-score:   0.4681

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6510, Test Loss: 0.6827, F1: 0.5498, AUC: 0.8116
Epoch [10/30] Train Loss: 0.0002, Test Loss: 4.2431, F1: 0.4715, AUC: 0.7931
Epoch [20/30] Train Loss: 0.0000, Test Loss: 8.8172, F1: 0.4686, AUC: 0.7725
Mejores resultados en la época:  0
f1-score 0.5498281786941581
AUC según el mejor F1-score 0.8116096535441425
Confusion Matrix:
 [[1042  174]
 [  88  160]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.8210
Precision:  0.4790
Recall:     0.6452
F1-score:   0.5498

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6488, Test Loss: 0.7662, F1: 0.4908, AUC: 0.8230
Epoch [10/30] Train Loss: 0.0007, Test Loss: 6.4076, F1: 0.4525, AUC: 0.7823
Epoch [20/30] Train Loss: 0.0000, Test Loss: 14.0147, F1: 0.4538, AUC: 0.7665
Mejores resultados en la época:  0
f1-score 0.49081364829396323
AUC según el mejor F1-score 0.8230117253820034
Confusion Matrix:
 [[889 327]
 [ 61 187]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.7350
Precision:  0.3638
Recall:     0.7540
F1-score:   0.4908

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6335, Test Loss: 0.4409, F1: 0.5709, AUC: 0.8313
Epoch [10/30] Train Loss: 0.0017, Test Loss: 4.9754, F1: 0.4590, AUC: 0.7883
Epoch [20/30] Train Loss: 0.0000, Test Loss: 7.5526, F1: 0.4516, AUC: 0.7742
Mejores resultados en la época:  0
f1-score 0.570902394106814
AUC según el mejor F1-score 0.8312519896010188
Confusion Matrix:
 [[1076  140]
 [  93  155]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.8408
Precision:  0.5254
Recall:     0.6250
F1-score:   0.5709
Tiempo total para red 6: 51.29 segundos
Saved on: outputs_only_text_pseudo/2/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.7343
Precision: 0.3620
Recall:    0.7460
F1-score:  0.4875
              precision    recall  f1-score   support

           0       0.93      0.73      0.82      1216
           1       0.36      0.75      0.49       248

    accuracy                           0.73      1464
   macro avg       0.65      0.74      0.65      1464
weighted avg       0.84      0.73      0.76      1464

[[890 326]
 [ 63 185]]
F1-score:   0.5677
Tiempo total para red 3: 47.03 segundos

Entrenando red 4 con capas [5000, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6720, Test Loss: 0.5907, F1: 0.5040, AUC: 0.8358
Epoch [10/30] Train Loss: 0.0007, Test Loss: 1.7199, F1: 0.4594, AUC: 0.7931
Epoch [20/30] Train Loss: 0.0000, Test Loss: 3.4281, F1: 0.4589, AUC: 0.7879
Mejores resultados en la época:  1
f1-score 0.5160390516039052
AUC según el mejor F1-score 0.8211879244482172
Confusion Matrix:
 [[932 284]
 [ 63 185]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.7630
Precision:  0.3945
Recall:     0.7460
F1-score:   0.5160

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6770, Test Loss: 0.5689, F1: 0.5339, AUC: 0.8322
Epoch [10/30] Train Loss: 0.0001, Test Loss: 2.4914, F1: 0.4522, AUC: 0.7886
Epoch [20/30] Train Loss: 0.0000, Test Loss: 3.3023, F1: 0.4591, AUC: 0.7840
Mejores resultados en la época:  0
f1-score 0.5339366515837104
AUC según el mejor F1-score 0.8322169460950763
Confusion Matrix:
 [[978 238]
 [ 71 177]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.7889
Precision:  0.4265
Recall:     0.7137
F1-score:   0.5339

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6780, Test Loss: 0.6398, F1: 0.4652, AUC: 0.8343
Epoch [10/30] Train Loss: 0.0012, Test Loss: 1.8379, F1: 0.4625, AUC: 0.7962
Epoch [20/30] Train Loss: 0.0001, Test Loss: 2.8800, F1: 0.4558, AUC: 0.7952
Mejores resultados en la época:  2
f1-score 0.48333333333333334
AUC según el mejor F1-score 0.8019120065789472
Confusion Matrix:
 [[918 298]
 [ 74 174]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.7459
Precision:  0.3686
Recall:     0.7016
F1-score:   0.4833

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6730, Test Loss: 0.5680, F1: 0.5327, AUC: 0.8339
Epoch [10/30] Train Loss: 0.0006, Test Loss: 1.9830, F1: 0.4490, AUC: 0.7867
Epoch [20/30] Train Loss: 0.0061, Test Loss: 2.3382, F1: 0.4422, AUC: 0.7877
Mejores resultados en la época:  0
f1-score 0.532724505327245
AUC según el mejor F1-score 0.8338948429541596
Confusion Matrix:
 [[982 234]
 [ 73 175]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_1323521.png
Accuracy:   0.7903
Precision:  0.4279
Recall:     0.7056
F1-score:   0.5327
Tiempo total para red 4: 46.33 segundos

Entrenando red 5 con capas [5000, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6490, Test Loss: 0.5008, F1: 0.5233, AUC: 0.8344
Epoch [10/30] Train Loss: 0.0020, Test Loss: 2.6400, F1: 0.4480, AUC: 0.7843
Epoch [20/30] Train Loss: 0.0000, Test Loss: 3.7626, F1: 0.4558, AUC: 0.7795
Mejores resultados en la época:  0
f1-score 0.5232558139534884
AUC según el mejor F1-score 0.8343623991935485
Confusion Matrix:
 [[956 260]
 [ 68 180]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7760
Precision:  0.4091
Recall:     0.7258
F1-score:   0.5233

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6248, Test Loss: 0.7130, F1: 0.4873, AUC: 0.8391
Epoch [10/30] Train Loss: 0.0030, Test Loss: 2.6544, F1: 0.4680, AUC: 0.8036
Epoch [20/30] Train Loss: 0.0000, Test Loss: 3.9552, F1: 0.4688, AUC: 0.7927
Mejores resultados en la época:  0
f1-score 0.48727272727272725
AUC según el mejor F1-score 0.8391009656196944
Confusion Matrix:
 [[840 376]
 [ 47 201]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7111
Precision:  0.3484
Recall:     0.8105
F1-score:   0.4873

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6410, Test Loss: 0.5754, F1: 0.5000, AUC: 0.8426
Epoch [10/30] Train Loss: 0.0007, Test Loss: 2.3803, F1: 0.4662, AUC: 0.7946
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.0376, F1: 0.4471, AUC: 0.7854
Mejores resultados en la época:  0
f1-score 0.5
AUC según el mejor F1-score 0.8426092954159593
Confusion Matrix:
 [[885 331]
 [ 55 193]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7363
Precision:  0.3683
Recall:     0.7782
F1-score:   0.5000

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6255, Test Loss: 0.6615, F1: 0.4735, AUC: 0.8388
Epoch [10/30] Train Loss: 0.0009, Test Loss: 2.1261, F1: 0.4619, AUC: 0.7997
Epoch [20/30] Train Loss: 0.0000, Test Loss: 4.2999, F1: 0.4677, AUC: 0.7895
Mejores resultados en la época:  3
f1-score 0.4794326241134752
AUC según el mejor F1-score 0.805392150360781
Confusion Matrix:
 [[928 288]
 [ 79 169]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_2733057.png
Accuracy:   0.7493
Precision:  0.3698
Recall:     0.6815
F1-score:   0.4794
Tiempo total para red 5: 47.88 segundos

Entrenando red 6 con capas [5000, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6246, Test Loss: 0.3397, F1: 0.5450, AUC: 0.8284
Epoch [10/30] Train Loss: 0.0004, Test Loss: 6.5182, F1: 0.4536, AUC: 0.7721
Epoch [20/30] Train Loss: 0.0000, Test Loss: 11.8759, F1: 0.4547, AUC: 0.7593
Mejores resultados en la época:  0
f1-score 0.5450236966824644
AUC según el mejor F1-score 0.8283902801358234
Confusion Matrix:
 [[1157   59]
 [ 133  115]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.8689
Precision:  0.6609
Recall:     0.4637
F1-score:   0.5450

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6221, Test Loss: 0.5796, F1: 0.5040, AUC: 0.8331
Epoch [10/30] Train Loss: 0.0004, Test Loss: 3.3181, F1: 0.4729, AUC: 0.7963
Epoch [20/30] Train Loss: 0.0000, Test Loss: 8.1363, F1: 0.4755, AUC: 0.7781
Mejores resultados en la época:  0
f1-score 0.5040214477211796
AUC según el mejor F1-score 0.8330923705432938
Confusion Matrix:
 [[906 310]
 [ 60 188]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.7473
Precision:  0.3775
Recall:     0.7581
F1-score:   0.5040

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6337, Test Loss: 0.3892, F1: 0.5627, AUC: 0.8313
Epoch [10/30] Train Loss: 0.0015, Test Loss: 3.9109, F1: 0.4632, AUC: 0.7912
Epoch [20/30] Train Loss: 0.0000, Test Loss: 6.7633, F1: 0.4627, AUC: 0.7777
Mejores resultados en la época:  0
f1-score 0.5627240143369175
AUC según el mejor F1-score 0.831341521646859
Confusion Matrix:
 [[1063  153]
 [  91  157]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.8333
Precision:  0.5065
Recall:     0.6331
F1-score:   0.5627

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6528, Test Loss: 0.5318, F1: 0.4489, AUC: 0.8073
Epoch [10/30] Train Loss: 0.0011, Test Loss: 5.9226, F1: 0.4563, AUC: 0.7754
Epoch [20/30] Train Loss: 0.0023, Test Loss: 3.5704, F1: 0.4704, AUC: 0.7854
Mejores resultados en la época:  7
f1-score 0.49926144756277696
AUC según el mejor F1-score 0.7983937287775891
Confusion Matrix:
 [[956 260]
 [ 79 169]]
Matriz de confusión guardada en: outputs_only_text_pseudo/2/tfidf/confusion_matrix_param_5820417.png
Accuracy:   0.7684
Precision:  0.3939
Recall:     0.6815
F1-score:   0.4993
Tiempo total para red 6: 51.52 segundos
Saved on: outputs_only_text_pseudo/2/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.7343
Precision: 0.3620
Recall:    0.7460
F1-score:  0.4875
              precision    recall  f1-score   support

           0       0.93      0.73      0.82      1216
           1       0.36      0.75      0.49       248

    accuracy                           0.73      1464
   macro avg       0.65      0.74      0.65      1464
weighted avg       0.84      0.73      0.76      1464

[[890 326]
 [ 63 185]]
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:46:32] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:46:33] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.8183
Precision: 0.4713
Recall:    0.5968
F1-score:  0.5267
              precision    recall  f1-score   support

           0       0.91      0.86      0.89      1216
           1       0.47      0.60      0.53       248

    accuracy                           0.82      1464
   macro avg       0.69      0.73      0.71      1464
weighted avg       0.84      0.82      0.83      1464

[[1050  166]
 [ 100  148]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8176
Precision: 0.4609
Recall:    0.4516
F1-score:  0.4562
              precision    recall  f1-score   support

           0       0.89      0.89      0.89      1216
           1       0.46      0.45      0.46       248

    accuracy                           0.82      1464
   macro avg       0.67      0.67      0.67      1464
weighted avg       0.82      0.82      0.82      1464

[[1085  131]
 [ 136  112]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8197
Precision: 0.4780
Recall:    0.7016
F1-score:  0.5686
              precision    recall  f1-score   support

           0       0.93      0.84      0.89      1216
           1       0.48      0.70      0.57       248

    accuracy                           0.82      1464
   macro avg       0.71      0.77      0.73      1464
weighted avg       0.86      0.82      0.83      1464

[[1026  190]
 [  74  174]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.7643
Precision: 0.3905
Recall:    0.6976
F1-score:  0.5007
              precision    recall  f1-score   support

           0       0.93      0.78      0.85      1216
           1       0.39      0.70      0.50       248

    accuracy                           0.76      1464
   macro avg       0.66      0.74      0.67      1464
weighted avg       0.84      0.76      0.79      1464

[[946 270]
 [ 75 173]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.7548
Precision: 0.3806
Recall:    0.7137
F1-score:  0.4965
              precision    recall  f1-score   support

           0       0.93      0.76      0.84      1216
           1       0.38      0.71      0.50       248

    accuracy                           0.75      1464
   macro avg       0.65      0.74      0.67      1464
weighted avg       0.84      0.75      0.78      1464

[[928 288]
 [ 71 177]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/naive_bayes_model.pkl


Resumen de métricas:
Random Forest: {'accuracy': 0.8197, 'precision': 0.478, 'recall': 0.7016, 'f1_score': 0.5686}
SVM: {'accuracy': 0.8183, 'precision': 0.4713, 'recall': 0.5968, 'f1_score': 0.5267}
XGBoost: {'accuracy': 0.7643, 'precision': 0.3905, 'recall': 0.6976, 'f1_score': 0.5007}
Naive Bayes: {'accuracy': 0.7548, 'precision': 0.3806, 'recall': 0.7137, 'f1_score': 0.4965}
Logistic Regression: {'accuracy': 0.7343, 'precision': 0.362, 'recall': 0.746, 'f1_score': 0.4875}
Decision Tree: {'accuracy': 0.8176, 'precision': 0.4609, 'recall': 0.4516, 'f1_score': 0.4562}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_5820417: {'accuracy': 0.8408469945355191, 'precision': 0.5254237288135594, 'recall': 0.625, 'f1_score': 0.570902394106814, 'f1_score_avg': 0.5199220663540662}
MLP_160065: {'accuracy': 0.7670765027322405, 'precision': 0.3982494529540481, 'recall': 0.7338709677419355, 'f1_score': 0.5698729582577132, 'f1_score_avg': 0.5404440226465943}
MLP_322177: {'accuracy': 0.7657103825136612, 'precision': 0.3956043956043956, 'recall': 0.7258064516129032, 'f1_score': 0.5698729582577132, 'f1_score_avg': 0.5338071717286138}
MLP_650497: {'accuracy': 0.7472677595628415, 'precision': 0.378, 'recall': 0.7620967741935484, 'f1_score': 0.5698729582577132, 'f1_score_avg': 0.5324541222433226}
MLP_1323521: {'accuracy': 0.7950819672131147, 'precision': 0.435, 'recall': 0.7016129032258065, 'f1_score': 0.5698729582577132, 'f1_score_avg': 0.5547745291542837}
MLP_2733057: {'accuracy': 0.7383879781420765, 'precision': 0.3684210526315789, 'recall': 0.7620967741935484, 'f1_score': 0.5698729582577132, 'f1_score_avg': 0.5102263312683812}
Random Forest: {'accuracy': 0.8197, 'precision': 0.478, 'recall': 0.7016, 'f1_score': 0.5686}
SVM: {'accuracy': 0.8183, 'precision': 0.4713, 'recall': 0.5968, 'f1_score': 0.5267}
XGBoost: {'accuracy': 0.7643, 'precision': 0.3905, 'recall': 0.6976, 'f1_score': 0.5007}
Naive Bayes: {'accuracy': 0.7548, 'precision': 0.3806, 'recall': 0.7137, 'f1_score': 0.4965}
Logistic Regression: {'accuracy': 0.7343, 'precision': 0.362, 'recall': 0.746, 'f1_score': 0.4875}
Decision Tree: {'accuracy': 0.8176, 'precision': 0.4609, 'recall': 0.4516, 'f1_score': 0.4562}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: False
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['lyrics']
Numeric Columns: Not used
====================================

Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.8183
Precision: 0.4713
Recall:    0.5968
F1-score:  0.5267
              precision    recall  f1-score   support

           0       0.91      0.86      0.89      1216
           1       0.47      0.60      0.53       248

    accuracy                           0.82      1464
   macro avg       0.69      0.73      0.71      1464
weighted avg       0.84      0.82      0.83      1464

[[1050  166]
 [ 100  148]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8176
Precision: 0.4609
Recall:    0.4516
F1-score:  0.4562
              precision    recall  f1-score   support

           0       0.89      0.89      0.89      1216
           1       0.46      0.45      0.46       248

    accuracy                           0.82      1464
   macro avg       0.67      0.67      0.67      1464
weighted avg       0.82      0.82      0.82      1464

[[1085  131]
 [ 136  112]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8197
Precision: 0.4780
Recall:    0.7016
F1-score:  0.5686
              precision    recall  f1-score   support

           0       0.93      0.84      0.89      1216
           1       0.48      0.70      0.57       248

    accuracy                           0.82      1464
   macro avg       0.71      0.77      0.73      1464
weighted avg       0.86      0.82      0.83      1464

[[1026  190]
 [  74  174]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.7643
Precision: 0.3905
Recall:    0.6976
F1-score:  0.5007
              precision    recall  f1-score   support

           0       0.93      0.78      0.85      1216
           1       0.39      0.70      0.50       248

    accuracy                           0.76      1464
   macro avg       0.66      0.74      0.67      1464
weighted avg       0.84      0.76      0.79      1464

[[946 270]
 [ 75 173]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.7548
Precision: 0.3806
Recall:    0.7137
F1-score:  0.4965
              precision    recall  f1-score   support

           0       0.93      0.76      0.84      1216
           1       0.38      0.71      0.50       248

    accuracy                           0.75      1464
   macro avg       0.65      0.74      0.67      1464
weighted avg       0.84      0.75      0.78      1464

[[928 288]
 [ 71 177]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_only_text_pseudo/2/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_only_text_pseudo/2/tfidf/naive_bayes_model.pkl


Resumen de métricas:
Random Forest: {'accuracy': 0.8197, 'precision': 0.478, 'recall': 0.7016, 'f1_score': 0.5686}
SVM: {'accuracy': 0.8183, 'precision': 0.4713, 'recall': 0.5968, 'f1_score': 0.5267}
XGBoost: {'accuracy': 0.7643, 'precision': 0.3905, 'recall': 0.6976, 'f1_score': 0.5007}
Naive Bayes: {'accuracy': 0.7548, 'precision': 0.3806, 'recall': 0.7137, 'f1_score': 0.4965}
Logistic Regression: {'accuracy': 0.7343, 'precision': 0.362, 'recall': 0.746, 'f1_score': 0.4875}
Decision Tree: {'accuracy': 0.8176, 'precision': 0.4609, 'recall': 0.4516, 'f1_score': 0.4562}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_160065: {'accuracy': 0.7739071038251366, 'precision': 0.4067415730337079, 'recall': 0.7298387096774194, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.5552383551688281}
MLP_322177: {'accuracy': 0.7534153005464481, 'precision': 0.3830227743271222, 'recall': 0.7459677419354839, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.5201798482586787}
MLP_650497: {'accuracy': 0.8189890710382514, 'precision': 0.4767123287671233, 'recall': 0.7016129032258065, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.543322552379871}
MLP_1323521: {'accuracy': 0.7903005464480874, 'precision': 0.4278728606356968, 'recall': 0.7056451612903226, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.5165083854620485}
MLP_2733057: {'accuracy': 0.7493169398907104, 'precision': 0.36980306345733044, 'recall': 0.6814516129032258, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.49749029133492273}
MLP_5820417: {'accuracy': 0.7684426229508197, 'precision': 0.3939393939393939, 'recall': 0.6814516129032258, 'f1_score': 0.5796545105566219, 'f1_score_avg': 0.5277576515758347}
Random Forest: {'accuracy': 0.8197, 'precision': 0.478, 'recall': 0.7016, 'f1_score': 0.5686}
SVM: {'accuracy': 0.8183, 'precision': 0.4713, 'recall': 0.5968, 'f1_score': 0.5267}
XGBoost: {'accuracy': 0.7643, 'precision': 0.3905, 'recall': 0.6976, 'f1_score': 0.5007}
Naive Bayes: {'accuracy': 0.7548, 'precision': 0.3806, 'recall': 0.7137, 'f1_score': 0.4965}
Logistic Regression: {'accuracy': 0.7343, 'precision': 0.362, 'recall': 0.746, 'f1_score': 0.4875}
Decision Tree: {'accuracy': 0.8176, 'precision': 0.4609, 'recall': 0.4516, 'f1_score': 0.4562}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: False
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['lyrics']
Numeric Columns: Not used
====================================

