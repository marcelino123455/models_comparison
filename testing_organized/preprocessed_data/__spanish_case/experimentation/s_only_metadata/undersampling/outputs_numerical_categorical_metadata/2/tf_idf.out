2025-10-30 00:26:49.933147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-30 00:26:49.933147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/__spanish_case/experimentation/s_only_metadata/undersampling/metadata_tfidf.py:267: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/__spanish_case/experimentation/s_only_metadata/undersampling/metadata_tfidf.py:267: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
For TF-IDF embbedings you are selecteing this columns:
--> ['artist', 'genre', 'title_songs_new']
For both embbedings your are adding this categorical columns: 
--> CAT_ALL 3 ['title_songs_new', 'artist', 'genre']

CAT_LOW 1 ['title_songs_new']
CAT_HIGH 2 ['artist', 'genre']
For both embbedings your are adding this columns: 
--> ['lyrics_word_count', 'popularity', 'duration_ms']
You are executing with [ALL] dataset
--> PaTH:  ../../../../../../data/spanish/LB_M/LB_fuss/lb_khipu_M.npy
Contaning the categorical cols
Preprocessing text...
Label distribution: {False: 6765, True: 554}

Splitting data (index-based split to avoid leakage)...
X_train_Numeric:  (5855, 3)
X_train_Numeric:  (5855, 3)
Concatenating TF-IDF and numeric features...
Shape of X_train after concatenation:  (5855, 4088)
Shape of X_test after concatenation:  (1464, 4088)
Shape of y_train:  (5855,)
Shape of y_test:  (1464,)

Data con el spliting...
Label distribution en TRAIN: {0: 5412, 1: 443}
Label distribution en TEST: {0: 1353, 1: 111}


==================================================
Data antes del undersampling ...
X: (5855, 4088)
y: (5855,)
Apliying UNDERSAMPLE
443
Label distribution: {0: 443, 1: 443}
X shape: (886, 4088)
y shape: (886,)
Resultados con MLP

Entrenando red 1 con capas [4088, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6880, Test Loss: 0.6632, F1: 0.3432, AUC: 0.8846
Epoch [10/30] Train Loss: 0.1988, Test Loss: 0.5035, F1: 0.3916, AUC: 0.8982
Epoch [20/30] Train Loss: 0.0665, Test Loss: 0.4879, F1: 0.4114, AUC: 0.8914
Mejores resultados en la época:  1
f1-score 0.43705463182897863
AUC según el mejor F1-score 0.9008875838144131
Confusion Matrix:
 [[1135  218]
 [  19   92]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.8381
Precision:  0.2968
Recall:     0.8288
F1-score:   0.4371

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6924, Test Loss: 0.7573, F1: 0.1410, AUC: 0.8962
Epoch [10/30] Train Loss: 0.1985, Test Loss: 0.4671, F1: 0.4174, AUC: 0.8995
Epoch [20/30] Train Loss: 0.0667, Test Loss: 0.4546, F1: 0.4234, AUC: 0.8936
Mejores resultados en la época:  12
f1-score 0.4246575342465753
AUC según el mejor F1-score 0.8983573373817275
Confusion Matrix:
 [[1119  234]
 [  18   93]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.8279
Precision:  0.2844
Recall:     0.8378
F1-score:   0.4247

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6911, Test Loss: 0.7367, F1: 0.1410, AUC: 0.8905
Epoch [10/30] Train Loss: 0.1952, Test Loss: 0.4884, F1: 0.4069, AUC: 0.8985
Epoch [20/30] Train Loss: 0.0655, Test Loss: 0.4785, F1: 0.4123, AUC: 0.8911
Mejores resultados en la época:  19
f1-score 0.41409691629955947
AUC según el mejor F1-score 0.8915589647296964
Confusion Matrix:
 [[1104  249]
 [  17   94]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.8183
Precision:  0.2741
Recall:     0.8468
F1-score:   0.4141

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6910, Test Loss: 0.7505, F1: 0.1410, AUC: 0.9044
Epoch [10/30] Train Loss: 0.1986, Test Loss: 0.5187, F1: 0.3854, AUC: 0.8972
Epoch [20/30] Train Loss: 0.0654, Test Loss: 0.4965, F1: 0.4060, AUC: 0.8911
Mejores resultados en la época:  17
f1-score 0.4078091106290672
AUC según el mejor F1-score 0.8924312338946485
Confusion Matrix:
 [[1097  256]
 [  17   94]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.8135
Precision:  0.2686
Recall:     0.8468
F1-score:   0.4078
Tiempo total para red 1: 24.73 segundos

Entrenando red 2 con capas [4088, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6928, Test Loss: 0.7382, F1: 0.1410, AUC: 0.8872
Epoch [10/30] Train Loss: 0.0303, Test Loss: 0.5643, F1: 0.3949, AUC: 0.8883
Epoch [20/30] Train Loss: 0.0081, Test Loss: 0.7249, F1: 0.3817, AUC: 0.8815
Mejores resultados en la época:  8
f1-score 0.41797752808988764
AUC según el mejor F1-score 0.8921249409054286
Confusion Matrix:
 [[1112  241]
 [  18   93]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8231
Precision:  0.2784
Recall:     0.8378
F1-score:   0.4180

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6902, Test Loss: 0.6722, F1: 0.2286, AUC: 0.9008
Epoch [10/30] Train Loss: 0.0328, Test Loss: 0.5167, F1: 0.4105, AUC: 0.8895
Epoch [20/30] Train Loss: 0.0084, Test Loss: 0.6579, F1: 0.3966, AUC: 0.8807
Mejores resultados en la época:  1
f1-score 0.48467966573816157
AUC según el mejor F1-score 0.9074062976502002
Confusion Matrix:
 [[1192  161]
 [  24   87]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8736
Precision:  0.3508
Recall:     0.7838
F1-score:   0.4847

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6929, Test Loss: 0.7339, F1: 0.1410, AUC: 0.8894
Epoch [10/30] Train Loss: 0.0300, Test Loss: 0.4821, F1: 0.4309, AUC: 0.8871
Epoch [20/30] Train Loss: 0.0080, Test Loss: 0.6660, F1: 0.3948, AUC: 0.8779
Mejores resultados en la época:  3
f1-score 0.5
AUC según el mejor F1-score 0.9021527070307557
Confusion Matrix:
 [[1206  147]
 [  25   86]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8825
Precision:  0.3691
Recall:     0.7748
F1-score:   0.5000

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6900, Test Loss: 0.6496, F1: 0.1290, AUC: 0.8869
Epoch [10/30] Train Loss: 0.0311, Test Loss: 0.5457, F1: 0.4132, AUC: 0.8910
Epoch [20/30] Train Loss: 0.0078, Test Loss: 0.7139, F1: 0.4017, AUC: 0.8843
Mejores resultados en la época:  1
f1-score 0.4915254237288136
AUC según el mejor F1-score 0.8996224605980704
Confusion Matrix:
 [[1197  156]
 [  24   87]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8770
Precision:  0.3580
Recall:     0.7838
F1-score:   0.4915
Tiempo total para red 2: 23.43 segundos

Entrenando red 3 con capas [4088, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6921, Test Loss: 0.7213, F1: 0.1410, AUC: 0.9002
Epoch [10/30] Train Loss: 0.0095, Test Loss: 0.8403, F1: 0.3882, AUC: 0.8842
Epoch [20/30] Train Loss: 0.0048, Test Loss: 0.9686, F1: 0.3874, AUC: 0.8820
Mejores resultados en la época:  4
f1-score 0.4504950495049505
AUC según el mejor F1-score 0.8957205542571396
Confusion Matrix:
 [[1151  202]
 [  20   91]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8484
Precision:  0.3106
Recall:     0.8198
F1-score:   0.4505

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6932, Test Loss: 0.7373, F1: 0.1410, AUC: 0.8959
Epoch [10/30] Train Loss: 0.0094, Test Loss: 0.7267, F1: 0.4035, AUC: 0.8791
Epoch [20/30] Train Loss: 0.0053, Test Loss: 0.7945, F1: 0.4147, AUC: 0.8751
Mejores resultados en la época:  3
f1-score 0.49853372434017595
AUC según el mejor F1-score 0.8971022019802507
Confusion Matrix:
 [[1208  145]
 [  26   85]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8832
Precision:  0.3696
Recall:     0.7658
F1-score:   0.4985

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6914, Test Loss: 0.6874, F1: 0.4248, AUC: 0.8875
Epoch [10/30] Train Loss: 0.0070, Test Loss: 0.7366, F1: 0.3957, AUC: 0.8806
Epoch [20/30] Train Loss: 0.0057, Test Loss: 0.9321, F1: 0.3717, AUC: 0.8780
Mejores resultados en la época:  27
f1-score 0.4509283819628647
AUC según el mejor F1-score 0.8765239740849496
Confusion Matrix:
 [[1172  181]
 [  26   85]]
For TF-IDF embbedings you are selecteing this columns:
--> ['artist', 'genre', 'title_songs_new']
For both embbedings your are adding this categorical columns: 
--> CAT_ALL 3 ['title_songs_new', 'artist', 'genre']

CAT_LOW 1 ['title_songs_new']
CAT_HIGH 2 ['artist', 'genre']
For both embbedings your are adding this columns: 
--> ['lyrics_word_count', 'popularity', 'duration_ms']
You are executing with [ALL] dataset
--> PaTH:  ../../../../../../data/spanish/LB_M/LB_fuss/lb_khipu_M.npy
Contaning the categorical cols
Preprocessing text...
Label distribution: {False: 6765, True: 554}

Splitting data (index-based split to avoid leakage)...
X_train_Numeric:  (5855, 3)
X_train_Numeric:  (5855, 3)
Concatenating TF-IDF and numeric features...
Shape of X_train after concatenation:  (5855, 4088)
Shape of X_test after concatenation:  (1464, 4088)
Shape of y_train:  (5855,)
Shape of y_test:  (1464,)

Data con el spliting...
Label distribution en TRAIN: {0: 5412, 1: 443}
Label distribution en TEST: {0: 1353, 1: 111}


==================================================
Data antes del undersampling ...
X: (5855, 4088)
y: (5855,)
Apliying UNDERSAMPLE
443
Label distribution: {0: 443, 1: 443}
X shape: (886, 4088)
y shape: (886,)
Resultados con MLP

Entrenando red 1 con capas [4088, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6882, Test Loss: 0.6746, F1: 0.5188, AUC: 0.9068
Epoch [10/30] Train Loss: 0.1949, Test Loss: 0.4436, F1: 0.4286, AUC: 0.9010
Epoch [20/30] Train Loss: 0.0655, Test Loss: 0.4469, F1: 0.4144, AUC: 0.8930
Mejores resultados en la época:  0
f1-score 0.5188284518828452
AUC según el mejor F1-score 0.9067937116717604
Confusion Matrix:
 [[1287   66]
 [  49   62]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.9214
Precision:  0.4844
Recall:     0.5586
F1-score:   0.5188

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6903, Test Loss: 0.6459, F1: 0.0526, AUC: 0.8705
Epoch [10/30] Train Loss: 0.1980, Test Loss: 0.4900, F1: 0.3957, AUC: 0.8983
Epoch [20/30] Train Loss: 0.0662, Test Loss: 0.4761, F1: 0.4114, AUC: 0.8908
Mejores resultados en la época:  1
f1-score 0.4940239043824701
AUC según el mejor F1-score 0.8949215290678705
Confusion Matrix:
 [[1275   78]
 [  49   62]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.9133
Precision:  0.4429
Recall:     0.5586
F1-score:   0.4940

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6897, Test Loss: 0.6502, F1: 0.0354, AUC: 0.8896
Epoch [10/30] Train Loss: 0.1959, Test Loss: 0.4811, F1: 0.4026, AUC: 0.8991
Epoch [20/30] Train Loss: 0.0653, Test Loss: 0.4722, F1: 0.4159, AUC: 0.8919
Mejores resultados en la época:  1
f1-score 0.5140562248995983
AUC según el mejor F1-score 0.9021060972280484
Confusion Matrix:
 [[1279   74]
 [  47   64]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.9173
Precision:  0.4638
Recall:     0.5766
F1-score:   0.5141

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6898, Test Loss: 0.7129, F1: 0.1426, AUC: 0.9062
Epoch [10/30] Train Loss: 0.1987, Test Loss: 0.4413, F1: 0.4358, AUC: 0.9009
Epoch [20/30] Train Loss: 0.0663, Test Loss: 0.4510, F1: 0.4187, AUC: 0.8938
Mejores resultados en la época:  7
f1-score 0.44768856447688565
AUC según el mejor F1-score 0.9028119028119028
Confusion Matrix:
 [[1145  208]
 [  19   92]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_130881.png
Accuracy:   0.8449
Precision:  0.3067
Recall:     0.8288
F1-score:   0.4477
Tiempo total para red 1: 24.74 segundos

Entrenando red 2 con capas [4088, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6912, Test Loss: 0.6986, F1: 0.1517, AUC: 0.8853
Epoch [10/30] Train Loss: 0.0314, Test Loss: 0.5272, F1: 0.4114, AUC: 0.8912
Epoch [20/30] Train Loss: 0.0082, Test Loss: 0.6899, F1: 0.3917, AUC: 0.8837
Mejores resultados en la época:  9
f1-score 0.4189189189189189
AUC según el mejor F1-score 0.8925777218460145
Confusion Matrix:
 [[1113  240]
 [  18   93]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8238
Precision:  0.2793
Recall:     0.8378
F1-score:   0.4189

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6898, Test Loss: 0.6956, F1: 0.1866, AUC: 0.8929
Epoch [10/30] Train Loss: 0.0328, Test Loss: 0.4780, F1: 0.4306, AUC: 0.8868
Epoch [20/30] Train Loss: 0.0086, Test Loss: 0.6537, F1: 0.3957, AUC: 0.8782
Mejores resultados en la época:  3
f1-score 0.5
AUC según el mejor F1-score 0.9031914397768056
Confusion Matrix:
 [[1206  147]
 [  25   86]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8825
Precision:  0.3691
Recall:     0.7748
F1-score:   0.5000

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6924, Test Loss: 0.7467, F1: 0.1410, AUC: 0.9055
Epoch [10/30] Train Loss: 0.0335, Test Loss: 0.5870, F1: 0.3892, AUC: 0.8887
Epoch [20/30] Train Loss: 0.0076, Test Loss: 0.7117, F1: 0.3882, AUC: 0.8815
Mejores resultados en la época:  9
f1-score 0.3991507430997877
AUC según el mejor F1-score 0.8912526717404766
Confusion Matrix:
 [[1087  266]
 [  17   94]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.8067
Precision:  0.2611
Recall:     0.8468
F1-score:   0.3992

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6920, Test Loss: 0.6542, F1: 0.0000, AUC: 0.9016
Epoch [10/30] Train Loss: 0.0322, Test Loss: 0.4868, F1: 0.4336, AUC: 0.8878
Epoch [20/30] Train Loss: 0.0085, Test Loss: 0.6988, F1: 0.3794, AUC: 0.8797
Mejores resultados en la época:  1
f1-score 0.5547945205479452
AUC según el mejor F1-score 0.909683519439617
Confusion Matrix:
 [[1253  100]
 [  30   81]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_263809.png
Accuracy:   0.9112
Precision:  0.4475
Recall:     0.7297
F1-score:   0.5548
Tiempo total para red 2: 23.45 segundos

Entrenando red 3 con capas [4088, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6923, Test Loss: 0.6746, F1: 0.0000, AUC: 0.9013
Epoch [10/30] Train Loss: 0.0082, Test Loss: 0.7754, F1: 0.3974, AUC: 0.8835
Epoch [20/30] Train Loss: 0.0045, Test Loss: 0.8923, F1: 0.3948, AUC: 0.8811
Mejores resultados en la época:  1
f1-score 0.48739495798319327
AUC según el mejor F1-score 0.904922661020222
Confusion Matrix:
 [[1194  159]
 [  24   87]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8750
Precision:  0.3537
Recall:     0.7838
F1-score:   0.4874

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6919, Test Loss: 0.7133, F1: 0.1410, AUC: 0.8954
Epoch [10/30] Train Loss: 0.0081, Test Loss: 0.9481, F1: 0.3640, AUC: 0.8804
Epoch [20/30] Train Loss: 0.0054, Test Loss: 1.0527, F1: 0.3651, AUC: 0.8782
Mejores resultados en la época:  28
f1-score 0.42298850574712643
AUC según el mejor F1-score 0.8777191825972314
Confusion Matrix:
 [[1121  232]
 [  19   92]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8286
Precision:  0.2840
Recall:     0.8288
F1-score:   0.4230

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6917, Test Loss: 0.7160, F1: 0.1410, AUC: 0.8971
Epoch [10/30] Train Loss: 0.0091, Test Loss: 0.8378, F1: 0.3676, AUC: 0.8795
Epoch [20/30] Train Loss: 0.0045, Test Loss: 1.0439, F1: 0.3529, AUC: 0.8776
Mejores resultados en la época:  2
f1-score 0.430622009569378
AUC según el mejor F1-score 0.902658756317293
Confusion Matrix:
 [[1136  217]
 [  21   90]]
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8586
Precision:  0.3195
Recall:     0.7658
F1-score:   0.4509

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6916, Test Loss: 0.6655, F1: 0.0526, AUC: 0.8996
Epoch [10/30] Train Loss: 0.0087, Test Loss: 0.7622, F1: 0.4053, AUC: 0.8837
Epoch [20/30] Train Loss: 0.0039, Test Loss: 0.8408, F1: 0.4128, AUC: 0.8807
Mejores resultados en la época:  1
f1-score 0.46194225721784776
AUC según el mejor F1-score 0.9073197365880293
Confusion Matrix:
 [[1171  182]
 [  23   88]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8600
Precision:  0.3259
Recall:     0.7928
F1-score:   0.4619
Tiempo total para red 3: 24.63 segundos

Entrenando red 4 con capas [4088, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6921, Test Loss: 0.6515, F1: 0.0000, AUC: 0.9055
Epoch [10/30] Train Loss: 0.0058, Test Loss: 0.8562, F1: 0.4262, AUC: 0.8853
Epoch [20/30] Train Loss: 0.0087, Test Loss: 1.0131, F1: 0.3898, AUC: 0.8843
Mejores resultados en la época:  3
f1-score 0.4918032786885246
AUC según el mejor F1-score 0.8984905082466058
Confusion Matrix:
 [[1188  165]
 [  21   90]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8730
Precision:  0.3529
Recall:     0.8108
F1-score:   0.4918

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6918, Test Loss: 0.6668, F1: 0.0000, AUC: 0.9045
Epoch [10/30] Train Loss: 0.0145, Test Loss: 0.7823, F1: 0.4116, AUC: 0.8767
Epoch [20/30] Train Loss: 0.0065, Test Loss: 0.9194, F1: 0.4089, AUC: 0.8768
Mejores resultados en la época:  1
f1-score 0.5745454545454546
AUC según el mejor F1-score 0.9079656152826885
Confusion Matrix:
 [[1268   85]
 [  32   79]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.9201
Precision:  0.4817
Recall:     0.7117
F1-score:   0.5745

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6937, Test Loss: 0.7298, F1: 0.1410, AUC: 0.9089
Epoch [10/30] Train Loss: 0.0109, Test Loss: 0.7979, F1: 0.4026, AUC: 0.8826
Epoch [20/30] Train Loss: 0.0045, Test Loss: 0.9210, F1: 0.4018, AUC: 0.8812
Mejores resultados en la época:  2
f1-score 0.49258160237388726
AUC según el mejor F1-score 0.9000219731927047
Confusion Matrix:
 [[1210  143]
 [  28   83]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8832
Precision:  0.3673
Recall:     0.7477
F1-score:   0.4926

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6912, Test Loss: 0.6891, F1: 0.3630, AUC: 0.8998
Epoch [10/30] Train Loss: 0.0100, Test Loss: 0.9722, F1: 0.3849, AUC: 0.8813
Epoch [20/30] Train Loss: 0.0046, Test Loss: 0.9882, F1: 0.3931, AUC: 0.8795
Mejores resultados en la época:  3
f1-score 0.5333333333333333
AUC según el mejor F1-score 0.8959536032706765
Confusion Matrix:
 [[1233  120]
 [  27   84]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8996
Precision:  0.4118
Recall:     0.7568
F1-score:   0.5333
Tiempo total para red 4: 27.62 segundos

Entrenando red 5 con capas [4088, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6854, Test Loss: 0.6885, F1: 0.3030, AUC: 0.9028
Epoch [10/30] Train Loss: 0.0069, Test Loss: 1.0138, F1: 0.3758, AUC: 0.8766
Epoch [20/30] Train Loss: 0.0093, Test Loss: 1.4159, F1: 0.3057, AUC: 0.8752
Mejores resultados en la época:  2
f1-score 0.5401929260450161
AUC según el mejor F1-score 0.8958570543936397
Confusion Matrix:
 [[1237  116]
 [  27   84]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9023
Precision:  0.4200
Recall:     0.7568
F1-score:   0.5402

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6900, Test Loss: 0.7031, F1: 0.1597, AUC: 0.9058
Epoch [10/30] Train Loss: 0.0067, Test Loss: 1.1222, F1: 0.3443, AUC: 0.8763
Epoch [20/30] Train Loss: 0.0052, Test Loss: 0.8629, F1: 0.4082, AUC: 0.8769
Mejores resultados en la época:  1
f1-score 0.49710982658959535
AUC según el mejor F1-score 0.9032713422957326
Confusion Matrix:
 [[1204  149]
 [  25   86]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.8811
Precision:  0.3660
Recall:     0.7748
F1-score:   0.4971

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6871, Test Loss: 0.6285, F1: 0.5421, AUC: 0.9046
Epoch [10/30] Train Loss: 0.0065, Test Loss: 0.9412, F1: 0.3827, AUC: 0.8791
Epoch [20/30] Train Loss: 0.0051, Test Loss: 0.9559, F1: 0.3851, AUC: 0.8788
Mejores resultados en la época:  0
f1-score 0.5420560747663551
AUC según el mejor F1-score 0.9046230265742461
Confusion Matrix:
 [[1308   45]
 [  53   58]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9331
Precision:  0.5631
Recall:     0.5225
F1-score:   0.5421

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6864, Test Loss: 0.6926, F1: 0.2625, AUC: 0.8991
Epoch [10/30] Train Loss: 0.0085, Test Loss: 0.9154, F1: 0.4320, AUC: 0.8836
Epoch [20/30] Train Loss: 0.0055, Test Loss: 1.0897, F1: 0.4053, AUC: 0.8831
Mejores resultados en la época:  2
f1-score 0.5263157894736842
AUC según el mejor F1-score 0.8915423183715866
Confusion Matrix:
 [[1240  113]
 [  31   80]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9016
Precision:  0.4145
Recall:     0.7207
F1-score:   0.5263
Tiempo total para red 5: 25.25 segundos

Entrenando red 6 con capas [4088, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6878, Test Loss: 0.6803, F1: 0.3401, AUC: 0.9033
Epoch [10/30] Train Loss: 0.0058, Test Loss: 1.2050, F1: 0.3877, AUC: 0.8791
Epoch [20/30] Train Loss: 0.0043, Test Loss: 1.1020, F1: 0.3929, AUC: 0.8784
Mejores resultados en la época:  1
f1-score 0.5074626865671642
AUC según el mejor F1-score 0.879939806769075
Confusion Matrix:
 [[1214  139]
 [  26   85]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8873
Precision:  0.3795
Recall:     0.7658
F1-score:   0.5075

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6903, Test Loss: 0.7064, F1: 0.1663, AUC: 0.8996
Epoch [10/30] Train Loss: 0.0062, Test Loss: 1.1041, F1: 0.3816, AUC: 0.8749
Epoch [20/30] Train Loss: 0.0036, Test Loss: 1.5495, F1: 0.3629, AUC: 0.8744
Mejores resultados en la época:  9
f1-score 0.38852097130242824
AUC según el mejor F1-score 0.8746296185320576
Confusion Matrix:
 [[1099  254]
 [  23   88]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8108
Precision:  0.2573
Recall:     0.7928
F1-score:   0.3885

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6915, Test Loss: 0.6593, F1: 0.0000, AUC: 0.9067
Epoch [10/30] Train Loss: 0.0078, Test Loss: 1.3301, F1: 0.3469, AUC: 0.8753
Epoch [20/30] Train Loss: 0.0044, Test Loss: 1.4175, F1: 0.3692, AUC: 0.8748
Mejores resultados en la época:  1
f1-score 0.46808510638297873
AUC según el mejor F1-score 0.9030849030849031
Confusion Matrix:
 [[1176  177]
 [  23   88]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8634
Precision:  0.3321
Recall:     0.7928
F1-score:   0.4681

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6889, Test Loss: 0.6778, F1: 0.3640, AUC: 0.8966
Epoch [10/30] Train Loss: 0.0080, Test Loss: 1.1320, F1: 0.3701, AUC: 0.8788
Epoch [20/30] Train Loss: 0.0067, Test Loss: 1.1520, F1: 0.3662, AUC: 0.8784
Mejores resultados en la época:  1
f1-score 0.4883720930232558
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8374
Precision:  0.2932
Recall:     0.8108
F1-score:   0.4306

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6912, Test Loss: 0.6778, F1: 0.4278, AUC: 0.9038
Epoch [10/30] Train Loss: 0.0094, Test Loss: 0.6193, F1: 0.4262, AUC: 0.8814
Epoch [20/30] Train Loss: 0.0038, Test Loss: 0.9726, F1: 0.3605, AUC: 0.8780
Mejores resultados en la época:  1
f1-score 0.5295950155763239
AUC según el mejor F1-score 0.9079656152826885
Confusion Matrix:
 [[1228  125]
 [  26   85]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_533761.png
Accuracy:   0.8969
Precision:  0.4048
Recall:     0.7658
F1-score:   0.5296
Tiempo total para red 3: 24.64 segundos

Entrenando red 4 con capas [4088, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6913, Test Loss: 0.7023, F1: 0.1418, AUC: 0.9003
Epoch [10/30] Train Loss: 0.0053, Test Loss: 0.9686, F1: 0.3890, AUC: 0.8818
Epoch [20/30] Train Loss: 0.0054, Test Loss: 0.9065, F1: 0.4165, AUC: 0.8808
Mejores resultados en la época:  3
f1-score 0.5056179775280899
AUC según el mejor F1-score 0.898110971281703
Confusion Matrix:
 [[1198  155]
 [  21   90]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8798
Precision:  0.3673
Recall:     0.8108
F1-score:   0.5056

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6935, Test Loss: 0.6514, F1: 0.0000, AUC: 0.8951
Epoch [10/30] Train Loss: 0.0085, Test Loss: 1.0866, F1: 0.3827, AUC: 0.8826
Epoch [20/30] Train Loss: 0.0047, Test Loss: 1.1109, F1: 0.3882, AUC: 0.8815
Mejores resultados en la época:  3
f1-score 0.4878048780487805
AUC según el mejor F1-score 0.897601592723544
Confusion Matrix:
 [[1185  168]
 [  21   90]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8709
Precision:  0.3488
Recall:     0.8108
F1-score:   0.4878

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6913, Test Loss: 0.6641, F1: 0.1148, AUC: 0.9028
Epoch [10/30] Train Loss: 0.0139, Test Loss: 0.8655, F1: 0.4272, AUC: 0.8804
Epoch [20/30] Train Loss: 0.0043, Test Loss: 1.0248, F1: 0.4000, AUC: 0.8796
Mejores resultados en la época:  3
f1-score 0.5069637883008357
AUC según el mejor F1-score 0.8954608710706272
Confusion Matrix:
 [[1196  157]
 [  20   91]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8791
Precision:  0.3669
Recall:     0.8198
F1-score:   0.5070

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6926, Test Loss: 0.6487, F1: 0.0000, AUC: 0.8998
Epoch [10/30] Train Loss: 0.0150, Test Loss: 1.0312, F1: 0.3461, AUC: 0.8772
Epoch [20/30] Train Loss: 0.0048, Test Loss: 0.9290, F1: 0.4035, AUC: 0.8767
Mejores resultados en la época:  1
f1-score 0.5151515151515151
AUC según el mejor F1-score 0.9083518107908352
Confusion Matrix:
 [[1219  134]
 [  26   85]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_1090049.png
Accuracy:   0.8907
Precision:  0.3881
Recall:     0.7658
F1-score:   0.5152
Tiempo total para red 4: 27.61 segundos

Entrenando red 5 con capas [4088, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6874, Test Loss: 0.6508, F1: 0.5197, AUC: 0.9004
Epoch [10/30] Train Loss: 0.0062, Test Loss: 1.1968, F1: 0.3413, AUC: 0.8780
Epoch [20/30] Train Loss: 0.0066, Test Loss: 1.1551, F1: 0.3619, AUC: 0.8792
Mejores resultados en la época:  0
f1-score 0.5197368421052632
AUC según el mejor F1-score 0.9004015101576076
Confusion Matrix:
 [[1239  114]
 [  32   79]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9003
Precision:  0.4093
Recall:     0.7117
F1-score:   0.5197

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6854, Test Loss: 0.6387, F1: 0.5703, AUC: 0.9072
Epoch [10/30] Train Loss: 0.0049, Test Loss: 0.8931, F1: 0.3914, AUC: 0.8793
Epoch [20/30] Train Loss: 0.0065, Test Loss: 0.9489, F1: 0.3974, AUC: 0.8791
Mejores resultados en la época:  0
f1-score 0.5703125
AUC según el mejor F1-score 0.9071665900934195
Confusion Matrix:
 [[1281   72]
 [  38   73]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9249
Precision:  0.5034
Recall:     0.6577
F1-score:   0.5703

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6878, Test Loss: 0.7031, F1: 0.1865, AUC: 0.8928
Epoch [10/30] Train Loss: 0.0069, Test Loss: 1.0221, F1: 0.3800, AUC: 0.8804
Epoch [20/30] Train Loss: 0.0076, Test Loss: 0.8921, F1: 0.4064, AUC: 0.8802
Mejores resultados en la época:  3
f1-score 0.5245901639344263
AUC según el mejor F1-score 0.8858326175399346
Confusion Matrix:
 [[1239  114]
 [  31   80]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.9010
Precision:  0.4124
Recall:     0.7207
F1-score:   0.5246

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6899, Test Loss: 0.7082, F1: 0.1417, AUC: 0.9004
Epoch [10/30] Train Loss: 0.0046, Test Loss: 1.2503, F1: 0.3219, AUC: 0.8745
Epoch [20/30] Train Loss: 0.0034, Test Loss: 0.9859, F1: 0.3747, AUC: 0.8752
Mejores resultados en la época:  1
f1-score 0.39751552795031053
AUC según el mejor F1-score 0.9047495388958804
Confusion Matrix:
 [[1077  276]
 [  15   96]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_2266113.png
Accuracy:   0.8012
Precision:  0.2581
Recall:     0.8649
F1-score:   0.3975
Tiempo total para red 5: 25.24 segundos

Entrenando red 6 con capas [4088, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6912, Test Loss: 0.6958, F1: 0.2080, AUC: 0.8952
Epoch [10/30] Train Loss: 0.0060, Test Loss: 1.4872, F1: 0.3400, AUC: 0.8723
Epoch [20/30] Train Loss: 0.0036, Test Loss: 2.1275, F1: 0.3327, AUC: 0.8713
Mejores resultados en la época:  3
f1-score 0.4690721649484536
AUC según el mejor F1-score 0.8894881577808407
Confusion Matrix:
 [[1167  186]
 [  20   91]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8593
Precision:  0.3285
Recall:     0.8198
F1-score:   0.4691

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6893, Test Loss: 0.6809, F1: 0.3796, AUC: 0.9044
Epoch [10/30] Train Loss: 0.0058, Test Loss: 1.0051, F1: 0.4444, AUC: 0.8853
Epoch [20/30] Train Loss: 0.0039, Test Loss: 1.5124, F1: 0.4248, AUC: 0.8844
Mejores resultados en la época:  1
f1-score 0.4883720930232558
AUC según el mejor F1-score 0.8670821597650866
Confusion Matrix:
 [[1204  149]
 [  27   84]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8798
Precision:  0.3605
Recall:     0.7568
F1-score:   0.4884

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6903, Test Loss: 0.6700, F1: 0.3738, AUC: 0.9039
Epoch [10/30] Train Loss: 0.0050, Test Loss: 1.1920, F1: 0.3922, AUC: 0.8816
Epoch [20/30] Train Loss: 0.0035, Test Loss: 1.4024, F1: 0.3732, AUC: 0.8810
Mejores resultados en la época:  2
f1-score 0.49283667621776506
AUC según el mejor F1-score 0.890490268539049
Confusion Matrix:
 [[1201  152]
 [  25   86]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8791
Precision:  0.3613
Recall:     0.7748
F1-score:   0.4928

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6900, Test Loss: 0.6656, F1: 0.5075, AUC: 0.9021
Epoch [10/30] Train Loss: 0.0103, Test Loss: 1.1109, F1: 0.3745, AUC: 0.8765
Epoch [20/30] Train Loss: 0.0043, Test Loss: 1.1981, F1: 0.3778, AUC: 0.8765
Mejores resultados en la época:  2
f1-score 0.5358255451713395
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:29:45] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:29:45] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
AUC según el mejor F1-score 0.8935831618758447
Confusion Matrix:
 [[1204  149]
 [  27   84]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8798
Precision:  0.3605
Recall:     0.7568
F1-score:   0.4884
Tiempo total para red 6: 27.53 segundos
Saved on: outputs_numerical_categorical_metadata/2/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.8381
Precision: 0.2941
Recall:    0.8108
F1-score:  0.4317
              precision    recall  f1-score   support

           0       0.98      0.84      0.91      1353
           1       0.29      0.81      0.43       111

    accuracy                           0.84      1464
   macro avg       0.64      0.83      0.67      1464
weighted avg       0.93      0.84      0.87      1464

[[1137  216]
 [  21   90]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.7746
Precision: 0.2269
Recall:    0.8198
F1-score:  0.3555
              precision    recall  f1-score   support

           0       0.98      0.77      0.86      1353
           1       0.23      0.82      0.36       111

    accuracy                           0.77      1464
   macro avg       0.60      0.80      0.61      1464
weighted avg       0.92      0.77      0.82      1464

[[1043  310]
 [  20   91]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8135
Precision: 0.2530
Recall:    0.7477
F1-score:  0.3781
              precision    recall  f1-score   support

           0       0.98      0.82      0.89      1353
           1       0.25      0.75      0.38       111

    accuracy                           0.81      1464
   macro avg       0.61      0.78      0.63      1464
weighted avg       0.92      0.81      0.85      1464

[[1108  245]
 [  28   83]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8586
Precision: 0.3273
Recall:    0.8198
F1-score:  0.4679
              precision    recall  f1-score   support

           0       0.98      0.86      0.92      1353
           1       0.33      0.82      0.47       111

    accuracy                           0.86      1464
   macro avg       0.66      0.84      0.69      1464
weighted avg       0.93      0.86      0.88      1464

[[1166  187]
 [  20   91]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.7985
Precision: 0.2486
Recall:    0.8198
F1-score:  0.3816
              precision    recall  f1-score   support

           0       0.98      0.80      0.88      1353
           1       0.25      0.82      0.38       111

    accuracy                           0.80      1464
   macro avg       0.62      0.81      0.63      1464
weighted avg       0.93      0.80      0.84      1464

[[1078  275]
 [  20   91]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.7657
Precision: 0.2264
Recall:    0.8649
F1-score:  0.3589
              precision    recall  f1-score   support

           0       0.99      0.76      0.86      1353
           1       0.23      0.86      0.36       111

    accuracy                           0.77      1464
   macro avg       0.61      0.81      0.61      1464
weighted avg       0.93      0.77      0.82      1464

[[1025  328]
 [  15   96]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/naive_bayes_model.pkl


Resumen de métricas:
Random Forest: {'accuracy': 0.8586, 'precision': 0.3273, 'recall': 0.8198, 'f1_score': 0.4679}
Logistic Regression: {'accuracy': 0.8381, 'precision': 0.2941, 'recall': 0.8108, 'f1_score': 0.4317}
XGBoost: {'accuracy': 0.7985, 'precision': 0.2486, 'recall': 0.8198, 'f1_score': 0.3816}
Decision Tree: {'accuracy': 0.8135, 'precision': 0.253, 'recall': 0.7477, 'f1_score': 0.3781}
Naive Bayes: {'accuracy': 0.7657, 'precision': 0.2264, 'recall': 0.8649, 'f1_score': 0.3589}
SVM: {'accuracy': 0.7746, 'precision': 0.2269, 'recall': 0.8198, 'f1_score': 0.3555}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_1090049: {'accuracy': 0.8995901639344263, 'precision': 0.4117647058823529, 'recall': 0.7567567567567568, 'f1_score': 0.5745454545454546, 'f1_score_avg': 0.5230659172352999}
MLP_2266113: {'accuracy': 0.9016393442622951, 'precision': 0.41450777202072536, 'recall': 0.7207207207207207, 'f1_score': 0.5745454545454546, 'f1_score_avg': 0.5264186542186626}
MLP_4886529: {'accuracy': 0.8797814207650273, 'precision': 0.3605150214592275, 'recall': 0.7567567567567568, 'f1_score': 0.5745454545454546, 'f1_score_avg': 0.4631102143189567}
MLP_263809: {'accuracy': 0.8770491803278688, 'precision': 0.35802469135802467, 'recall': 0.7837837837837838, 'f1_score': 0.5, 'f1_score_avg': 0.4735456543892157}
MLP_533761: {'accuracy': 0.8599726775956285, 'precision': 0.32592592592592595, 'recall': 0.7927927927927928, 'f1_score': 0.5, 'f1_score_avg': 0.4654748532564597}
Random Forest: {'accuracy': 0.8586, 'precision': 0.3273, 'recall': 0.8198, 'f1_score': 0.4679}
MLP_130881: {'accuracy': 0.8135245901639344, 'precision': 0.26857142857142857, 'recall': 0.8468468468468469, 'f1_score': 0.43705463182897863, 'f1_score_avg': 0.4209045482510452}
Logistic Regression: {'accuracy': 0.8381, 'precision': 0.2941, 'recall': 0.8108, 'f1_score': 0.4317}
XGBoost: {'accuracy': 0.7985, 'precision': 0.2486, 'recall': 0.8198, 'f1_score': 0.3816}
Decision Tree: {'accuracy': 0.8135, 'precision': 0.253, 'recall': 0.7477, 'f1_score': 0.3781}
Naive Bayes: {'accuracy': 0.7657, 'precision': 0.2264, 'recall': 0.8649, 'f1_score': 0.3589}
SVM: {'accuracy': 0.7746, 'precision': 0.2269, 'recall': 0.8198, 'f1_score': 0.3555}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['artist', 'genre', 'title_songs_new']
Numeric Columns: ['lyrics_word_count', 'popularity', 'duration_ms']
====================================

AUC según el mejor F1-score 0.8913425620742693
Confusion Matrix:
 [[1229  124]
 [  25   86]]
Matriz de confusión guardada en: outputs_numerical_categorical_metadata/2/tfidf/confusion_matrix_param_4886529.png
Accuracy:   0.8982
Precision:  0.4095
Recall:     0.7748
F1-score:   0.5358
Tiempo total para red 6: 27.54 segundos
Saved on: outputs_numerical_categorical_metadata/2/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.8381
Precision: 0.2941
Recall:    0.8108
F1-score:  0.4317
              precision    recall  f1-score   support

           0       0.98      0.84      0.91      1353
           1       0.29      0.81      0.43       111

    accuracy                           0.84      1464
   macro avg       0.64      0.83      0.67      1464
weighted avg       0.93      0.84      0.87      1464

[[1137  216]
 [  21   90]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.7746
Precision: 0.2269
Recall:    0.8198
F1-score:  0.3555
              precision    recall  f1-score   support

           0       0.98      0.77      0.86      1353
           1       0.23      0.82      0.36       111

    accuracy                           0.77      1464
   macro avg       0.60      0.80      0.61      1464
weighted avg       0.92      0.77      0.82      1464

[[1043  310]
 [  20   91]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8135
Precision: 0.2530
Recall:    0.7477
F1-score:  0.3781
              precision    recall  f1-score   support

           0       0.98      0.82      0.89      1353
           1       0.25      0.75      0.38       111

    accuracy                           0.81      1464
   macro avg       0.61      0.78      0.63      1464
weighted avg       0.92      0.81      0.85      1464

[[1108  245]
 [  28   83]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8586
Precision: 0.3273
Recall:    0.8198
F1-score:  0.4679
              precision    recall  f1-score   support

           0       0.98      0.86      0.92      1353
           1       0.33      0.82      0.47       111

    accuracy                           0.86      1464
   macro avg       0.66      0.84      0.69      1464
weighted avg       0.93      0.86      0.88      1464

[[1166  187]
 [  20   91]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.7985
Precision: 0.2486
Recall:    0.8198
F1-score:  0.3816
              precision    recall  f1-score   support

           0       0.98      0.80      0.88      1353
           1       0.25      0.82      0.38       111

    accuracy                           0.80      1464
   macro avg       0.62      0.81      0.63      1464
weighted avg       0.93      0.80      0.84      1464

[[1078  275]
 [  20   91]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.7657
Precision: 0.2264
Recall:    0.8649
F1-score:  0.3589
              precision    recall  f1-score   support

           0       0.99      0.76      0.86      1353
           1       0.23      0.86      0.36       111

    accuracy                           0.77      1464
   macro avg       0.61      0.81      0.61      1464
weighted avg       0.93      0.77      0.82      1464

[[1025  328]
 [  15   96]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_numerical_categorical_metadata/2/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_numerical_categorical_metadata/2/tfidf/naive_bayes_model.pkl


Resumen de métricas:
Random Forest: {'accuracy': 0.8586, 'precision': 0.3273, 'recall': 0.8198, 'f1_score': 0.4679}
Logistic Regression: {'accuracy': 0.8381, 'precision': 0.2941, 'recall': 0.8108, 'f1_score': 0.4317}
XGBoost: {'accuracy': 0.7985, 'precision': 0.2486, 'recall': 0.8198, 'f1_score': 0.3816}
Decision Tree: {'accuracy': 0.8135, 'precision': 0.253, 'recall': 0.7477, 'f1_score': 0.3781}
Naive Bayes: {'accuracy': 0.7657, 'precision': 0.2264, 'recall': 0.8649, 'f1_score': 0.3589}
SVM: {'accuracy': 0.7746, 'precision': 0.2269, 'recall': 0.8198, 'f1_score': 0.3555}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_2266113: {'accuracy': 0.8012295081967213, 'precision': 0.25806451612903225, 'recall': 0.8648648648648649, 'f1_score': 0.5703125, 'f1_score_avg': 0.5030387584975}
MLP_4886529: {'accuracy': 0.898224043715847, 'precision': 0.4095238095238095, 'recall': 0.7747747747747747, 'f1_score': 0.5703125, 'f1_score_avg': 0.4965266198402035}
MLP_263809: {'accuracy': 0.9112021857923497, 'precision': 0.44751381215469616, 'recall': 0.7297297297297297, 'f1_score': 0.5547945205479452, 'f1_score_avg': 0.4682160456416629}
MLP_533761: {'accuracy': 0.8968579234972678, 'precision': 0.40476190476190477, 'recall': 0.7657657657657657, 'f1_score': 0.5547945205479452, 'f1_score_avg': 0.46765012221900537}
MLP_1090049: {'accuracy': 0.8907103825136612, 'precision': 0.3881278538812785, 'recall': 0.7657657657657657, 'f1_score': 0.5547945205479452, 'f1_score_avg': 0.5038845397573053}
MLP_130881: {'accuracy': 0.8449453551912568, 'precision': 0.30666666666666664, 'recall': 0.8288288288288288, 'f1_score': 0.5188284518828452, 'f1_score_avg': 0.4936492864104498}
Random Forest: {'accuracy': 0.8586, 'precision': 0.3273, 'recall': 0.8198, 'f1_score': 0.4679}
Logistic Regression: {'accuracy': 0.8381, 'precision': 0.2941, 'recall': 0.8108, 'f1_score': 0.4317}
XGBoost: {'accuracy': 0.7985, 'precision': 0.2486, 'recall': 0.8198, 'f1_score': 0.3816}
Decision Tree: {'accuracy': 0.8135, 'precision': 0.253, 'recall': 0.7477, 'f1_score': 0.3781}
Naive Bayes: {'accuracy': 0.7657, 'precision': 0.2264, 'recall': 0.8649, 'f1_score': 0.3589}
SVM: {'accuracy': 0.7746, 'precision': 0.2269, 'recall': 0.8198, 'f1_score': 0.3555}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['artist', 'genre', 'title_songs_new']
Numeric Columns: ['lyrics_word_count', 'popularity', 'duration_ms']
====================================

