2025-09-30 23:44:25.087592: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-30 23:44:25.087591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
CAT_LOW 3 ['emotion', 'Key', 'Time signature']
CAT_HIGH 14 ['Artist(s)', 'song', 'Length', 'Genre', 'Album', 'Loudness (db)', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For TF-IDF embbedings you are selecteing this columns:
--> ['text']
For both embbedings your are adding this columns: 
--> ['Release Date', 'Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
--> PaTH:  ../../data/new_embbedings_khipu/LB_fuss/lb_khipu_T.npy
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 7085)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 7131)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 7131)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [7131, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5975, Test Loss: 0.5003, F1: 0.6555, AUC: 0.8775
Epoch [10/30] Train Loss: 0.3284, Test Loss: 0.4017, F1: 0.7125, AUC: 0.9200
Epoch [20/30] Train Loss: 0.2938, Test Loss: 0.3542, F1: 0.7319, AUC: 0.9201
Mejores resultados en la época:  29
f1-score 0.7411106671993608
AUC según el mejor F1-score 0.9187945065525416
Confusion Matrix:
 [[15323  1142]
 [ 1450  3710]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.8801
Precision:  0.7646
Recall:     0.7190
F1-score:   0.7411

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5832, Test Loss: 0.5758, F1: 0.5991, AUC: 0.8815
Epoch [10/30] Train Loss: 0.3147, Test Loss: 0.3169, F1: 0.7407, AUC: 0.9235
Epoch [20/30] Train Loss: 0.2605, Test Loss: 0.3302, F1: 0.7452, AUC: 0.9286
Mejores resultados en la época:  24
f1-score 0.7646571560055223
AUC según el mejor F1-score 0.9283587042752185
Confusion Matrix:
 [[14914  1551]
 [ 1006  4154]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.8818
Precision:  0.7281
Recall:     0.8050
F1-score:   0.7647

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5873, Test Loss: 0.3897, F1: 0.6458, AUC: 0.8776
Epoch [10/30] Train Loss: 0.3230, Test Loss: 0.3306, F1: 0.7366, AUC: 0.9213
Epoch [20/30] Train Loss: 0.2746, Test Loss: 0.3116, F1: 0.7476, AUC: 0.9240
Mejores resultados en la época:  28
f1-score 0.7569706450722371
AUC según el mejor F1-score 0.9263249917019188
Confusion Matrix:
 [[14871  1594]
 [ 1047  4113]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.8779
Precision:  0.7207
Recall:     0.7971
F1-score:   0.7570

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6501, Test Loss: 0.5520, F1: 0.6578, AUC: 0.8658
Epoch [10/30] Train Loss: 0.3396, Test Loss: 0.3390, F1: 0.7354, AUC: 0.9161
Epoch [20/30] Train Loss: 0.2973, Test Loss: 0.3688, F1: 0.7291, AUC: 0.9180
Mejores resultados en la época:  24
f1-score 0.7448302029975337
AUC según el mejor F1-score 0.9196080068832877
Confusion Matrix:
 [[15009  1456]
 [ 1234  3926]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.8756
Precision:  0.7295
Recall:     0.7609
F1-score:   0.7448
Tiempo total para red 1: 912.13 segundos

Entrenando red 2 con capas [7131, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5249, Test Loss: 0.4155, F1: 0.6973, AUC: 0.8970
Epoch [10/30] Train Loss: 0.3058, Test Loss: 0.3277, F1: 0.7378, AUC: 0.9207
Epoch [20/30] Train Loss: 0.2528, Test Loss: 0.3145, F1: 0.7593, AUC: 0.9288
Mejores resultados en la época:  21
f1-score 0.7636330476016779
AUC según el mejor F1-score 0.9284069567346286
Confusion Matrix:
 [[14846  1619]
 [  973  4187]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8801
Precision:  0.7212
Recall:     0.8114
F1-score:   0.7636

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5276, Test Loss: 0.3814, F1: 0.7119, AUC: 0.8971
Epoch [10/30] Train Loss: 0.3080, Test Loss: 0.3188, F1: 0.7395, AUC: 0.9215
Epoch [20/30] Train Loss: 0.2720, Test Loss: 0.3307, F1: 0.7426, AUC: 0.9254
Mejores resultados en la época:  27
f1-score 0.7660731021555763
AUC según el mejor F1-score 0.9284560919686344
Confusion Matrix:
 [[15042  1423]
 [ 1073  4087]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8846
Precision:  0.7417
Recall:     0.7921
F1-score:   0.7661

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5042, Test Loss: 0.3819, F1: 0.7121, AUC: 0.9016
Epoch [10/30] Train Loss: 0.2897, Test Loss: 0.3004, F1: 0.7501, AUC: 0.9254
Epoch [20/30] Train Loss: 0.2371, Test Loss: 0.4103, F1: 0.7305, AUC: 0.9340
Mejores resultados en la época:  21
f1-score 0.7739083363406712
AUC según el mejor F1-score 0.93369792512659
Confusion Matrix:
 [[14830  1635]
 [  871  4289]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8841
Precision:  0.7240
Recall:     0.8312
F1-score:   0.7739

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5406, Test Loss: 0.5290, F1: 0.6417, AUC: 0.8949
Epoch [10/30] Train Loss: 0.3050, Test Loss: 0.3172, F1: 0.7442, AUC: 0.9242
Epoch [20/30] Train Loss: 0.2403, Test Loss: 0.2854, F1: 0.7695, AUC: 0.9299
Mejores resultados en la época:  28
f1-score 0.7812288340590228
AUC según el mejor F1-score 0.9301242005004744
Confusion Matrix:
 [[15327  1138]
 [ 1123  4037]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8954
CAT_LOW 3 ['emotion', 'Key', 'Time signature']
CAT_HIGH 14 ['Artist(s)', 'song', 'Length', 'Genre', 'Album', 'Loudness (db)', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For TF-IDF embbedings you are selecteing this columns:
--> ['text']
For both embbedings your are adding this columns: 
--> ['Release Date', 'Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
--> PaTH:  ../../data/new_embbedings_khipu/LB_fuss/lb_khipu_T.npy
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 7085)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 7131)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 7131)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [7131, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6934, Test Loss: 0.6907, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6934, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6923, F1: 0.0000, AUC: 0.5000
Mejores resultados en la época:  1
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6944, Test Loss: 0.7003, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6915, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6943, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5596, Test Loss: 0.5040, F1: 0.6563, AUC: 0.8870
Epoch [10/30] Train Loss: 0.3229, Test Loss: 0.4641, F1: 0.6830, AUC: 0.9202
Epoch [20/30] Train Loss: 0.2954, Test Loss: 0.4909, F1: 0.6738, AUC: 0.9189
Mejores resultados en la época:  17
f1-score 0.7429809870948675
AUC según el mejor F1-score 0.9195018679510449
Confusion Matrix:
 [[15245  1220]
 [ 1389  3771]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.8794
Precision:  0.7556
Recall:     0.7308
F1-score:   0.7430

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6937, Test Loss: 0.6920, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6957, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6935, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  1
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_228257.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853
Tiempo total para red 1: 911.82 segundos

Entrenando red 2 con capas [7131, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5352, Test Loss: 0.6044, F1: 0.5976, AUC: 0.8953
Epoch [10/30] Train Loss: 0.3076, Test Loss: 0.3685, F1: 0.7221, AUC: 0.9198
Epoch [20/30] Train Loss: 0.2637, Test Loss: 0.3655, F1: 0.7226, AUC: 0.9199
Mejores resultados en la época:  21
f1-score 0.7522772277227723
AUC según el mejor F1-score 0.9241527247132159
Confusion Matrix:
 [[15324  1141]
 [ 1361  3799]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8843
Precision:  0.7690
Recall:     0.7362
F1-score:   0.7523

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5232, Test Loss: 0.4303, F1: 0.6927, AUC: 0.8980
Epoch [10/30] Train Loss: 0.2894, Test Loss: 0.3045, F1: 0.7546, AUC: 0.9268
Epoch [20/30] Train Loss: 0.2462, Test Loss: 0.3052, F1: 0.7590, AUC: 0.9317
Mejores resultados en la época:  27
f1-score 0.7691877273151171
AUC según el mejor F1-score 0.9292783258827157
Confusion Matrix:
 [[15026  1439]
 [ 1036  4124]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8855
Precision:  0.7413
Recall:     0.7992
F1-score:   0.7692

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5395, Test Loss: 0.3477, F1: 0.7019, AUC: 0.8949
Epoch [10/30] Train Loss: 0.3062, Test Loss: 0.3235, F1: 0.7404, AUC: 0.9206
Epoch [20/30] Train Loss: 0.2628, Test Loss: 0.5477, F1: 0.6482, AUC: 0.9266
Mejores resultados en la época:  25
f1-score 0.7628037758586061
AUC según el mejor F1-score 0.9289815841448974
Confusion Matrix:
 [[15465  1000]
 [ 1362  3798]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8908
Precision:  0.7916
Recall:     0.7360
F1-score:   0.7628

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5378, Test Loss: 0.3907, F1: 0.7083, AUC: 0.8952
Epoch [10/30] Train Loss: 0.3092, Test Loss: 0.5167, F1: 0.6499, AUC: 0.9216
Epoch [20/30] Train Loss: 0.2508, Test Loss: 0.3062, F1: 0.7573, AUC: 0.9279
Mejores resultados en la época:  25
f1-score 0.7719507350019865
AUC según el mejor F1-score 0.9324884121121382
Confusion Matrix:
 [[15443  1022]
 [ 1274  3886]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_458561.png
Accuracy:   0.8938
Precision:  0.7918
Recall:     0.7531
Precision:  0.7801
Recall:     0.7824
F1-score:   0.7812
Tiempo total para red 2: 921.44 segundos

Entrenando red 3 con capas [7131, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4950, Test Loss: 0.5652, F1: 0.6174, AUC: 0.9051
Epoch [10/30] Train Loss: 0.3070, Test Loss: 0.5982, F1: 0.6186, AUC: 0.9217
Epoch [20/30] Train Loss: 0.2491, Test Loss: 0.3295, F1: 0.7532, AUC: 0.9306
Mejores resultados en la época:  22
f1-score 0.7702783897456439
AUC según el mejor F1-score 0.9314221381036119
Confusion Matrix:
 [[15485   980]
 [ 1314  3846]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8939
Precision:  0.7969
Recall:     0.7453
F1-score:   0.7703

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5159, Test Loss: 0.4595, F1: 0.6795, AUC: 0.9007
Epoch [10/30] Train Loss: 0.3027, Test Loss: 0.3776, F1: 0.7179, AUC: 0.9245
Epoch [20/30] Train Loss: 0.2353, Test Loss: 0.6199, F1: 0.6647, AUC: 0.9307
Mejores resultados en la época:  22
f1-score 0.7760063770426465
AUC según el mejor F1-score 0.9303282273650709
Confusion Matrix:
 [[15483   982]
 [ 1266  3894]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8960
Precision:  0.7986
Recall:     0.7547
F1-score:   0.7760

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5028, Test Loss: 0.6332, F1: 0.5756, AUC: 0.9025
Epoch [10/30] Train Loss: 0.3106, Test Loss: 0.3097, F1: 0.7404, AUC: 0.9210
Epoch [20/30] Train Loss: 0.2514, Test Loss: 0.3190, F1: 0.7574, AUC: 0.9298
Mejores resultados en la época:  21
f1-score 0.7643393806120579
AUC según el mejor F1-score 0.9302692697923948
Confusion Matrix:
 [[14882  1583]
 [  989  4171]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8811
Precision:  0.7249
Recall:     0.8083
F1-score:   0.7643

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5121, Test Loss: 0.4116, F1: 0.7020, AUC: 0.9004
Epoch [10/30] Train Loss: 0.3029, Test Loss: 0.3193, F1: 0.7414, AUC: 0.9229
Epoch [20/30] Train Loss: 0.2366, Test Loss: 0.3818, F1: 0.7429, AUC: 0.9287
Mejores resultados en la época:  24
f1-score 0.7728664370455415
AUC según el mejor F1-score 0.9313128800344634
Confusion Matrix:
 [[15212  1253]
 [ 1121  4039]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8902
Precision:  0.7632
Recall:     0.7828
F1-score:   0.7729
Tiempo total para red 3: 954.61 segundos

Entrenando red 4 con capas [7131, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5129, Test Loss: 0.4737, F1: 0.6705, AUC: 0.9017
Epoch [10/30] Train Loss: 0.3022, Test Loss: 0.6790, F1: 0.6386, AUC: 0.9250
Epoch [20/30] Train Loss: 0.2458, Test Loss: 0.3784, F1: 0.7364, AUC: 0.9333
Mejores resultados en la época:  28
f1-score 0.777191328934967
AUC según el mejor F1-score 0.930842155194128
Confusion Matrix:
 [[15138  1327]
 [ 1037  4123]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8907
Precision:  0.7565
Recall:     0.7990
F1-score:   0.7772

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5177, Test Loss: 0.4051, F1: 0.7021, AUC: 0.8997
Epoch [10/30] Train Loss: 0.3016, Test Loss: 0.3397, F1: 0.7311, AUC: 0.9229
Epoch [20/30] Train Loss: 0.2459, Test Loss: 0.3511, F1: 0.7448, AUC: 0.9280
Mejores resultados en la época:  19
f1-score 0.7661570209173624
AUC según el mejor F1-score 0.9295667930799888
Confusion Matrix:
 [[15048  1417]
 [ 1076  4084]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8847
Precision:  0.7424
Recall:     0.7915
F1-score:   0.7662

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5216, Test Loss: 0.3512, F1: 0.7138, AUC: 0.8992
Epoch [10/30] Train Loss: 0.2933, Test Loss: 0.3260, F1: 0.7484, AUC: 0.9263
Epoch [20/30] Train Loss: 0.2317, Test Loss: 0.2841, F1: 0.7744, AUC: 0.9324
Mejores resultados en la época:  27
f1-score 0.7802830649097121
AUC según el mejor F1-score 0.9320958187087007
Confusion Matrix:
 [[15377  1088]
 [ 1163  3997]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8959
Precision:  0.7860
Recall:     0.7746
F1-score:   0.7803

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5427, Test Loss: 0.3902, F1: 0.7062, AUC: 0.8967
Epoch [10/30] Train Loss: 0.2959, Test Loss: 0.5220, F1: 0.6546, AUC: 0.9247
Epoch [20/30] Train Loss: 0.2392, Test Loss: 0.3125, F1: 0.7649, AUC: 0.9312
Mejores resultados en la época:  27
f1-score 0.7755692085290928
AUC según el mejor F1-score 0.9334464520700475
Confusion Matrix:
 [[14849  1616]
 [  868  4292]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8851
Precision:  0.7265
Recall:     0.8318
F1-score:   0.7756
Tiempo total para red 4: 988.93 segundos

Entrenando red 5 con capas [7131, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5058, Test Loss: 0.4866, F1: 0.6645, AUC: 0.9033
Epoch [10/30] Train Loss: 0.3040, Test Loss: 0.3227, F1: 0.7401, AUC: 0.9221
Epoch [20/30] Train Loss: 0.2397, Test Loss: 0.3980, F1: 0.7274, AUC: 0.9283
Mejores resultados en la época:  29
f1-score 0.7748243782039111
AUC según el mejor F1-score 0.9308195679348019
Confusion Matrix:
 [[15172  1293]
 [ 1079  4081]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8903
Precision:  0.7594
Recall:     0.7909
F1-score:   0.7748

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4938, Test Loss: 0.6165, F1: 0.5958, AUC: 0.9048
Epoch [10/30] Train Loss: 0.3099, Test Loss: 0.3759, F1: 0.7314, AUC: 0.9270
Epoch [20/30] Train Loss: 0.2352, Test Loss: 0.3734, F1: 0.7286, AUC: 0.9321
Mejores resultados en la época:  23
f1-score 0.7780920060331825
AUC según el mejor F1-score 0.9342376182035184
Confusion Matrix:
 [[15144  1321]
 [ 1033  4127]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8911
Precision:  0.7575
Recall:     0.7998
F1-score:   0.7781

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5008, Test Loss: 0.3493, F1: 0.7208, AUC: 0.9028
Epoch [10/30] Train Loss: 0.3083, Test Loss: 0.4279, F1: 0.6988, AUC: 0.9247
Epoch [20/30] Train Loss: 0.2378, Test Loss: 0.4803, F1: 0.6901, AUC: 0.9316
Mejores resultados en la época:  28
f1-score 0.7584627638391079
AUC según el mejor F1-score 0.9277862426052914
Confusion Matrix:
 [[15390  1075]
 [ 1351  3809]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8878
Precision:  0.7799
Recall:     0.7382
F1-score:   0.7585

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4862, Test Loss: 0.5204, F1: 0.6416, AUC: 0.9066
Epoch [10/30] Train Loss: 0.3070, Test Loss: 0.3124, F1: 0.7424, AUC: 0.9234
Epoch [20/30] Train Loss: 0.2560, Test Loss: 0.4729, F1: 0.6852, AUC: 0.9261
Mejores resultados en la época:  26
f1-score 0.7749140893470791
AUC según el mejor F1-score 0.9323893353766625
Confusion Matrix:
 [[15208  1257]
 [ 1101  4059]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8910
Precision:  0.7635
Recall:     0.7866
F1-score:   0.7749
Tiempo total para red 5: 964.19 segundos

Entrenando red 6 con capas [7131, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5566, Test Loss: 0.3359, F1: 0.6889, AUC: 0.8967
Epoch [10/30] Train Loss: 0.2960, Test Loss: 0.2892, F1: 0.7573, AUC: 0.9269
F1-score:   0.7720
Tiempo total para red 2: 920.76 segundos

Entrenando red 3 con capas [7131, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5224, Test Loss: 0.3571, F1: 0.7150, AUC: 0.8992
Epoch [10/30] Train Loss: 0.2942, Test Loss: 0.3591, F1: 0.7360, AUC: 0.9280
Epoch [20/30] Train Loss: 0.2326, Test Loss: 0.2736, F1: 0.7645, AUC: 0.9329
Mejores resultados en la época:  14
f1-score 0.7666730001900057
AUC según el mejor F1-score 0.9309701633956926
Confusion Matrix:
 [[15134  1331]
 [ 1125  4035]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8864
Precision:  0.7520
Recall:     0.7820
F1-score:   0.7667

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5191, Test Loss: 0.3800, F1: 0.7116, AUC: 0.9008
Epoch [10/30] Train Loss: 0.2997, Test Loss: 0.4341, F1: 0.7052, AUC: 0.9264
Epoch [20/30] Train Loss: 0.2498, Test Loss: 0.4305, F1: 0.7187, AUC: 0.9314
Mejores resultados en la época:  22
f1-score 0.7799771602588504
AUC según el mejor F1-score 0.9334936628554344
Confusion Matrix:
 [[15215  1250]
 [ 1062  4098]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8931
Precision:  0.7663
Recall:     0.7942
F1-score:   0.7800

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5239, Test Loss: 0.6270, F1: 0.5781, AUC: 0.8995
Epoch [10/30] Train Loss: 0.3057, Test Loss: 0.3101, F1: 0.7211, AUC: 0.9200
Epoch [20/30] Train Loss: 0.2428, Test Loss: 0.4310, F1: 0.7072, AUC: 0.9294
Mejores resultados en la época:  18
f1-score 0.763676963155936
AUC según el mejor F1-score 0.9278103658924145
Confusion Matrix:
 [[14981  1484]
 [ 1056  4104]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8825
Precision:  0.7344
Recall:     0.7953
F1-score:   0.7637

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5649, Test Loss: 0.4677, F1: 0.6677, AUC: 0.8917
Epoch [10/30] Train Loss: 0.3091, Test Loss: 0.3727, F1: 0.7166, AUC: 0.9211
Epoch [20/30] Train Loss: 0.2550, Test Loss: 0.3533, F1: 0.7383, AUC: 0.9295
Mejores resultados en la época:  26
f1-score 0.7632230268585571
AUC según el mejor F1-score 0.9302261491959688
Confusion Matrix:
 [[14879  1586]
 [  997  4163]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_923265.png
Accuracy:   0.8806
Precision:  0.7241
Recall:     0.8068
F1-score:   0.7632
Tiempo total para red 3: 954.32 segundos

Entrenando red 4 con capas [7131, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5243, Test Loss: 0.4393, F1: 0.6821, AUC: 0.9000
Epoch [10/30] Train Loss: 0.3141, Test Loss: 0.3462, F1: 0.7335, AUC: 0.9227
Epoch [20/30] Train Loss: 0.2599, Test Loss: 0.3266, F1: 0.7549, AUC: 0.9291
Mejores resultados en la época:  23
f1-score 0.7663271979818742
AUC según el mejor F1-score 0.9282089798185957
Confusion Matrix:
 [[15023  1442]
 [ 1059  4101]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8843
Precision:  0.7399
Recall:     0.7948
F1-score:   0.7663

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4982, Test Loss: 0.3436, F1: 0.6136, AUC: 0.9046
Epoch [10/30] Train Loss: 0.3043, Test Loss: 0.4704, F1: 0.6737, AUC: 0.9229
Epoch [20/30] Train Loss: 0.2516, Test Loss: 0.2749, F1: 0.7687, AUC: 0.9322
Mejores resultados en la época:  20
f1-score 0.768688293370945
AUC según el mejor F1-score 0.9321839961205001
Confusion Matrix:
 [[15514   951]
 [ 1345  3815]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8938
Precision:  0.8005
Recall:     0.7393
F1-score:   0.7687

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4998, Test Loss: 0.4155, F1: 0.7007, AUC: 0.9032
Epoch [10/30] Train Loss: 0.3058, Test Loss: 0.4573, F1: 0.6980, AUC: 0.9252
Epoch [20/30] Train Loss: 0.2476, Test Loss: 0.4472, F1: 0.7061, AUC: 0.9308
Mejores resultados en la época:  22
f1-score 0.7777564717162032
AUC según el mejor F1-score 0.9326878720894922
Confusion Matrix:
 [[15251  1214]
 [ 1104  4056]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8928
Precision:  0.7696
Recall:     0.7860
F1-score:   0.7778

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.5379, Test Loss: 0.6231, F1: 0.5825, AUC: 0.8981
Epoch [10/30] Train Loss: 0.3038, Test Loss: 0.3544, F1: 0.7245, AUC: 0.9237
Epoch [20/30] Train Loss: 0.2466, Test Loss: 0.3476, F1: 0.7497, AUC: 0.9274
Mejores resultados en la época:  27
f1-score 0.7685497064767587
AUC según el mejor F1-score 0.9298466679378621
Confusion Matrix:
 [[15227  1238]
 [ 1167  3993]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_1869057.png
Accuracy:   0.8888
Precision:  0.7633
Recall:     0.7738
F1-score:   0.7685
Tiempo total para red 4: 988.61 segundos

Entrenando red 5 con capas [7131, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5147, Test Loss: 0.4201, F1: 0.6952, AUC: 0.9023
Epoch [10/30] Train Loss: 0.3011, Test Loss: 0.3248, F1: 0.7480, AUC: 0.9254
Epoch [20/30] Train Loss: 0.2327, Test Loss: 0.3186, F1: 0.7536, AUC: 0.9263
Mejores resultados en la época:  29
f1-score 0.775745562663303
AUC según el mejor F1-score 0.9349142531609217
Confusion Matrix:
 [[14831  1634]
 [  855  4305]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8849
Precision:  0.7249
Recall:     0.8343
F1-score:   0.7757

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5047, Test Loss: 0.5292, F1: 0.6479, AUC: 0.9033
Epoch [10/30] Train Loss: 0.3054, Test Loss: 0.4344, F1: 0.7068, AUC: 0.9244
Epoch [20/30] Train Loss: 0.2423, Test Loss: 0.4634, F1: 0.6803, AUC: 0.9270
Mejores resultados en la época:  23
f1-score 0.7733782645324347
AUC según el mejor F1-score 0.9322054593135073
Confusion Matrix:
 [[15073  1392]
 [ 1029  4131]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8880
Precision:  0.7480
Recall:     0.8006
F1-score:   0.7734

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5026, Test Loss: 0.4063, F1: 0.7037, AUC: 0.9027
Epoch [10/30] Train Loss: 0.2982, Test Loss: 0.3975, F1: 0.7244, AUC: 0.9269
Epoch [20/30] Train Loss: 0.2312, Test Loss: 0.3601, F1: 0.7546, AUC: 0.9333
Mejores resultados en la época:  29
f1-score 0.7794212218649518
AUC según el mejor F1-score 0.9333597636047336
Confusion Matrix:
 [[14982  1483]
 [  918  4242]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8890
Precision:  0.7410
Recall:     0.8221
F1-score:   0.7794

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5016, Test Loss: 0.3294, F1: 0.7144, AUC: 0.9035
Epoch [10/30] Train Loss: 0.2932, Test Loss: 0.3543, F1: 0.7367, AUC: 0.9256
Epoch [20/30] Train Loss: 0.2289, Test Loss: 0.3930, F1: 0.7286, AUC: 0.9319
Mejores resultados en la época:  25
f1-score 0.7765011119347665
AUC según el mejor F1-score 0.9337750972817604
Confusion Matrix:
 [[15023  1442]
 [  970  4190]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_3824129.png
Accuracy:   0.8885
Precision:  0.7440
Recall:     0.8120
F1-score:   0.7765
Tiempo total para red 5: 963.65 segundos

Entrenando red 6 con capas [7131, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5053, Test Loss: 0.4810, F1: 0.6835, AUC: 0.9022
Epoch [10/30] Train Loss: 0.3090, Test Loss: 0.4523, F1: 0.6943, AUC: 0.9222
Epoch [20/30] Train Loss: 0.2522, Test Loss: 0.2932, F1: 0.7598, AUC: 0.9278
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [02:01:46] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [02:01:47] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Mejores resultados en la época:  26
f1-score 0.76858943286476
AUC según el mejor F1-score 0.9314207904010621
Confusion Matrix:
 [[15274  1191]
 [ 1196  3964]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8896
Precision:  0.7690
Recall:     0.7682
F1-score:   0.7686

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6931, Test Loss: 0.6969, F1: 0.3853, AUC: 0.1646
Epoch [10/30] Train Loss: 0.3202, Test Loss: 0.3459, F1: 0.7273, AUC: 0.9206
Epoch [20/30] Train Loss: 0.2880, Test Loss: 0.5015, F1: 0.6558, AUC: 0.9197
Mejores resultados en la época:  14
f1-score 0.7423680456490728
AUC según el mejor F1-score 0.9206370042632128
Confusion Matrix:
 [[15013  1452]
 [ 1257  3903]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8747
Precision:  0.7289
Recall:     0.7564
F1-score:   0.7424

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5350, Test Loss: 0.5207, F1: 0.6577, AUC: 0.8991
Epoch [10/30] Train Loss: 0.3112, Test Loss: 0.3951, F1: 0.7016, AUC: 0.9250
Epoch [20/30] Train Loss: 0.2777, Test Loss: 0.4968, F1: 0.6902, AUC: 0.9210
Mejores resultados en la época:  9
f1-score 0.7479569093610698
AUC según el mejor F1-score 0.9240425191326681
Confusion Matrix:
 [[14884  1581]
 [ 1133  4027]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8745
Precision:  0.7181
Recall:     0.7804
F1-score:   0.7480

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5097, Test Loss: 0.3464, F1: 0.7206, AUC: 0.9021
Epoch [10/30] Train Loss: 0.2988, Test Loss: 0.4135, F1: 0.7191, AUC: 0.9256
Epoch [20/30] Train Loss: 0.2319, Test Loss: 0.3547, F1: 0.7604, AUC: 0.9314
Mejores resultados en la época:  26
f1-score 0.772323431750875
AUC según el mejor F1-score 0.9338858678380497
Confusion Matrix:
 [[14785  1680]
 [  857  4303]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8827
Precision:  0.7192
Recall:     0.8339
F1-score:   0.7723
Tiempo total para red 6: 1153.21 segundos
Saved on: outputs_text_plus_numerical_categorical/0/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.8697
Precision: 0.6819
Recall:    0.8508
F1-score:  0.7570
              precision    recall  f1-score   support

           0       0.95      0.88      0.91     16465
           1       0.68      0.85      0.76      5160

    accuracy                           0.87     21625
   macro avg       0.82      0.86      0.83     21625
weighted avg       0.89      0.87      0.87     21625

[[14417  2048]
 [  770  4390]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.4499
Precision: 0.2985
Recall:    0.9667
F1-score:  0.4561
              precision    recall  f1-score   support

           0       0.96      0.29      0.44     16465
           1       0.30      0.97      0.46      5160

    accuracy                           0.45     21625
   macro avg       0.63      0.63      0.45     21625
weighted avg       0.81      0.45      0.45     21625

[[ 4741 11724]
 [  172  4988]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8969
Precision: 0.7459
Recall:    0.8612
F1-score:  0.7994
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.86      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.87     21625
weighted avg       0.90      0.90      0.90     21625

[[14951  1514]
 [  716  4444]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8780
Precision: 0.7197
Recall:    0.8006
F1-score:  0.7580
              precision    recall  f1-score   support

           0       0.94      0.90      0.92     16465
           1       0.72      0.80      0.76      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

[[14856  1609]
 [ 1029  4131]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.9193
Precision: 0.7892
Recall:    0.9027
F1-score:  0.8422
              precision    recall  f1-score   support

           0       0.97      0.92      0.95     16465
           1       0.79      0.90      0.84      5160

    accuracy                           0.92     21625
   macro avg       0.88      0.91      0.89     21625
weighted avg       0.93      0.92      0.92     21625

[[15221  1244]
 [  502  4658]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.8238
Precision: 0.6065
Recall:    0.7450
F1-score:  0.6686
              precision    recall  f1-score   support

           0       0.91      0.85      0.88     16465
           1       0.61      0.74      0.67      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625
Epoch [20/30] Train Loss: 0.2343, Test Loss: 0.3035, F1: 0.7733, AUC: 0.9321
Mejores resultados en la época:  22
f1-score 0.7760234991738572
AUC según el mejor F1-score 0.9329742206277352
Confusion Matrix:
 [[14958  1507]
 [  933  4227]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8872
Precision:  0.7372
Recall:     0.8192
F1-score:   0.7760

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5062, Test Loss: 0.4377, F1: 0.6968, AUC: 0.9050
Epoch [10/30] Train Loss: 0.3049, Test Loss: 0.4029, F1: 0.7113, AUC: 0.9252
Epoch [20/30] Train Loss: 0.2455, Test Loss: 0.2988, F1: 0.7589, AUC: 0.9266
Mejores resultados en la época:  26
f1-score 0.7756982435934351
AUC según el mejor F1-score 0.932769464002806
Confusion Matrix:
 [[15247  1218]
 [ 1119  4041]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8919
Precision:  0.7684
Recall:     0.7831
F1-score:   0.7757

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5590, Test Loss: 0.3636, F1: 0.6632, AUC: 0.8966
Epoch [10/30] Train Loss: 0.2988, Test Loss: 0.4558, F1: 0.6827, AUC: 0.9258
Epoch [20/30] Train Loss: 0.2339, Test Loss: 0.3593, F1: 0.7480, AUC: 0.9310
Mejores resultados en la época:  27
f1-score 0.7684418855703491
AUC según el mejor F1-score 0.9332472510399084
Confusion Matrix:
 [[14780  1685]
 [  889  4271]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8810
Precision:  0.7171
Recall:     0.8277
F1-score:   0.7684

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6906, Test Loss: 0.7001, F1: 0.3853, AUC: 0.8597
Epoch [10/30] Train Loss: 0.3185, Test Loss: 0.3007, F1: 0.7437, AUC: 0.9169
Epoch [20/30] Train Loss: 0.2898, Test Loss: 0.4519, F1: 0.6841, AUC: 0.9188
Mejores resultados en la época:  10
f1-score 0.743732318798166
AUC según el mejor F1-score 0.9168930218433745
Confusion Matrix:
 [[15186  1279]
 [ 1348  3812]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/tfidf/confusion_matrix_param_8002561.png
Accuracy:   0.8785
Precision:  0.7488
Recall:     0.7388
F1-score:   0.7437
Tiempo total para red 6: 1153.15 segundos
Saved on: outputs_text_plus_numerical_categorical/0/tfidf

==============================
Model: Logistic Regression
Accuracy:  0.8697
Precision: 0.6819
Recall:    0.8508
F1-score:  0.7570
              precision    recall  f1-score   support

           0       0.95      0.88      0.91     16465
           1       0.68      0.85      0.76      5160

    accuracy                           0.87     21625
   macro avg       0.82      0.86      0.83     21625
weighted avg       0.89      0.87      0.87     21625

[[14417  2048]
 [  770  4390]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.4499
Precision: 0.2985
Recall:    0.9667
F1-score:  0.4561
              precision    recall  f1-score   support

           0       0.96      0.29      0.44     16465
           1       0.30      0.97      0.46      5160

    accuracy                           0.45     21625
   macro avg       0.63      0.63      0.45     21625
weighted avg       0.81      0.45      0.45     21625

[[ 4741 11724]
 [  172  4988]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8969
Precision: 0.7459
Recall:    0.8612
F1-score:  0.7994
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.86      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.87     21625
weighted avg       0.90      0.90      0.90     21625

[[14951  1514]
 [  716  4444]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8780
Precision: 0.7197
Recall:    0.8006
F1-score:  0.7580
              precision    recall  f1-score   support

           0       0.94      0.90      0.92     16465
           1       0.72      0.80      0.76      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

[[14856  1609]
 [ 1029  4131]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.9193
Precision: 0.7892
Recall:    0.9027
F1-score:  0.8422
              precision    recall  f1-score   support

           0       0.97      0.92      0.95     16465
           1       0.79      0.90      0.84      5160

    accuracy                           0.92     21625
   macro avg       0.88      0.91      0.89     21625
weighted avg       0.93      0.92      0.92     21625

[[15221  1244]
 [  502  4658]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.8238
Precision: 0.6065
Recall:    0.7450
F1-score:  0.6686
              precision    recall  f1-score   support

           0       0.91      0.85      0.88     16465
           1       0.61      0.74      0.67      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])

[[13971  2494]
 [ 1316  3844]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.9193, 'precision': 0.7892, 'recall': 0.9027, 'f1_score': 0.8422}
Decision Tree: {'accuracy': 0.8969, 'precision': 0.7459, 'recall': 0.8612, 'f1_score': 0.7994}
Random Forest: {'accuracy': 0.878, 'precision': 0.7197, 'recall': 0.8006, 'f1_score': 0.758}
Logistic Regression: {'accuracy': 0.8697, 'precision': 0.6819, 'recall': 0.8508, 'f1_score': 0.757}
Naive Bayes: {'accuracy': 0.8238, 'precision': 0.6065, 'recall': 0.745, 'f1_score': 0.6686}
SVM: {'accuracy': 0.4499, 'precision': 0.2985, 'recall': 0.9667, 'f1_score': 0.4561}
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 2385)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 2431)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 2431)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [2431, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6936, Test Loss: 0.6907, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6931, Test Loss: 0.6979, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6954, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  3
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6937, Test Loss: 0.6943, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6943, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6919, F1: 0.0000, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6546, Test Loss: 0.6790, F1: 0.4897, AUC: 0.8053
Epoch [10/30] Train Loss: 0.3943, Test Loss: 0.3261, F1: 0.7304, AUC: 0.9097
Epoch [20/30] Train Loss: 0.3707, Test Loss: 0.3479, F1: 0.7324, AUC: 0.9189
Mejores resultados en la época:  29
f1-score 0.7542094058447842
AUC según el mejor F1-score 0.923889687309468
Confusion Matrix:
 [[15188  1277]
 [ 1263  3897]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.8825
Precision:  0.7532
Recall:     0.7552
F1-score:   0.7542

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6262, Test Loss: 0.5808, F1: 0.5711, AUC: 0.8381
Epoch [10/30] Train Loss: 0.3956, Test Loss: 0.4596, F1: 0.6771, AUC: 0.9141
Epoch [20/30] Train Loss: 0.3692, Test Loss: 0.3286, F1: 0.7501, AUC: 0.9228
Mejores resultados en la época:  25
f1-score 0.757258774073712
AUC según el mejor F1-score 0.9261799753764739
Confusion Matrix:
 [[15269  1196]
 [ 1287  3873]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.8852
Precision:  0.7641
Recall:     0.7506
F1-score:   0.7573
Tiempo total para red 1: 462.34 segundos

Entrenando red 2 con capas [2431, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6249, Test Loss: 0.5802, F1: 0.5730, AUC: 0.8512
Epoch [10/30] Train Loss: 0.3933, Test Loss: 0.4080, F1: 0.7060, AUC: 0.9157
Epoch [20/30] Train Loss: 0.3643, Test Loss: 0.3466, F1: 0.7389, AUC: 0.9245
Mejores resultados en la época:  26
f1-score 0.7601661354196851
AUC según el mejor F1-score 0.9273711384496595
Confusion Matrix:
 [[15207  1258]
 [ 1225  3935]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8852
Precision:  0.7578
Recall:     0.7626
F1-score:   0.7602

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6443, Test Loss: 0.4223, F1: 0.4926, AUC: 0.8384
Epoch [10/30] Train Loss: 0.3884, Test Loss: 0.4361, F1: 0.6901, AUC: 0.9151
Epoch [20/30] Train Loss: 0.3694, Test Loss: 0.4531, F1: 0.6829, AUC: 0.9232
Mejores resultados en la época:  28
f1-score 0.7566924449732302
AUC según el mejor F1-score 0.9262625030308594
Confusion Matrix:
 [[15355  1110]
 [ 1344  3816]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8865
Precision:  0.7747
Recall:     0.7395
F1-score:   0.7567

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.5997, Test Loss: 0.5424, F1: 0.5995, AUC: 0.8625
Epoch [10/30] Train Loss: 0.3901, Test Loss: 0.4646, F1: 0.6790, AUC: 0.9161
Epoch [20/30] Train Loss: 0.3642, Test Loss: 0.4602, F1: 0.6802, AUC: 0.9242
Mejores resultados en la época:  28
f1-score 0.7577826872866037
AUC según el mejor F1-score 0.9280566953156448
Confusion Matrix:
 [[15440  1025]
 [ 1387  3773]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8885
Precision:  0.7864
Recall:     0.7312
F1-score:   0.7578

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6494, Test Loss: 0.6578, F1: 0.5191, AUC: 0.8256
Epoch [10/30] Train Loss: 0.3904, Test Loss: 0.4978, F1: 0.6552, AUC: 0.9147
Epoch [20/30] Train Loss: 0.3698, Test Loss: 0.4747, F1: 0.6761, AUC: 0.9238
Mejores resultados en la época:  25
f1-score 0.7567990608491489
AUC según el mejor F1-score 0.9262111549751999
Confusion Matrix:
 [[15271  1194]
 [ 1292  3868]]

[[13971  2494]
 [ 1316  3844]]
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/tfidf/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/tfidf/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.9193, 'precision': 0.7892, 'recall': 0.9027, 'f1_score': 0.8422}
Decision Tree: {'accuracy': 0.8969, 'precision': 0.7459, 'recall': 0.8612, 'f1_score': 0.7994}
Random Forest: {'accuracy': 0.878, 'precision': 0.7197, 'recall': 0.8006, 'f1_score': 0.758}
Logistic Regression: {'accuracy': 0.8697, 'precision': 0.6819, 'recall': 0.8508, 'f1_score': 0.757}
Naive Bayes: {'accuracy': 0.8238, 'precision': 0.6065, 'recall': 0.745, 'f1_score': 0.6686}
SVM: {'accuracy': 0.4499, 'precision': 0.2985, 'recall': 0.9667, 'f1_score': 0.4561}
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 2385)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 2431)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 2431)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [2431, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6943, Test Loss: 0.6864, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6938, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6940, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  3
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5000303674460977
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6226, Test Loss: 0.4381, F1: 0.5268, AUC: 0.8406
Epoch [10/30] Train Loss: 0.3929, Test Loss: 0.3741, F1: 0.7223, AUC: 0.9135
Epoch [20/30] Train Loss: 0.3658, Test Loss: 0.4961, F1: 0.6623, AUC: 0.9224
Mejores resultados en la época:  26
f1-score 0.7559908710536326
AUC según el mejor F1-score 0.9253556581143464
Confusion Matrix:
 [[15084  1381]
 [ 1185  3975]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.8813
Precision:  0.7422
Recall:     0.7703
F1-score:   0.7560

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5921, Test Loss: 0.4160, F1: 0.6310, AUC: 0.8620
Epoch [10/30] Train Loss: 0.3917, Test Loss: 0.3993, F1: 0.7066, AUC: 0.9157
Epoch [20/30] Train Loss: 0.3666, Test Loss: 0.3605, F1: 0.7300, AUC: 0.9237
Mejores resultados en la época:  28
f1-score 0.7569022226652048
AUC según el mejor F1-score 0.9262069117719759
Confusion Matrix:
 [[15389  1076]
 [ 1363  3797]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.8872
Precision:  0.7792
Recall:     0.7359
F1-score:   0.7569

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6936, Test Loss: 0.6954, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6945, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6931, F1: 0.0000, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_77857.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853
Tiempo total para red 1: 460.92 segundos

Entrenando red 2 con capas [2431, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6356, Test Loss: 0.4441, F1: 0.5747, AUC: 0.8359
Epoch [10/30] Train Loss: 0.3846, Test Loss: 0.3017, F1: 0.7348, AUC: 0.9148
Epoch [20/30] Train Loss: 0.3664, Test Loss: 0.3832, F1: 0.7173, AUC: 0.9232
Mejores resultados en la época:  29
f1-score 0.7463134657836644
AUC según el mejor F1-score 0.9271708192383659
Confusion Matrix:
 [[14526  1939]
 [  934  4226]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8671
Precision:  0.6855
Recall:     0.8190
F1-score:   0.7463

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6595, Test Loss: 0.6385, F1: 0.5272, AUC: 0.8206
Epoch [10/30] Train Loss: 0.3882, Test Loss: 0.4023, F1: 0.7085, AUC: 0.9141
Epoch [20/30] Train Loss: 0.3695, Test Loss: 0.3059, F1: 0.7516, AUC: 0.9223
Mejores resultados en la época:  29
f1-score 0.7596749226006192
AUC según el mejor F1-score 0.926614065071081
Confusion Matrix:
 [[15215  1250]
 [ 1234  3926]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8851
Precision:  0.7585
Recall:     0.7609
F1-score:   0.7597

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6151, Test Loss: 0.5262, F1: 0.6061, AUC: 0.8548
Epoch [10/30] Train Loss: 0.3915, Test Loss: 0.5044, F1: 0.6535, AUC: 0.9149
Epoch [20/30] Train Loss: 0.3673, Test Loss: 0.3407, F1: 0.7433, AUC: 0.9230
Mejores resultados en la época:  26
f1-score 0.7573143285821455
AUC según el mejor F1-score 0.9265834504480964
Confusion Matrix:
 [[14999  1466]
 [ 1122  4038]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8803
Precision:  0.7336
Recall:     0.7826
F1-score:   0.7573

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.6473, Test Loss: 0.5260, F1: 0.5917, AUC: 0.8282
Epoch [10/30] Train Loss: 0.3880, Test Loss: 0.3143, F1: 0.7371, AUC: 0.9150
Epoch [20/30] Train Loss: 0.3685, Test Loss: 0.6842, F1: 0.5684, AUC: 0.9231
Mejores resultados en la época:  29
f1-score 0.7569173630454967
AUC según el mejor F1-score 0.9274324088917766
Confusion Matrix:
 [[14931  1534]
 [ 1084  4076]]
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8789
Precision:  0.7266
Recall:     0.7899
F1-score:   0.7569
Tiempo total para red 2: 474.22 segundos

Entrenando red 3 con capas [2431, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6097, Test Loss: 0.6279, F1: 0.5520, AUC: 0.8654
Epoch [10/30] Train Loss: 0.3854, Test Loss: 0.3761, F1: 0.7234, AUC: 0.9171
Epoch [20/30] Train Loss: 0.3723, Test Loss: 0.3524, F1: 0.7369, AUC: 0.9247
Mejores resultados en la época:  26
f1-score 0.755902584123443
AUC según el mejor F1-score 0.9272652231536476
Confusion Matrix:
 [[14933  1532]
 [ 1094  4066]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8786
Precision:  0.7263
Recall:     0.7880
F1-score:   0.7559

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6057, Test Loss: 0.4184, F1: 0.6555, AUC: 0.8643
Epoch [10/30] Train Loss: 0.3943, Test Loss: 0.4339, F1: 0.6947, AUC: 0.9163
Epoch [20/30] Train Loss: 0.3638, Test Loss: 0.3058, F1: 0.7549, AUC: 0.9247
Mejores resultados en la época:  25
f1-score 0.7594985535197686
AUC según el mejor F1-score 0.9268853240488987
Confusion Matrix:
 [[15193  1272]
 [ 1222  3938]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8847
Precision:  0.7559
Recall:     0.7632
F1-score:   0.7595

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.5997, Test Loss: 0.4112, F1: 0.6658, AUC: 0.8711
Epoch [10/30] Train Loss: 0.3938, Test Loss: 0.6038, F1: 0.6120, AUC: 0.9164
Epoch [20/30] Train Loss: 0.3717, Test Loss: 0.4835, F1: 0.6730, AUC: 0.9236
Mejores resultados en la época:  21
f1-score 0.7545880515423663
AUC según el mejor F1-score 0.9246458837986145
Confusion Matrix:
 [[15246  1219]
 [ 1295  3865]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8837
Precision:  0.7602
Recall:     0.7490
F1-score:   0.7546

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6339, Test Loss: 0.5639, F1: 0.5858, AUC: 0.8550
Epoch [10/30] Train Loss: 0.3841, Test Loss: 0.3058, F1: 0.7400, AUC: 0.9162
Epoch [20/30] Train Loss: 0.3651, Test Loss: 0.2929, F1: 0.7545, AUC: 0.9248
Mejores resultados en la época:  22
f1-score 0.7549830763444904
AUC según el mejor F1-score 0.9251967704574185
Confusion Matrix:
 [[15004  1461]
 [ 1145  4015]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8795
Precision:  0.7332
Recall:     0.7781
F1-score:   0.7550
Tiempo total para red 3: 490.88 segundos

Entrenando red 4 con capas [2431, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6053, Test Loss: 0.4970, F1: 0.6339, AUC: 0.8647
Epoch [10/30] Train Loss: 0.3885, Test Loss: 0.4024, F1: 0.7220, AUC: 0.9174
Epoch [20/30] Train Loss: 0.3668, Test Loss: 0.4319, F1: 0.6938, AUC: 0.9245
Mejores resultados en la época:  28
f1-score 0.7613077442376314
AUC según el mejor F1-score 0.9287112020565118
Confusion Matrix:
 [[15203  1262]
 [ 1213  3947]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8855
Precision:  0.7577
Recall:     0.7649
F1-score:   0.7613

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6223, Test Loss: 0.5328, F1: 0.6017, AUC: 0.8612
Epoch [10/30] Train Loss: 0.3916, Test Loss: 0.3026, F1: 0.7064, AUC: 0.9149
Epoch [20/30] Train Loss: 0.3738, Test Loss: 0.4954, F1: 0.6646, AUC: 0.9231
Mejores resultados en la época:  21
f1-score 0.7553914901884593
AUC según el mejor F1-score 0.9236179751740243
Confusion Matrix:
 [[15219  1246]
 [ 1272  3888]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8836
Precision:  0.7573
Recall:     0.7535
F1-score:   0.7554

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6010, Test Loss: 0.4708, F1: 0.6385, AUC: 0.8702
Epoch [10/30] Train Loss: 0.3908, Test Loss: 0.4892, F1: 0.6594, AUC: 0.9165
Epoch [20/30] Train Loss: 0.3710, Test Loss: 0.3063, F1: 0.7517, AUC: 0.9237
Mejores resultados en la época:  24
f1-score 0.7580503940071991
AUC según el mejor F1-score 0.9263286051925979
Confusion Matrix:
 [[15242  1223]
 [ 1264  3896]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8850
Precision:  0.7611
Recall:     0.7550
F1-score:   0.7581

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6612, Test Loss: 0.4436, F1: 0.5327, AUC: 0.8361
Epoch [10/30] Train Loss: 0.3916, Test Loss: 0.3229, F1: 0.7397, AUC: 0.9156
Epoch [20/30] Train Loss: 0.3831, Test Loss: 0.3169, F1: 0.7490, AUC: 0.9219
Mejores resultados en la época:  26
f1-score 0.7587473419679103
AUC según el mejor F1-score 0.9277019082055664
Confusion Matrix:
 [[15204  1261]
 [ 1235  3925]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8846
Precision:  0.7568
Recall:     0.7607
F1-score:   0.7587
Tiempo total para red 4: 519.73 segundos

Entrenando red 5 con capas [2431, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6161, Test Loss: 0.5302, F1: 0.6134, AUC: 0.8705
Epoch [10/30] Train Loss: 0.3917, Test Loss: 0.7321, F1: 0.5522, AUC: 0.9164
Epoch [20/30] Train Loss: 0.3729, Test Loss: 0.4115, F1: 0.7084, AUC: 0.9233
Mejores resultados en la época:  24
f1-score 0.7511804557585712
AUC según el mejor F1-score 0.9249825328333298
Confusion Matrix:
 [[15542   923]
 [ 1501  3659]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8879
Precision:  0.7986
Recall:     0.7091
F1-score:   0.7512

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6187, Test Loss: 0.3967, F1: 0.6437, AUC: 0.8634
Epoch [10/30] Train Loss: 0.3958, Test Loss: 0.3084, F1: 0.7373, AUC: 0.9160
Epoch [20/30] Train Loss: 0.3649, Test Loss: 0.4067, F1: 0.7107, AUC: 0.9233
Mejores resultados en la época:  26
f1-score 0.7566293459045375
AUC según el mejor F1-score 0.9259280962436175
Confusion Matrix:
 [[15295  1170]
 [ 1308  3852]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8854
Precision:  0.7670
Recall:     0.7465
F1-score:   0.7566

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6936, Test Loss: 0.6986, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6912, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6947, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6083, Test Loss: 0.3998, F1: 0.6577, AUC: 0.8693
Epoch [10/30] Train Loss: 0.3843, Test Loss: 0.3302, F1: 0.7412, AUC: 0.9172
Epoch [20/30] Train Loss: 0.3737, Test Loss: 0.4013, F1: 0.7177, AUC: 0.9242
Mejores resultados en la época:  25
f1-score 0.7595873077671793
AUC según el mejor F1-score 0.9274163894754437
Confusion Matrix:
 [[15253  1212]
 [ 1258  3902]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8858
Precision:  0.7630
Recall:     0.7562
F1-score:   0.7596
Tiempo total para red 5: 564.08 segundos

Entrenando red 6 con capas [2431, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6773, Test Loss: 0.4725, F1: 0.5706, AUC: 0.8206
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_157761.png
Accuracy:   0.8850
Precision:  0.7641
Recall:     0.7496
F1-score:   0.7568
Tiempo total para red 2: 475.01 segundos

Entrenando red 3 con capas [2431, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6381, Test Loss: 0.9166, F1: 0.4433, AUC: 0.8505
Epoch [10/30] Train Loss: 0.3874, Test Loss: 0.5024, F1: 0.6513, AUC: 0.9160
Epoch [20/30] Train Loss: 0.3647, Test Loss: 0.3816, F1: 0.7216, AUC: 0.9237
Mejores resultados en la época:  27
f1-score 0.7600987654320988
AUC según el mejor F1-score 0.927790815377698
Confusion Matrix:
 [[15348  1117]
 [ 1312  3848]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8877
Precision:  0.7750
Recall:     0.7457
F1-score:   0.7601

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6163, Test Loss: 0.3834, F1: 0.5931, AUC: 0.8623
Epoch [10/30] Train Loss: 0.3898, Test Loss: 0.3026, F1: 0.7379, AUC: 0.9163
Epoch [20/30] Train Loss: 0.3690, Test Loss: 0.3193, F1: 0.7517, AUC: 0.9237
Mejores resultados en la época:  26
f1-score 0.7597669309389626
AUC según el mejor F1-score 0.9264941489699787
Confusion Matrix:
 [[15133  1332]
 [ 1183  3977]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8837
Precision:  0.7491
Recall:     0.7707
F1-score:   0.7598

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6448, Test Loss: 0.5468, F1: 0.5914, AUC: 0.8496
Epoch [10/30] Train Loss: 0.3868, Test Loss: 0.3374, F1: 0.7376, AUC: 0.9154
Epoch [20/30] Train Loss: 0.3628, Test Loss: 0.2868, F1: 0.7368, AUC: 0.9234
Mejores resultados en la época:  25
f1-score 0.7548266166822868
AUC según el mejor F1-score 0.9261064461378024
Confusion Matrix:
 [[14982  1483]
 [ 1133  4027]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8790
Precision:  0.7309
Recall:     0.7804
F1-score:   0.7548

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.6129, Test Loss: 0.5301, F1: 0.6029, AUC: 0.8579
Epoch [10/30] Train Loss: 0.3884, Test Loss: 0.3400, F1: 0.7362, AUC: 0.9159
Epoch [20/30] Train Loss: 0.3680, Test Loss: 0.4194, F1: 0.7103, AUC: 0.9243
Mejores resultados en la época:  27
f1-score 0.760697923774247
AUC según el mejor F1-score 0.928265512703715
Confusion Matrix:
 [[15268  1197]
 [ 1258  3902]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_321665.png
Accuracy:   0.8865
Precision:  0.7652
Recall:     0.7562
F1-score:   0.7607
Tiempo total para red 3: 492.09 segundos

Entrenando red 4 con capas [2431, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6199, Test Loss: 0.4648, F1: 0.6437, AUC: 0.8621
Epoch [10/30] Train Loss: 0.3908, Test Loss: 0.5477, F1: 0.6354, AUC: 0.9161
Epoch [20/30] Train Loss: 0.3606, Test Loss: 0.6505, F1: 0.5896, AUC: 0.9235
Mejores resultados en la época:  29
f1-score 0.7625157966365316
AUC según el mejor F1-score 0.925309206515112
Confusion Matrix:
 [[15260  1205]
 [ 1238  3922]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8870
Precision:  0.7650
Recall:     0.7601
F1-score:   0.7625

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6009, Test Loss: 0.3745, F1: 0.6418, AUC: 0.8670
Epoch [10/30] Train Loss: 0.3871, Test Loss: 0.3934, F1: 0.7128, AUC: 0.9162
Epoch [20/30] Train Loss: 0.3771, Test Loss: 0.4777, F1: 0.6801, AUC: 0.9234
Mejores resultados en la época:  27
f1-score 0.7577769347496206
AUC según el mejor F1-score 0.9276230175825159
Confusion Matrix:
 [[15076  1389]
 [ 1165  3995]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8819
Precision:  0.7420
Recall:     0.7742
F1-score:   0.7578

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6026, Test Loss: 0.4503, F1: 0.6547, AUC: 0.8723
Epoch [10/30] Train Loss: 0.3866, Test Loss: 0.4486, F1: 0.6833, AUC: 0.9164
Epoch [20/30] Train Loss: 0.3710, Test Loss: 0.5753, F1: 0.6253, AUC: 0.9242
Mejores resultados en la época:  26
f1-score 0.7599067599067599
AUC según el mejor F1-score 0.9256502929634625
Confusion Matrix:
 [[15241  1224]
 [ 1248  3912]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8857
Precision:  0.7617
Recall:     0.7581
F1-score:   0.7599

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.6061, Test Loss: 0.3785, F1: 0.6311, AUC: 0.8689
Epoch [10/30] Train Loss: 0.3953, Test Loss: 0.4170, F1: 0.7060, AUC: 0.9165
Epoch [20/30] Train Loss: 0.3787, Test Loss: 0.3846, F1: 0.7262, AUC: 0.9244
Mejores resultados en la época:  26
f1-score 0.7576119402985074
AUC según el mejor F1-score 0.9250075918615245
Confusion Matrix:
 [[15382  1083]
 [ 1353  3807]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_665857.png
Accuracy:   0.8874
Precision:  0.7785
Recall:     0.7378
F1-score:   0.7576
Tiempo total para red 4: 519.68 segundos

Entrenando red 5 con capas [2431, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6668, Test Loss: 0.6645, F1: 0.5349, AUC: 0.8416
Epoch [10/30] Train Loss: 0.3880, Test Loss: 0.3184, F1: 0.7412, AUC: 0.9158
Epoch [20/30] Train Loss: 0.3630, Test Loss: 0.3430, F1: 0.7427, AUC: 0.9238
Mejores resultados en la época:  26
f1-score 0.758391881342701
AUC según el mejor F1-score 0.9259357528419457
Confusion Matrix:
 [[15263  1202]
 [ 1274  3886]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8855
Precision:  0.7638
Recall:     0.7531
F1-score:   0.7584

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6935, Test Loss: 0.6949, F1: 0.3853, AUC: 0.5001
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6979, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6950, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5000911023382933
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.5974, Test Loss: 0.4430, F1: 0.6606, AUC: 0.8676
Epoch [10/30] Train Loss: 0.3854, Test Loss: 0.3050, F1: 0.7416, AUC: 0.9172
Epoch [20/30] Train Loss: 0.3731, Test Loss: 0.2933, F1: 0.7226, AUC: 0.9244
Mejores resultados en la época:  25
f1-score 0.7577676627745894
AUC según el mejor F1-score 0.9278047573311489
Confusion Matrix:
 [[15348  1117]
 [ 1331  3829]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8868
Precision:  0.7742
Recall:     0.7421
F1-score:   0.7578

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.6228, Test Loss: 0.4599, F1: 0.6599, AUC: 0.8666
Epoch [10/30] Train Loss: 0.3936, Test Loss: 0.3212, F1: 0.7407, AUC: 0.9158
Epoch [20/30] Train Loss: 0.3742, Test Loss: 0.3014, F1: 0.7501, AUC: 0.9239
Mejores resultados en la época:  28
f1-score 0.7580502215657312
AUC según el mejor F1-score 0.9279063234909851
Confusion Matrix:
 [[15319  1146]
 [ 1311  3849]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_1417729.png
Accuracy:   0.8864
Precision:  0.7706
Recall:     0.7459
F1-score:   0.7581
Tiempo total para red 5: 564.10 segundos

Entrenando red 6 con capas [2431, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6277, Test Loss: 0.5160, F1: 0.6426, AUC: 0.8628
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:16:37] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:16:39] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Epoch [10/30] Train Loss: 0.3850, Test Loss: 0.3887, F1: 0.7210, AUC: 0.9169
Epoch [20/30] Train Loss: 0.3676, Test Loss: 0.3768, F1: 0.7200, AUC: 0.9255
Mejores resultados en la época:  21
f1-score 0.757747027869811
AUC según el mejor F1-score 0.9254703776156612
Confusion Matrix:
 [[15251  1214]
 [ 1272  3888]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.8850
Precision:  0.7621
Recall:     0.7535
F1-score:   0.7577

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6933, Test Loss: 0.6853, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6931, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6938, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  2
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6775, Test Loss: 0.6106, F1: 0.5671, AUC: 0.8187
Epoch [10/30] Train Loss: 0.3869, Test Loss: 0.4809, F1: 0.6627, AUC: 0.9161
Epoch [20/30] Train Loss: 0.3763, Test Loss: 0.3401, F1: 0.7480, AUC: 0.9233
Mejores resultados en la época:  29
f1-score 0.7595617912742648
AUC según el mejor F1-score 0.9280293822696488
Confusion Matrix:
 [[15171  1294]
 [ 1208  3952]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.8843
Precision:  0.7533
Recall:     0.7659
F1-score:   0.7596

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6754, Test Loss: 0.4679, F1: 0.5903, AUC: 0.8285
Epoch [10/30] Train Loss: 0.3991, Test Loss: 0.3354, F1: 0.7377, AUC: 0.9160
Epoch [20/30] Train Loss: 0.3799, Test Loss: 0.3761, F1: 0.7285, AUC: 0.9232
Mejores resultados en la época:  27
f1-score 0.7550335570469798
AUC según el mejor F1-score 0.9266093157437554
Confusion Matrix:
 [[15318  1147]
 [ 1335  3825]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.8852
Precision:  0.7693
Recall:     0.7413
F1-score:   0.7550
Tiempo total para red 6: 640.85 segundos
Saved on: outputs_text_plus_numerical_categorical/0/lyrics_bert

==============================
Model: Logistic Regression
Accuracy:  0.8696
Precision: 0.6817
Recall:    0.8512
F1-score:  0.7570
              precision    recall  f1-score   support

           0       0.95      0.88      0.91     16465
           1       0.68      0.85      0.76      5160

    accuracy                           0.87     21625
   macro avg       0.82      0.86      0.83     21625
weighted avg       0.89      0.87      0.87     21625

[[14414  2051]
 [  768  4392]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.2928
Precision: 0.2499
Recall:    0.9812
F1-score:  0.3983
              precision    recall  f1-score   support

           0       0.93      0.08      0.14     16465
           1       0.25      0.98      0.40      5160

    accuracy                           0.29     21625
   macro avg       0.59      0.53      0.27     21625
weighted avg       0.77      0.29      0.20     21625

[[ 1268 15197]
 [   97  5063]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8057
Precision: 0.5656
Recall:    0.8008
F1-score:  0.6629
              precision    recall  f1-score   support

           0       0.93      0.81      0.86     16465
           1       0.57      0.80      0.66      5160

    accuracy                           0.81     21625
   macro avg       0.75      0.80      0.76     21625
weighted avg       0.84      0.81      0.82     21625

[[13291  3174]
 [ 1028  4132]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8561
Precision: 0.6711
Recall:    0.7789
F1-score:  0.7210
              precision    recall  f1-score   support

           0       0.93      0.88      0.90     16465
           1       0.67      0.78      0.72      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.87      0.86      0.86     21625

[[14495  1970]
 [ 1141  4019]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.8814
Precision: 0.7109
Recall:    0.8479
F1-score:  0.7734
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.77      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.88     21625

[[14686  1779]
 [  785  4375]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/xgboost_model.pkl

Epoch [10/30] Train Loss: 0.3977, Test Loss: 0.4151, F1: 0.7052, AUC: 0.9149
Epoch [20/30] Train Loss: 0.3688, Test Loss: 0.4059, F1: 0.7165, AUC: 0.9233
Mejores resultados en la época:  28
f1-score 0.7582036284326361
AUC según el mejor F1-score 0.9272482150297671
Confusion Matrix:
 [[15362  1103]
 [ 1336  3824]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.8872
Precision:  0.7761
Recall:     0.7411
F1-score:   0.7582

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6195, Test Loss: 0.6675, F1: 0.5486, AUC: 0.8611
Epoch [10/30] Train Loss: 0.4017, Test Loss: 0.3028, F1: 0.7307, AUC: 0.9151
Epoch [20/30] Train Loss: 0.3744, Test Loss: 0.4362, F1: 0.6993, AUC: 0.9240
Mejores resultados en la época:  29
f1-score 0.7611523268137586
AUC según el mejor F1-score 0.9275269422806658
Confusion Matrix:
 [[15196  1269]
 [ 1210  3950]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.8854
Precision:  0.7568
Recall:     0.7655
F1-score:   0.7612

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6927, Test Loss: 0.6214, F1: 0.4892, AUC: 0.7700
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6897, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6927, F1: 0.0000, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.4891572879494922
AUC según el mejor F1-score 0.770029255150107
Confusion Matrix:
 [[13369  3096]
 [ 2487  2673]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.7418
Precision:  0.4633
Recall:     0.5180
F1-score:   0.4892

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.6932, Test Loss: 0.6868, F1: 0.0000, AUC: 0.5001
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6906, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6913, F1: 0.0000, AUC: 0.5000
Mejores resultados en la época:  2
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5000968992248062
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/lyrics_bert/confusion_matrix_param_3189761.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853
Tiempo total para red 6: 640.84 segundos
Saved on: outputs_text_plus_numerical_categorical/0/lyrics_bert

==============================
Model: Logistic Regression
Accuracy:  0.8696
Precision: 0.6817
Recall:    0.8512
F1-score:  0.7570
              precision    recall  f1-score   support

           0       0.95      0.88      0.91     16465
           1       0.68      0.85      0.76      5160

    accuracy                           0.87     21625
   macro avg       0.82      0.86      0.83     21625
weighted avg       0.89      0.87      0.87     21625

[[14414  2051]
 [  768  4392]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.2928
Precision: 0.2499
Recall:    0.9812
F1-score:  0.3983
              precision    recall  f1-score   support

           0       0.93      0.08      0.14     16465
           1       0.25      0.98      0.40      5160

    accuracy                           0.29     21625
   macro avg       0.59      0.53      0.27     21625
weighted avg       0.77      0.29      0.20     21625

[[ 1268 15197]
 [   97  5063]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8057
Precision: 0.5656
Recall:    0.8008
F1-score:  0.6629
              precision    recall  f1-score   support

           0       0.93      0.81      0.86     16465
           1       0.57      0.80      0.66      5160

    accuracy                           0.81     21625
   macro avg       0.75      0.80      0.76     21625
weighted avg       0.84      0.81      0.82     21625

[[13291  3174]
 [ 1028  4132]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8561
Precision: 0.6711
Recall:    0.7789
F1-score:  0.7210
              precision    recall  f1-score   support

           0       0.93      0.88      0.90     16465
           1       0.67      0.78      0.72      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.87      0.86      0.86     21625

[[14495  1970]
 [ 1141  4019]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.8814
Precision: 0.7109
Recall:    0.8479
F1-score:  0.7734
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.77      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.88     21625

[[14686  1779]
 [  785  4375]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/xgboost_model.pkl

/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/musica_ia_workshop/models_comparison/testing_organized/preprocessed_data/main_only_text_plus_numerical_categorical.py:281: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
==============================
Model: Naive Bayes
Accuracy:  0.7978
Precision: 0.5574
Recall:    0.7409
F1-score:  0.6362
              precision    recall  f1-score   support

           0       0.91      0.82      0.86     16465
           1       0.56      0.74      0.64      5160

    accuracy                           0.80     21625
   macro avg       0.73      0.78      0.75     21625
weighted avg       0.83      0.80      0.81     21625

[[13429  3036]
 [ 1337  3823]]
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.8814, 'precision': 0.7109, 'recall': 0.8479, 'f1_score': 0.7734}
Logistic Regression: {'accuracy': 0.8696, 'precision': 0.6817, 'recall': 0.8512, 'f1_score': 0.757}
Random Forest: {'accuracy': 0.8561, 'precision': 0.6711, 'recall': 0.7789, 'f1_score': 0.721}
Decision Tree: {'accuracy': 0.8057, 'precision': 0.5656, 'recall': 0.8008, 'f1_score': 0.6629}
Naive Bayes: {'accuracy': 0.7978, 'precision': 0.5574, 'recall': 0.7409, 'f1_score': 0.6362}
SVM: {'accuracy': 0.2928, 'precision': 0.2499, 'recall': 0.9812, 'f1_score': 0.3983}
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 1536)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 1536), y: (108138,)
Shape filtrado  X: (108125, 1536), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 3621)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 3667)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 3667)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [3667, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.4766, Test Loss: 0.4583, F1: 0.6844, AUC: 0.9005
Epoch [10/30] Train Loss: 0.3405, Test Loss: 0.3085, F1: 0.7610, AUC: 0.9345
Epoch [20/30] Train Loss: 0.3230, Test Loss: 0.3711, F1: 0.7453, AUC: 0.9396
Mejores resultados en la época:  28
f1-score 0.7803302887720269
AUC según el mejor F1-score 0.9419571230493623
Confusion Matrix:
 [[15015  1450]
 [  931  4229]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.8899
Precision:  0.7447
Recall:     0.8196
F1-score:   0.7803

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6944, Test Loss: 0.6996, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6919, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6948, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6934, Test Loss: 0.6918, F1: 0.0000, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6955, F1: 0.3853, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6931, Test Loss: 0.6976, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  1
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6938, Test Loss: 0.6935, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6921, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6941, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853
Tiempo total para red 1: 562.06 segundos

Entrenando red 2 con capas [3667, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4877, Test Loss: 0.4246, F1: 0.6998, AUC: 0.8978
Epoch [10/30] Train Loss: 0.3489, Test Loss: 0.2825, F1: 0.7648, AUC: 0.9341
Epoch [20/30] Train Loss: 0.3232, Test Loss: 0.2766, F1: 0.7727, AUC: 0.9398
Mejores resultados en la época:  29
f1-score 0.7804647647836765
AUC según el mejor F1-score 0.9425593930748098
Confusion Matrix:
 [[15170  1295]
 [ 1029  4131]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.8925
Precision:  0.7613
Recall:     0.8006
F1-score:   0.7805

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4764, Test Loss: 0.4411, F1: 0.6922, AUC: 0.9005
Epoch [10/30] Train Loss: 0.3478, Test Loss: 0.3327, F1: 0.7525, AUC: 0.9346
Epoch [20/30] Train Loss: 0.3267, Test Loss: 0.4318, F1: 0.7088, AUC: 0.9422
Mejores resultados en la época:  27
f1-score 0.7926241134751772
AUC según el mejor F1-score 0.9459586520149625
Confusion Matrix:
 [[15241  1224]
 [  969  4191]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.8986
Precision:  0.7740
Recall:     0.8122
F1-score:   0.7926

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4760, Test Loss: 0.3656, F1: 0.7183, AUC: 0.9022
Epoch [10/30] Train Loss: 0.3429, Test Loss: 0.2742, F1: 0.7627, AUC: 0.9357
Epoch [20/30] Train Loss: 0.3162, Test Loss: 0.2508, F1: 0.7852, AUC: 0.9450
Mejores resultados en la época:  28
f1-score 0.7956788973738126
AUC según el mejor F1-score 0.9488549589568666
Confusion Matrix:
 [[15159  1306]
 [  888  4272]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.8985
Precision:  0.7659
Recall:     0.8279
F1-score:   0.7957

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4862, Test Loss: 0.3784, F1: 0.7133, AUC: 0.9010
==============================
Model: Naive Bayes
Accuracy:  0.7978
Precision: 0.5574
Recall:    0.7409
F1-score:  0.6362
              precision    recall  f1-score   support

           0       0.91      0.82      0.86     16465
           1       0.56      0.74      0.64      5160

    accuracy                           0.80     21625
   macro avg       0.73      0.78      0.75     21625
weighted avg       0.83      0.80      0.81     21625

[[13429  3036]
 [ 1337  3823]]
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/lyrics_bert/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/lyrics_bert/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.8814, 'precision': 0.7109, 'recall': 0.8479, 'f1_score': 0.7734}
Logistic Regression: {'accuracy': 0.8696, 'precision': 0.6817, 'recall': 0.8512, 'f1_score': 0.757}
Random Forest: {'accuracy': 0.8561, 'precision': 0.6711, 'recall': 0.7789, 'f1_score': 0.721}
Decision Tree: {'accuracy': 0.8057, 'precision': 0.5656, 'recall': 0.8008, 'f1_score': 0.6629}
Naive Bayes: {'accuracy': 0.7978, 'precision': 0.5574, 'recall': 0.7409, 'f1_score': 0.6362}
SVM: {'accuracy': 0.2928, 'precision': 0.2499, 'recall': 0.9812, 'f1_score': 0.3983}
Using text columns (Lyrics of the song) on the embeddings

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 1536)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
Shape original X: (108138, 1536), y: (108138,)
Shape filtrado  X: (108125, 1536), y: (108125,)
Contaning the categorical cols
Nuevas dimensiones X con categóricas: (108125, 3621)
Tamanio:  (108125, 43)
Total de columnas:  43
Columnas numericas usadas:  ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
Columnas del df:  ['Artist(s)', 'song', 'text', 'Length', 'emotion', 'Genre', 'Album', 'Key', 'Tempo', 'Loudness (db)', 'Time signature', 'Explicit', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Similar Artist 1', 'Similar Song 1', 'Similarity Score 1', 'Similar Artist 2', 'Similar Song 2', 'Similarity Score 2', 'Similar Artist 3', 'Similar Song 3', 'Similarity Score 3', 'song_normalized', 'artist_normalized', 'Release_Year', 'Release_Month', 'Release_Day']

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 3667)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 3667)
y shape: (41278,)
Resultados con MLP

Entrenando red 1 con capas [3667, 32, 1]

--- Iteración 1 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5152, Test Loss: 0.3650, F1: 0.6984, AUC: 0.8901
Epoch [10/30] Train Loss: 0.3451, Test Loss: 0.2765, F1: 0.7559, AUC: 0.9325
Epoch [20/30] Train Loss: 0.3246, Test Loss: 0.3383, F1: 0.7599, AUC: 0.9384
Mejores resultados en la época:  27
f1-score 0.77947932618683
AUC según el mejor F1-score 0.9407415130050355
Confusion Matrix:
 [[15249  1216]
 [ 1088  4072]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.8935
Precision:  0.7700
Recall:     0.7891
F1-score:   0.7795

--- Iteración 2 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5088, Test Loss: 0.5478, F1: 0.6365, AUC: 0.8914
Epoch [10/30] Train Loss: 0.3449, Test Loss: 0.3437, F1: 0.7500, AUC: 0.9320
Epoch [20/30] Train Loss: 0.3235, Test Loss: 0.3725, F1: 0.7433, AUC: 0.9382
Mejores resultados en la época:  27
f1-score 0.7766432041241201
AUC según el mejor F1-score 0.9407110867072978
Confusion Matrix:
 [[15455  1010]
 [ 1243  3917]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.8958
Precision:  0.7950
Recall:     0.7591
F1-score:   0.7766

--- Iteración 3 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.5863, Test Loss: 0.4180, F1: 0.6932, AUC: 0.8800
Epoch [10/30] Train Loss: 0.3581, Test Loss: 0.3629, F1: 0.7403, AUC: 0.9239
Epoch [20/30] Train Loss: 0.3363, Test Loss: 0.2832, F1: 0.7655, AUC: 0.9352
Mejores resultados en la época:  29
f1-score 0.772916851539622
AUC según el mejor F1-score 0.9386827472887052
Confusion Matrix:
 [[14711  1754]
 [  805  4355]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.8817
Precision:  0.7129
Recall:     0.8440
F1-score:   0.7729

--- Iteración 4 de 4 para la red 1 ---
Epoch [0/30] Train Loss: 0.6939, Test Loss: 0.6975, F1: 0.3853, AUC: 0.5000
Epoch [10/30] Train Loss: 0.6932, Test Loss: 0.6919, F1: 0.0000, AUC: 0.5000
Epoch [20/30] Train Loss: 0.6932, Test Loss: 0.6973, F1: 0.3853, AUC: 0.5000
Mejores resultados en la época:  0
f1-score 0.3852902744073175
AUC según el mejor F1-score 0.5
Confusion Matrix:
 [[    0 16465]
 [    0  5160]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_117409.png
Accuracy:   0.2386
Precision:  0.2386
Recall:     1.0000
F1-score:   0.3853
Tiempo total para red 1: 564.46 segundos

Entrenando red 2 con capas [3667, 64, 32, 1]

--- Iteración 1 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4711, Test Loss: 0.4499, F1: 0.6837, AUC: 0.9017
Epoch [10/30] Train Loss: 0.3415, Test Loss: 0.2816, F1: 0.7709, AUC: 0.9384
Epoch [20/30] Train Loss: 0.3088, Test Loss: 0.2655, F1: 0.7796, AUC: 0.9427
Mejores resultados en la época:  29
f1-score 0.7889567294929652
AUC según el mejor F1-score 0.948769218002952
Confusion Matrix:
 [[14782  1683]
 [  702  4458]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.8897
Precision:  0.7259
Recall:     0.8640
F1-score:   0.7890

--- Iteración 2 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4772, Test Loss: 0.4166, F1: 0.7009, AUC: 0.9016
Epoch [10/30] Train Loss: 0.3307, Test Loss: 0.2708, F1: 0.7720, AUC: 0.9374
Epoch [20/30] Train Loss: 0.3054, Test Loss: 0.3141, F1: 0.7665, AUC: 0.9447
Mejores resultados en la época:  26
f1-score 0.7961901059383808
AUC según el mejor F1-score 0.9485342234055325
Confusion Matrix:
 [[15432  1033]
 [ 1064  4096]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.9030
Precision:  0.7986
Recall:     0.7938
F1-score:   0.7962

--- Iteración 3 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4656, Test Loss: 0.4742, F1: 0.6746, AUC: 0.9036
Epoch [10/30] Train Loss: 0.3362, Test Loss: 0.2781, F1: 0.7706, AUC: 0.9377
Epoch [20/30] Train Loss: 0.3142, Test Loss: 0.2692, F1: 0.7825, AUC: 0.9440
Mejores resultados en la época:  26
f1-score 0.7944873824378433
AUC según el mejor F1-score 0.9474656482978928
Confusion Matrix:
 [[15152  1313]
 [  894  4266]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.8979
Precision:  0.7647
Recall:     0.8267
F1-score:   0.7945

--- Iteración 4 de 4 para la red 2 ---
Epoch [0/30] Train Loss: 0.4720, Test Loss: 0.3485, F1: 0.7206, AUC: 0.9038
Epoch [10/30] Train Loss: 0.3328, Test Loss: 0.3577, F1: 0.7418, AUC: 0.9379
Epoch [20/30] Train Loss: 0.3055, Test Loss: 0.2956, F1: 0.7749, AUC: 0.9454
Mejores resultados en la época:  28
f1-score 0.7936982750024928
AUC según el mejor F1-score 0.9478061697705022
Confusion Matrix:
 [[15576   889]
 [ 1180  3980]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.9043
Precision:  0.8174
Recall:     0.7713
F1-score:   0.7937
Tiempo total para red 2: 578.39 segundos

Entrenando red 3 con capas [3667, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4831, Test Loss: 0.4686, F1: 0.6759, AUC: 0.9009
Epoch [10/30] Train Loss: 0.3449, Test Loss: 0.3680, F1: 0.7401, AUC: 0.9355
Epoch [20/30] Train Loss: 0.3247, Test Loss: 0.2577, F1: 0.7674, AUC: 0.9405
Mejores resultados en la época:  29
f1-score 0.7881811204911742
AUC según el mejor F1-score 0.945227785271553
Confusion Matrix:
 [[15309  1156]
 [ 1052  4108]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8979
Precision:  0.7804
Recall:     0.7961
F1-score:   0.7882

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4716, Test Loss: 0.5103, F1: 0.6589, AUC: 0.9038
Epoch [10/30] Train Loss: 0.3462, Test Loss: 0.3237, F1: 0.7551, AUC: 0.9357
Epoch [20/30] Train Loss: 0.3169, Test Loss: 0.2911, F1: 0.7853, AUC: 0.9431
Mejores resultados en la época:  25
f1-score 0.790237706405371
AUC según el mejor F1-score 0.9469543099409835
Confusion Matrix:
 [[14958  1507]
 [  805  4355]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8931
Precision:  0.7429
Recall:     0.8440
F1-score:   0.7902

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4740, Test Loss: 0.3292, F1: 0.6993, AUC: 0.9026
Epoch [10/30] Train Loss: 0.3519, Test Loss: 0.3140, F1: 0.7569, AUC: 0.9340
Epoch [20/30] Train Loss: 0.3264, Test Loss: 0.2964, F1: 0.7696, AUC: 0.9408
Mejores resultados en la época:  29
f1-score 0.7830091156846161
AUC según el mejor F1-score 0.9446168052034265
Confusion Matrix:
 [[15150  1315]
 [  994  4166]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8932
Precision:  0.7601
Recall:     0.8074
F1-score:   0.7830

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4698, Test Loss: 0.3366, F1: 0.7199, AUC: 0.9040
Epoch [10/30] Train Loss: 0.3473, Test Loss: 0.4654, F1: 0.6815, AUC: 0.9351
Epoch [20/30] Train Loss: 0.3211, Test Loss: 0.2805, F1: 0.7747, AUC: 0.9426
Mejores resultados en la época:  21
f1-score 0.7890929326655537
AUC según el mejor F1-score 0.9446844316226339
Confusion Matrix:
 [[15097  1368]
 [  906  4254]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8948
Precision:  0.7567
Recall:     0.8244
F1-score:   0.7891
Tiempo total para red 3: 595.72 segundos

Entrenando red 4 con capas [3667, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4713, Test Loss: 0.3945, F1: 0.7088, AUC: 0.9047
Epoch [10/30] Train Loss: 0.3357, Test Loss: 0.3463, F1: 0.7489, AUC: 0.9376
Epoch [20/30] Train Loss: 0.3182, Test Loss: 0.3349, F1: 0.7582, AUC: 0.9443
Mejores resultados en la época:  27
f1-score 0.7949962658700522
AUC según el mejor F1-score 0.9478311110954174
Confusion Matrix:
 [[15171  1294]
 [  902  4258]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.8985
Precision:  0.7669
Recall:     0.8252
F1-score:   0.7950

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4642, Test Loss: 0.4317, F1: 0.6966, AUC: 0.9055
Epoch [10/30] Train Loss: 0.3417, Test Loss: 0.2731, F1: 0.7661, AUC: 0.9360
Epoch [20/30] Train Loss: 0.3178, Test Loss: 0.3357, F1: 0.7646, AUC: 0.9442
Mejores resultados en la época:  29
f1-score 0.7940038684719536
AUC según el mejor F1-score 0.9474888240736163
Confusion Matrix:
 [[15390  1075]
 [ 1055  4105]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.9015
Precision:  0.7925
Recall:     0.7955
F1-score:   0.7940

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4745, Test Loss: 0.3572, F1: 0.7227, AUC: 0.9037
Epoch [10/30] Train Loss: 0.3402, Test Loss: 0.3373, F1: 0.7520, AUC: 0.9359
Epoch [20/30] Train Loss: 0.3208, Test Loss: 0.4179, F1: 0.7296, AUC: 0.9428
Mejores resultados en la época:  28
f1-score 0.7961649089165868
AUC según el mejor F1-score 0.9483563031283179
Confusion Matrix:
 [[15347  1118]
 [ 1008  4152]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.9017
Precision:  0.7879
Recall:     0.8047
F1-score:   0.7962

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4703, Test Loss: 0.3621, F1: 0.7223, AUC: 0.9044
Epoch [10/30] Train Loss: 0.3451, Test Loss: 0.3048, F1: 0.7587, AUC: 0.9336
Epoch [20/30] Train Loss: 0.3225, Test Loss: 0.2971, F1: 0.7648, AUC: 0.9433
Mejores resultados en la época:  23
f1-score 0.7880097725991355
AUC según el mejor F1-score 0.9446908346810359
Confusion Matrix:
 [[15176  1289]
 [  967  4193]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.8957
Precision:  0.7649
Recall:     0.8126
F1-score:   0.7880
Tiempo total para red 4: 642.23 segundos

Entrenando red 5 con capas [3667, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4666, Test Loss: 0.4466, F1: 0.6924, AUC: 0.9069
Epoch [10/30] Train Loss: 0.3461, Test Loss: 0.2937, F1: 0.7612, AUC: 0.9363
Epoch [20/30] Train Loss: 0.3180, Test Loss: 0.4599, F1: 0.6850, AUC: 0.9435
Mejores resultados en la época:  28
f1-score 0.7935308928917296
AUC según el mejor F1-score 0.9468296386273916
Confusion Matrix:
 [[15396  1069]
 [ 1063  4097]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.9014
Precision:  0.7931
Recall:     0.7940
F1-score:   0.7935

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4700, Test Loss: 0.4265, F1: 0.7033, AUC: 0.9073
Epoch [10/30] Train Loss: 0.3444, Test Loss: 0.2814, F1: 0.7656, AUC: 0.9362
Epoch [20/30] Train Loss: 0.3172, Test Loss: 0.6228, F1: 0.5943, AUC: 0.9440
Mejores resultados en la época:  28
f1-score 0.796989616080785
AUC según el mejor F1-score 0.9481340087147508
Confusion Matrix:
 [[15311  1154]
 [  977  4183]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.9015
Precision:  0.7838
Recall:     0.8107
F1-score:   0.7970

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4720, Test Loss: 0.3383, F1: 0.7200, AUC: 0.9048
Epoch [10/30] Train Loss: 0.3493, Test Loss: 0.3127, F1: 0.7570, AUC: 0.9359
Epoch [20/30] Train Loss: 0.3139, Test Loss: 0.2630, F1: 0.7800, AUC: 0.9433
Mejores resultados en la época:  29
f1-score 0.7951142631993696
AUC según el mejor F1-score 0.9482193789033351
Confusion Matrix:
 [[15509   956]
 [ 1124  4036]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.9038
Precision:  0.8085
Recall:     0.7822
F1-score:   0.7951

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4674, Test Loss: 0.4511, F1: 0.6720, AUC: 0.9062
Epoch [10/30] Train Loss: 0.3407, Test Loss: 0.2968, F1: 0.7624, AUC: 0.9364
Epoch [20/30] Train Loss: 0.3091, Test Loss: 0.4335, F1: 0.6969, AUC: 0.9452
Mejores resultados en la época:  24
f1-score 0.787033546928006
AUC según el mejor F1-score 0.9449135351709169
Confusion Matrix:
 [[15189  1276]
 [  984  4176]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.8955
Precision:  0.7660
Recall:     0.8093
Epoch [10/30] Train Loss: 0.3441, Test Loss: 0.2892, F1: 0.7631, AUC: 0.9353
Epoch [20/30] Train Loss: 0.3166, Test Loss: 0.4647, F1: 0.7065, AUC: 0.9408
Mejores resultados en la época:  25
f1-score 0.7944298373746227
AUC según el mejor F1-score 0.9463711372726267
Confusion Matrix:
 [[15435  1030]
 [ 1081  4079]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_236865.png
Accuracy:   0.9024
Precision:  0.7984
Recall:     0.7905
F1-score:   0.7944
Tiempo total para red 2: 580.83 segundos

Entrenando red 3 con capas [3667, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4728, Test Loss: 0.5195, F1: 0.6523, AUC: 0.9023
Epoch [10/30] Train Loss: 0.3418, Test Loss: 0.3740, F1: 0.7346, AUC: 0.9358
Epoch [20/30] Train Loss: 0.3138, Test Loss: 0.3100, F1: 0.7695, AUC: 0.9407
Mejores resultados en la época:  29
f1-score 0.7844759306521165
AUC según el mejor F1-score 0.9475462632739874
Confusion Matrix:
 [[14719  1746]
 [  703  4457]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8868
Precision:  0.7185
Recall:     0.8638
F1-score:   0.7845

--- Iteración 2 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4778, Test Loss: 0.4299, F1: 0.6957, AUC: 0.9036
Epoch [10/30] Train Loss: 0.3440, Test Loss: 0.3090, F1: 0.7622, AUC: 0.9347
Epoch [20/30] Train Loss: 0.3204, Test Loss: 0.2553, F1: 0.7825, AUC: 0.9419
Mejores resultados en la época:  28
f1-score 0.7956388034665921
AUC según el mejor F1-score 0.9479596666172313
Confusion Matrix:
 [[15163  1302]
 [  891  4269]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8986
Precision:  0.7663
Recall:     0.8273
F1-score:   0.7956

--- Iteración 3 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4758, Test Loss: 0.3845, F1: 0.7104, AUC: 0.9016
Epoch [10/30] Train Loss: 0.3425, Test Loss: 0.3496, F1: 0.7478, AUC: 0.9364
Epoch [20/30] Train Loss: 0.3088, Test Loss: 0.2779, F1: 0.7901, AUC: 0.9453
Mejores resultados en la época:  25
f1-score 0.7913629233182615
AUC según el mejor F1-score 0.946910424273241
Confusion Matrix:
 [[15076  1389]
 [  872  4288]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8954
Precision:  0.7553
Recall:     0.8310
F1-score:   0.7914

--- Iteración 4 de 4 para la red 3 ---
Epoch [0/30] Train Loss: 0.4825, Test Loss: 0.5113, F1: 0.6553, AUC: 0.9020
Epoch [10/30] Train Loss: 0.3446, Test Loss: 0.3960, F1: 0.7230, AUC: 0.9356
Epoch [20/30] Train Loss: 0.3161, Test Loss: 0.3906, F1: 0.7329, AUC: 0.9439
Mejores resultados en la época:  22
f1-score 0.7887243735763098
AUC según el mejor F1-score 0.9446503859490534
Confusion Matrix:
 [[15244  1221]
 [ 1005  4155]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_479873.png
Accuracy:   0.8971
Precision:  0.7729
Recall:     0.8052
F1-score:   0.7887
Tiempo total para red 3: 598.53 segundos

Entrenando red 4 con capas [3667, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4699, Test Loss: 0.5395, F1: 0.6325, AUC: 0.9047
Epoch [10/30] Train Loss: 0.3466, Test Loss: 0.2780, F1: 0.7632, AUC: 0.9359
Epoch [20/30] Train Loss: 0.3219, Test Loss: 0.3183, F1: 0.7628, AUC: 0.9426
Mejores resultados en la época:  25
f1-score 0.7886417415996214
AUC según el mejor F1-score 0.9453186639736157
Confusion Matrix:
 [[15226  1239]
 [  994  4166]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.8967
Precision:  0.7708
Recall:     0.8074
F1-score:   0.7886

--- Iteración 2 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4712, Test Loss: 0.3883, F1: 0.7143, AUC: 0.9038
Epoch [10/30] Train Loss: 0.3418, Test Loss: 0.3354, F1: 0.7524, AUC: 0.9360
Epoch [20/30] Train Loss: 0.3227, Test Loss: 0.2601, F1: 0.7769, AUC: 0.9416
Mejores resultados en la época:  27
f1-score 0.7936297279362973
AUC según el mejor F1-score 0.9469020908810561
Confusion Matrix:
 [[15262  1203]
 [  974  4186]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.8993
Precision:  0.7768
Recall:     0.8112
F1-score:   0.7936

--- Iteración 3 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4811, Test Loss: 0.4001, F1: 0.7092, AUC: 0.9023
Epoch [10/30] Train Loss: 0.3455, Test Loss: 0.3337, F1: 0.7539, AUC: 0.9357
Epoch [20/30] Train Loss: 0.3222, Test Loss: 0.3282, F1: 0.7694, AUC: 0.9442
Mejores resultados en la época:  24
f1-score 0.7928768688696315
AUC según el mejor F1-score 0.9470318587466486
Confusion Matrix:
 [[15287  1178]
 [  997  4163]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.8994
Precision:  0.7794
Recall:     0.8068
F1-score:   0.7929

--- Iteración 4 de 4 para la red 4 ---
Epoch [0/30] Train Loss: 0.4623, Test Loss: 0.3331, F1: 0.7147, AUC: 0.9067
Epoch [10/30] Train Loss: 0.3495, Test Loss: 0.2722, F1: 0.7458, AUC: 0.9352
Epoch [20/30] Train Loss: 0.3218, Test Loss: 0.2543, F1: 0.7832, AUC: 0.9435
Mejores resultados en la época:  28
f1-score 0.7919969070172047
AUC según el mejor F1-score 0.9466600988236735
Confusion Matrix:
 [[15376  1089]
 [ 1063  4097]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_982273.png
Accuracy:   0.9005
Precision:  0.7900
Recall:     0.7940
F1-score:   0.7920
Tiempo total para red 4: 644.31 segundos

Entrenando red 5 con capas [3667, 512, 256, 128, 64, 1]

--- Iteración 1 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4680, Test Loss: 0.5207, F1: 0.6491, AUC: 0.9059
Epoch [10/30] Train Loss: 0.3496, Test Loss: 0.2977, F1: 0.7631, AUC: 0.9352
Epoch [20/30] Train Loss: 0.3229, Test Loss: 0.3384, F1: 0.7533, AUC: 0.9432
Mejores resultados en la época:  28
f1-score 0.7945127179194056
AUC según el mejor F1-score 0.9478740727924161
Confusion Matrix:
 [[15298  1167]
 [  990  4170]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.9003
Precision:  0.7813
Recall:     0.8081
F1-score:   0.7945

--- Iteración 2 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4664, Test Loss: 0.3196, F1: 0.7069, AUC: 0.9069
Epoch [10/30] Train Loss: 0.3444, Test Loss: 0.2831, F1: 0.7039, AUC: 0.9335
Epoch [20/30] Train Loss: 0.3168, Test Loss: 0.4136, F1: 0.7283, AUC: 0.9435
Mejores resultados en la época:  28
f1-score 0.794123332688962
AUC según el mejor F1-score 0.9469737486375845
Confusion Matrix:
 [[15387  1078]
 [ 1052  4108]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.9015
Precision:  0.7921
Recall:     0.7961
F1-score:   0.7941

--- Iteración 3 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4722, Test Loss: 0.3752, F1: 0.7190, AUC: 0.9060
Epoch [10/30] Train Loss: 0.3462, Test Loss: 0.4177, F1: 0.7244, AUC: 0.9363
Epoch [20/30] Train Loss: 0.3169, Test Loss: 0.2839, F1: 0.7697, AUC: 0.9413
Mejores resultados en la época:  26
f1-score 0.785479719534925
AUC según el mejor F1-score 0.9473967624535953
Confusion Matrix:
 [[14783  1682]
 [  735  4425]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.8882
Precision:  0.7246
Recall:     0.8576
F1-score:   0.7855

--- Iteración 4 de 4 para la red 5 ---
Epoch [0/30] Train Loss: 0.4701, Test Loss: 0.3736, F1: 0.7186, AUC: 0.9055
Epoch [10/30] Train Loss: 0.3451, Test Loss: 0.3596, F1: 0.7354, AUC: 0.9362
Epoch [20/30] Train Loss: 0.3132, Test Loss: 0.2649, F1: 0.7841, AUC: 0.9444
Mejores resultados en la época:  29
f1-score 0.792130518234165
AUC según el mejor F1-score 0.9471688300529431
Confusion Matrix:
 [[15332  1133]
 [ 1033  4127]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_2050561.png
Accuracy:   0.8998
Precision:  0.7846
Recall:     0.7998
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:47:03] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:47:04] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
F1-score:   0.7870
Tiempo total para red 5: 673.87 segundos

Entrenando red 6 con capas [3667, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.4841, Test Loss: 0.4332, F1: 0.6952, AUC: 0.9024
Epoch [10/30] Train Loss: 0.3527, Test Loss: 0.3120, F1: 0.7574, AUC: 0.9352
Epoch [20/30] Train Loss: 0.3155, Test Loss: 0.2844, F1: 0.7766, AUC: 0.9431
Mejores resultados en la época:  26
f1-score 0.7945179036772513
AUC según el mejor F1-score 0.947361839890583
Confusion Matrix:
 [[15380  1085]
 [ 1044  4116]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.9015
Precision:  0.7914
Recall:     0.7977
F1-score:   0.7945

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5007, Test Loss: 0.4034, F1: 0.7003, AUC: 0.9058
Epoch [10/30] Train Loss: 0.3454, Test Loss: 0.6277, F1: 0.6272, AUC: 0.9370
Epoch [20/30] Train Loss: 0.3211, Test Loss: 0.3091, F1: 0.7442, AUC: 0.9397
Mejores resultados en la época:  22
f1-score 0.787700008938947
AUC según el mejor F1-score 0.9466402422804303
Confusion Matrix:
 [[14844  1621]
 [  754  4406]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.8902
Precision:  0.7310
Recall:     0.8539
F1-score:   0.7877

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.4789, Test Loss: 0.3368, F1: 0.7107, AUC: 0.9044
Epoch [10/30] Train Loss: 0.3457, Test Loss: 0.2946, F1: 0.7644, AUC: 0.9358
Epoch [20/30] Train Loss: 0.3173, Test Loss: 0.2875, F1: 0.7795, AUC: 0.9440
Mejores resultados en la época:  27
f1-score 0.7929371074906708
AUC según el mejor F1-score 0.9481947612624383
Confusion Matrix:
 [[14994  1471]
 [  804  4356]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.8948
Precision:  0.7476
Recall:     0.8442
F1-score:   0.7929

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.4837, Test Loss: 0.3630, F1: 0.7193, AUC: 0.9055
Epoch [10/30] Train Loss: 0.3504, Test Loss: 0.3516, F1: 0.7450, AUC: 0.9354
Epoch [20/30] Train Loss: 0.3186, Test Loss: 0.2774, F1: 0.7765, AUC: 0.9431
Mejores resultados en la época:  28
f1-score 0.7928218761868591
AUC según el mejor F1-score 0.9473488689891878
Confusion Matrix:
 [[15268  1197]
 [  985  4175]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.8991
Precision:  0.7772
Recall:     0.8091
F1-score:   0.7928
Tiempo total para red 6: 823.77 segundos
Saved on: outputs_text_plus_numerical_categorical/0/gpt

==============================
Model: Logistic Regression
Accuracy:  0.8855
Precision: 0.7122
Recall:    0.8727
F1-score:  0.7843
              precision    recall  f1-score   support

           0       0.96      0.89      0.92     16465
           1       0.71      0.87      0.78      5160

    accuracy                           0.89     21625
   macro avg       0.83      0.88      0.85     21625
weighted avg       0.90      0.89      0.89     21625

[[14645  1820]
 [  657  4503]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.7070
Precision: 0.4421
Recall:    0.8707
F1-score:  0.5864
              precision    recall  f1-score   support

           0       0.94      0.66      0.77     16465
           1       0.44      0.87      0.59      5160

    accuracy                           0.71     21625
   macro avg       0.69      0.76      0.68     21625
weighted avg       0.82      0.71      0.73     21625

[[10795  5670]
 [  667  4493]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8196
Precision: 0.5934
Recall:    0.7754
F1-score:  0.6723
              precision    recall  f1-score   support

           0       0.92      0.83      0.88     16465
           1       0.59      0.78      0.67      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625

[[13723  2742]
 [ 1159  4001]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8573
Precision: 0.6779
Recall:    0.7661
F1-score:  0.7193
              precision    recall  f1-score   support

           0       0.92      0.89      0.90     16465
           1       0.68      0.77      0.72      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.86      0.86      0.86     21625

[[14587  1878]
 [ 1207  3953]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.8909
Precision: 0.7331
Recall:    0.8537
F1-score:  0.7888
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.85      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

[[14861  1604]
 [  755  4405]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
F1-score:   0.7921
Tiempo total para red 5: 678.49 segundos

Entrenando red 6 con capas [3667, 1024, 512, 256, 128, 64, 32, 1]

--- Iteración 1 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5191, Test Loss: 0.4966, F1: 0.6716, AUC: 0.9000
Epoch [10/30] Train Loss: 0.3482, Test Loss: 0.3011, F1: 0.7542, AUC: 0.9345
Epoch [20/30] Train Loss: 0.3181, Test Loss: 0.3336, F1: 0.7433, AUC: 0.9437
Mejores resultados en la época:  27
f1-score 0.7929062893691249
AUC según el mejor F1-score 0.947329377326111
Confusion Matrix:
 [[15397  1068]
 [ 1069  4091]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.9012
Precision:  0.7930
Recall:     0.7928
F1-score:   0.7929

--- Iteración 2 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.5197, Test Loss: 0.3404, F1: 0.7082, AUC: 0.8994
Epoch [10/30] Train Loss: 0.3436, Test Loss: 0.2681, F1: 0.7622, AUC: 0.9344
Epoch [20/30] Train Loss: 0.3236, Test Loss: 0.4023, F1: 0.7334, AUC: 0.9414
Mejores resultados en la época:  24
f1-score 0.7877697841726619
AUC según el mejor F1-score 0.9455546413934187
Confusion Matrix:
 [[15559   906]
 [ 1218  3942]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.9018
Precision:  0.8131
Recall:     0.7640
F1-score:   0.7878

--- Iteración 3 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.4785, Test Loss: 0.3347, F1: 0.7194, AUC: 0.9054
Epoch [10/30] Train Loss: 0.3572, Test Loss: 0.4064, F1: 0.7267, AUC: 0.9341
Epoch [20/30] Train Loss: 0.3291, Test Loss: 0.3132, F1: 0.7618, AUC: 0.9402
Mejores resultados en la época:  18
f1-score 0.7689099526066351
AUC según el mejor F1-score 0.9389229267155842
Confusion Matrix:
 [[15131  1334]
 [ 1104  4056]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.8873
Precision:  0.7525
Recall:     0.7860
F1-score:   0.7689

--- Iteración 4 de 4 para la red 6 ---
Epoch [0/30] Train Loss: 0.4968, Test Loss: 0.3870, F1: 0.7100, AUC: 0.9007
Epoch [10/30] Train Loss: 0.3474, Test Loss: 0.5664, F1: 0.6243, AUC: 0.9353
Epoch [20/30] Train Loss: 0.3227, Test Loss: 0.2730, F1: 0.7873, AUC: 0.9446
Mejores resultados en la época:  21
f1-score 0.7882341632221475
AUC según el mejor F1-score 0.9437353724249465
Confusion Matrix:
 [[15322  1143]
 [ 1060  4100]]
Matriz de confusión guardada en: outputs_text_plus_numerical_categorical/0/gpt/confusion_matrix_param_4455425.png
Accuracy:   0.8981
Precision:  0.7820
Recall:     0.7946
F1-score:   0.7882
Tiempo total para red 6: 827.45 segundos
Saved on: outputs_text_plus_numerical_categorical/0/gpt

==============================
Model: Logistic Regression
Accuracy:  0.8855
Precision: 0.7122
Recall:    0.8727
F1-score:  0.7843
              precision    recall  f1-score   support

           0       0.96      0.89      0.92     16465
           1       0.71      0.87      0.78      5160

    accuracy                           0.89     21625
   macro avg       0.83      0.88      0.85     21625
weighted avg       0.90      0.89      0.89     21625

[[14645  1820]
 [  657  4503]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/logistic_regression_model.pkl

==============================
Model: SVM
Accuracy:  0.7070
Precision: 0.4421
Recall:    0.8707
F1-score:  0.5864
              precision    recall  f1-score   support

           0       0.94      0.66      0.77     16465
           1       0.44      0.87      0.59      5160

    accuracy                           0.71     21625
   macro avg       0.69      0.76      0.68     21625
weighted avg       0.82      0.71      0.73     21625

[[10795  5670]
 [  667  4493]]
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_svm.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/svm_model.pkl

==============================
Model: Decision Tree
Accuracy:  0.8196
Precision: 0.5934
Recall:    0.7754
F1-score:  0.6723
              precision    recall  f1-score   support

           0       0.92      0.83      0.88     16465
           1       0.59      0.78      0.67      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625

[[13723  2742]
 [ 1159  4001]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_decision_tree.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/decision_tree_model.pkl

==============================
Model: Random Forest
Accuracy:  0.8573
Precision: 0.6779
Recall:    0.7661
F1-score:  0.7193
              precision    recall  f1-score   support

           0       0.92      0.89      0.90     16465
           1       0.68      0.77      0.72      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.86      0.86      0.86     21625

[[14587  1878]
 [ 1207  3953]]
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_random_forest.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/random_forest_model.pkl

==============================
Model: XGBoost
Accuracy:  0.8909
Precision: 0.7331
Recall:    0.8537
F1-score:  0.7888
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.85      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

[[14861  1604]
 [  755  4405]]
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.8652
Precision: 0.6960
Recall:    0.7721
F1-score:  0.7321
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     16465
           1       0.70      0.77      0.73      5160

    accuracy                           0.87     21625
   macro avg       0.81      0.83      0.82     21625
weighted avg       0.87      0.87      0.87     21625

[[14725  1740]
 [ 1176  3984]]
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.8909, 'precision': 0.7331, 'recall': 0.8537, 'f1_score': 0.7888}
Logistic Regression: {'accuracy': 0.8855, 'precision': 0.7122, 'recall': 0.8727, 'f1_score': 0.7843}
Naive Bayes: {'accuracy': 0.8652, 'precision': 0.696, 'recall': 0.7721, 'f1_score': 0.7321}
Random Forest: {'accuracy': 0.8573, 'precision': 0.6779, 'recall': 0.7661, 'f1_score': 0.7193}
Decision Tree: {'accuracy': 0.8196, 'precision': 0.5934, 'recall': 0.7754, 'f1_score': 0.6723}
SVM: {'accuracy': 0.707, 'precision': 0.4421, 'recall': 0.8707, 'f1_score': 0.5864}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
XGBoost: {'accuracy': 0.9193, 'precision': 0.7892, 'recall': 0.9027, 'f1_score': 0.8422}
Decision Tree: {'accuracy': 0.8969, 'precision': 0.7459, 'recall': 0.8612, 'f1_score': 0.7994}
MLP_458561: {'accuracy': 0.8954450867052023, 'precision': 0.7800966183574879, 'recall': 0.7823643410852713, 'f1_score': 0.7812288340590228, 'f1_score_avg': 0.7712108300392371}
MLP_923265: {'accuracy': 0.8902196531791907, 'precision': 0.7632275132275133, 'recall': 0.7827519379844962, 'f1_score': 0.7812288340590228, 'f1_score_avg': 0.7708726461114724}
MLP_1869057: {'accuracy': 0.8851329479768786, 'precision': 0.7264725795531483, 'recall': 0.8317829457364341, 'f1_score': 0.7812288340590228, 'f1_score_avg': 0.7748001558227835}
MLP_3824129: {'accuracy': 0.8909595375722543, 'precision': 0.7635440180586908, 'recall': 0.7866279069767442, 'f1_score': 0.7812288340590228, 'f1_score_avg': 0.7715733093558201}
MLP_8002561: {'accuracy': 0.8785202312138728, 'precision': 0.7487723433510116, 'recall': 0.7387596899224806, 'f1_score': 0.7812288340590228, 'f1_score_avg': 0.7659739867839519}
MLP_228257: {'accuracy': 0.8756069364161849, 'precision': 0.7294685990338164, 'recall': 0.7608527131782946, 'f1_score': 0.7646571560055223, 'f1_score_avg': 0.7518921678186634}
Random Forest: {'accuracy': 0.878, 'precision': 0.7197, 'recall': 0.8006, 'f1_score': 0.758}
Logistic Regression: {'accuracy': 0.8697, 'precision': 0.6819, 'recall': 0.8508, 'f1_score': 0.757}
Naive Bayes: {'accuracy': 0.8238, 'precision': 0.6065, 'recall': 0.745, 'f1_score': 0.6686}
SVM: {'accuracy': 0.4499, 'precision': 0.2985, 'recall': 0.9667, 'f1_score': 0.4561}


EMBEDDINGS TYPE: LYRICS_BERT
XGBoost: {'accuracy': 0.8814, 'precision': 0.7109, 'recall': 0.8479, 'f1_score': 0.7734}
MLP_665857: {'accuracy': 0.884578034682081, 'precision': 0.7568453528731199, 'recall': 0.7606589147286822, 'f1_score': 0.7613077442376314, 'f1_score_avg': 0.7583742426003}
MLP_1417729: {'accuracy': 0.8857803468208092, 'precision': 0.7630035197497067, 'recall': 0.756201550387597, 'f1_score': 0.7613077442376314, 'f1_score_avg': 0.6631718459594014}
MLP_3189761: {'accuracy': 0.23861271676300577, 'precision': 0.23861271676300577, 'recall': 1.0, 'f1_score': 0.7613077442376314, 'f1_score_avg': 0.5984508794008011}
MLP_157761: {'accuracy': 0.8789364161849711, 'precision': 0.7265597147950089, 'recall': 0.789922480620155, 'f1_score': 0.7596749226006192, 'f1_score_avg': 0.7550550200029815}
MLP_321665: {'accuracy': 0.8794913294797688, 'precision': 0.7331994156318481, 'recall': 0.7781007751937985, 'f1_score': 0.7596749226006192, 'f1_score_avg': 0.7562430663825171}
Logistic Regression: {'accuracy': 0.8696, 'precision': 0.6817, 'recall': 0.8512, 'f1_score': 0.757}
MLP_77857: {'accuracy': 0.23861271676300577, 'precision': 0.23861271676300577, 'recall': 1.0, 'f1_score': 0.7569022226652048, 'f1_score_avg': 0.5708684106333681}
Random Forest: {'accuracy': 0.8561, 'precision': 0.6711, 'recall': 0.7789, 'f1_score': 0.721}
Decision Tree: {'accuracy': 0.8057, 'precision': 0.5656, 'recall': 0.8008, 'f1_score': 0.6629}
Naive Bayes: {'accuracy': 0.7978, 'precision': 0.5574, 'recall': 0.7409, 'f1_score': 0.6362}
SVM: {'accuracy': 0.2928, 'precision': 0.2499, 'recall': 0.9812, 'f1_score': 0.3983}


EMBEDDINGS TYPE: GPT
MLP_2050561: {'accuracy': 0.8954913294797688, 'precision': 0.7659574468085106, 'recall': 0.8093023255813954, 'f1_score': 0.796989616080785, 'f1_score_avg': 0.7931670797749726}
MLP_4455425: {'accuracy': 0.8990982658959538, 'precision': 0.7771779597915115, 'recall': 0.8091085271317829, 'f1_score': 0.796989616080785, 'f1_score_avg': 0.791994224073432}
MLP_982273: {'accuracy': 0.8956763005780347, 'precision': 0.7648668369208318, 'recall': 0.8125968992248062, 'f1_score': 0.7961649089165868, 'f1_score_avg': 0.7932937039644321}
MLP_236865: {'accuracy': 0.9043236994219653, 'precision': 0.8174163072499486, 'recall': 0.7713178294573644, 'f1_score': 0.7956788973738126, 'f1_score_avg': 0.7906165126587898}
MLP_479873: {'accuracy': 0.8948439306358381, 'precision': 0.7566702241195304, 'recall': 0.8244186046511628, 'f1_score': 0.7956788973738126, 'f1_score_avg': 0.7876302188116787}
XGBoost: {'accuracy': 0.8909, 'precision': 0.7331, 'recall': 0.8537, 'f1_score': 0.7888}
Logistic Regression: {'accuracy': 0.8855, 'precision': 0.7122, 'recall': 0.8727, 'f1_score': 0.7843}
MLP_117409: {'accuracy': 0.23861271676300577, 'precision': 0.23861271676300577, 'recall': 1.0, 'f1_score': 0.7803302887720269, 'f1_score_avg': 0.4840502779984948}
Naive Bayes: {'accuracy': 0.8652, 'precision': 0.696, 'recall': 0.7721, 'f1_score': 0.7321}
Random Forest: {'accuracy': 0.8573, 'precision': 0.6779, 'recall': 0.7661, 'f1_score': 0.7193}
Decision Tree: {'accuracy': 0.8196, 'precision': 0.5934, 'recall': 0.7754, 'f1_score': 0.6723}
SVM: {'accuracy': 0.707, 'precision': 0.4421, 'recall': 0.8707, 'f1_score': 0.5864}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['text']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
====================================

Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_xgboost.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes
Accuracy:  0.8652
Precision: 0.6960
Recall:    0.7721
F1-score:  0.7321
              precision    recall  f1-score   support

           0       0.93      0.89      0.91     16465
           1       0.70      0.77      0.73      5160

    accuracy                           0.87     21625
   macro avg       0.81      0.83      0.82     21625
weighted avg       0.87      0.87      0.87     21625

[[14725  1740]
 [ 1176  3984]]
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}
Confusion matrix saved as: outputs_text_plus_numerical_categorical/0/gpt/conf_matrix_naive_bayes.png
Modelo guardado como: outputs_text_plus_numerical_categorical/0/gpt/naive_bayes_model.pkl


Resumen de métricas:
XGBoost: {'accuracy': 0.8909, 'precision': 0.7331, 'recall': 0.8537, 'f1_score': 0.7888}
Logistic Regression: {'accuracy': 0.8855, 'precision': 0.7122, 'recall': 0.8727, 'f1_score': 0.7843}
Naive Bayes: {'accuracy': 0.8652, 'precision': 0.696, 'recall': 0.7721, 'f1_score': 0.7321}
Random Forest: {'accuracy': 0.8573, 'precision': 0.6779, 'recall': 0.7661, 'f1_score': 0.7193}
Decision Tree: {'accuracy': 0.8196, 'precision': 0.5934, 'recall': 0.7754, 'f1_score': 0.6723}
SVM: {'accuracy': 0.707, 'precision': 0.4421, 'recall': 0.8707, 'f1_score': 0.5864}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
XGBoost: {'accuracy': 0.9193, 'precision': 0.7892, 'recall': 0.9027, 'f1_score': 0.8422}
Decision Tree: {'accuracy': 0.8969, 'precision': 0.7459, 'recall': 0.8612, 'f1_score': 0.7994}
MLP_923265: {'accuracy': 0.8805549132947977, 'precision': 0.7241259349452078, 'recall': 0.806782945736434, 'f1_score': 0.7799771602588504, 'f1_score_avg': 0.7683875376158373}
MLP_1869057: {'accuracy': 0.8887861271676301, 'precision': 0.7633339705601223, 'recall': 0.7738372093023256, 'f1_score': 0.7799771602588504, 'f1_score_avg': 0.7703304173864453}
MLP_3824129: {'accuracy': 0.8884624277456648, 'precision': 0.7439630681818182, 'recall': 0.812015503875969, 'f1_score': 0.7799771602588504, 'f1_score_avg': 0.776261540248864}
MLP_8002561: {'accuracy': 0.8826820809248555, 'precision': 0.7192044125020892, 'recall': 0.8339147286821705, 'f1_score': 0.7799771602588504, 'f1_score_avg': 0.7578094549064445}
MLP_458561: {'accuracy': 0.8938265895953758, 'precision': 0.7917685411572942, 'recall': 0.7531007751937985, 'f1_score': 0.7719507350019865, 'f1_score_avg': 0.7640548664746205}
Random Forest: {'accuracy': 0.878, 'precision': 0.7197, 'recall': 0.8006, 'f1_score': 0.758}
Logistic Regression: {'accuracy': 0.8697, 'precision': 0.6819, 'recall': 0.8508, 'f1_score': 0.757}
MLP_228257: {'accuracy': 0.23861271676300577, 'precision': 0.23861271676300577, 'recall': 1.0, 'f1_score': 0.7429809870948675, 'f1_score_avg': 0.474712952579205}
Naive Bayes: {'accuracy': 0.8238, 'precision': 0.6065, 'recall': 0.745, 'f1_score': 0.6686}
SVM: {'accuracy': 0.4499, 'precision': 0.2985, 'recall': 0.9667, 'f1_score': 0.4561}


EMBEDDINGS TYPE: LYRICS_BERT
XGBoost: {'accuracy': 0.8814, 'precision': 0.7109, 'recall': 0.8479, 'f1_score': 0.7734}
MLP_665857: {'accuracy': 0.8873526011560694, 'precision': 0.7785276073619631, 'recall': 0.7377906976744186, 'f1_score': 0.7625157966365316, 'f1_score_avg': 0.7594528578978548}
MLP_1417729: {'accuracy': 0.8863815028901734, 'precision': 0.7705705705705705, 'recall': 0.7459302325581395, 'f1_score': 0.7625157966365316, 'f1_score_avg': 0.6648750100225849}
MLP_3189761: {'accuracy': 0.8852254335260116, 'precision': 0.7693081255028158, 'recall': 0.7412790697674418, 'f1_score': 0.7625157966365316, 'f1_score_avg': 0.6644081626495932}
MLP_321665: {'accuracy': 0.8864739884393064, 'precision': 0.7652480878603648, 'recall': 0.756201550387597, 'f1_score': 0.760697923774247, 'f1_score_avg': 0.7588475592068988}
MLP_157761: {'accuracy': 0.8850404624277457, 'precision': 0.7641248518372185, 'recall': 0.7496124031007751, 'f1_score': 0.7601661354196851, 'f1_score_avg': 0.7578600821321669}
MLP_77857: {'accuracy': 0.8851791907514451, 'precision': 0.7640560268297495, 'recall': 0.7505813953488372, 'f1_score': 0.757258774073712, 'f1_score_avg': 0.5705121821832828}
Logistic Regression: {'accuracy': 0.8696, 'precision': 0.6817, 'recall': 0.8512, 'f1_score': 0.757}
Random Forest: {'accuracy': 0.8561, 'precision': 0.6711, 'recall': 0.7789, 'f1_score': 0.721}
Decision Tree: {'accuracy': 0.8057, 'precision': 0.5656, 'recall': 0.8008, 'f1_score': 0.6629}
Naive Bayes: {'accuracy': 0.7978, 'precision': 0.5574, 'recall': 0.7409, 'f1_score': 0.6362}
SVM: {'accuracy': 0.2928, 'precision': 0.2499, 'recall': 0.9812, 'f1_score': 0.3983}


EMBEDDINGS TYPE: GPT
MLP_236865: {'accuracy': 0.9023815028901734, 'precision': 0.7983949892346839, 'recall': 0.7905038759689923, 'f1_score': 0.7961901059383808, 'f1_score_avg': 0.793516013810953}
MLP_479873: {'accuracy': 0.8970635838150289, 'precision': 0.7728794642857143, 'recall': 0.8052325581395349, 'f1_score': 0.7961901059383808, 'f1_score_avg': 0.79005050775332}
MLP_982273: {'accuracy': 0.900485549132948, 'precision': 0.7900115696104898, 'recall': 0.7939922480620155, 'f1_score': 0.7961901059383808, 'f1_score_avg': 0.7917863113556887}
MLP_2050561: {'accuracy': 0.8998381502890174, 'precision': 0.7846007604562738, 'recall': 0.7998062015503876, 'f1_score': 0.7961901059383808, 'f1_score_avg': 0.7915615720943644}
MLP_4455425: {'accuracy': 0.8981271676300578, 'precision': 0.7819950410070571, 'recall': 0.7945736434108527, 'f1_score': 0.7961901059383808, 'f1_score_avg': 0.7844550473426424}
XGBoost: {'accuracy': 0.8909, 'precision': 0.7331, 'recall': 0.8537, 'f1_score': 0.7888}
Logistic Regression: {'accuracy': 0.8855, 'precision': 0.7122, 'recall': 0.8727, 'f1_score': 0.7843}
MLP_117409: {'accuracy': 0.23861271676300577, 'precision': 0.23861271676300577, 'recall': 1.0, 'f1_score': 0.77947932618683, 'f1_score_avg': 0.6785824140644724}
Naive Bayes: {'accuracy': 0.8652, 'precision': 0.696, 'recall': 0.7721, 'f1_score': 0.7321}
Random Forest: {'accuracy': 0.8573, 'precision': 0.6779, 'recall': 0.7661, 'f1_score': 0.7193}
Decision Tree: {'accuracy': 0.8196, 'precision': 0.5934, 'recall': 0.7754, 'f1_score': 0.6723}
SVM: {'accuracy': 0.707, 'precision': 0.4421, 'recall': 0.8707, 'f1_score': 0.5864}

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['text']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine', 'Release_Year', 'Release_Month', 'Release_Day']
====================================

