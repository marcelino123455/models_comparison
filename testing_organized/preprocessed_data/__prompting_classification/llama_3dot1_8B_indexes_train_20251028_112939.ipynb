{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353be05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:29:42.752818Z",
     "iopub.status.busy": "2025-10-28T16:29:42.752672Z",
     "iopub.status.idle": "2025-10-28T16:30:24.103695Z",
     "shell.execute_reply": "2025-10-28T16:30:24.103179Z"
    },
    "papermill": {
     "duration": 41.359728,
     "end_time": "2025-10-28T16:30:24.104879",
     "exception": false,
     "start_time": "2025-10-28T16:29:42.745151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:30:12.643762: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import os \n",
    "from datetime import datetime\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fa8697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:30:24.118875Z",
     "iopub.status.busy": "2025-10-28T16:30:24.118002Z",
     "iopub.status.idle": "2025-10-28T16:30:24.123070Z",
     "shell.execute_reply": "2025-10-28T16:30:24.122739Z"
    },
    "papermill": {
     "duration": 0.012571,
     "end_time": "2025-10-28T16:30:24.123889",
     "exception": false,
     "start_time": "2025-10-28T16:30:24.111318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "path_DATA = \"../../../data\"\n",
    "csv_path = f\"{path_DATA}/spotify_dataset_sin_duplicados_4.csv\"\n",
    "\n",
    "# To compare with  tfidf\n",
    "zero_shot_path = f\"{path_DATA}/zero_outputs\"\n",
    "os.makedirs(zero_shot_path, exist_ok=True)\n",
    "\n",
    "\n",
    "TESTING = False\n",
    "\n",
    "if TESTING:\n",
    "    NROWS = 200\n",
    "else:\n",
    "    NROWS = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bca28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:30:24.137396Z",
     "iopub.status.busy": "2025-10-28T16:30:24.137115Z",
     "iopub.status.idle": "2025-10-28T16:30:24.141494Z",
     "shell.execute_reply": "2025-10-28T16:30:24.141138Z"
    },
    "papermill": {
     "duration": 0.01183,
     "end_time": "2025-10-28T16:30:24.142290",
     "exception": false,
     "start_time": "2025-10-28T16:30:24.130460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_array(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        array_ = json.load(f)  \n",
    "    return array_\n",
    "\n",
    "def get_song_and_target(csv_path, faltantes_path = \"faltantes_according_token.json\", sample_size=None, path_test_indexes=None):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    indices_to_remove = get_array(faltantes_path)\n",
    "    if indices_to_remove[-1]>df.shape[0]:\n",
    "        print(\"You are executing in testing way\")\n",
    "    else:\n",
    "        df = df.drop(indices_to_remove).reset_index(drop=True)\n",
    "    df['original_index'] = df.index # Indices correctos despues de la eliminaci√≥n\n",
    "\n",
    "    if path_test_indexes is not None:\n",
    "        df_split_indices_test = pd.read_csv(path_test_indexes)\n",
    "        idx_test = df_split_indices_test[\"train_index\"].values\n",
    "        df = df.iloc[idx_test].reset_index(drop=True)\n",
    "\n",
    "    if sample_size is not None:\n",
    "        df = df.iloc[:sample_size].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    X = df['text']\n",
    "    df['Explicit_binary'] = (df['Explicit'].str.lower() == 'yes').astype(int)\n",
    "    y = df['Explicit_binary']\n",
    "    return X, y, df['original_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6bfb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:30:24.158058Z",
     "iopub.status.busy": "2025-10-28T16:30:24.157892Z",
     "iopub.status.idle": "2025-10-28T16:30:26.670904Z",
     "shell.execute_reply": "2025-10-28T16:30:26.670492Z"
    },
    "papermill": {
     "duration": 2.523427,
     "end_time": "2025-10-28T16:30:26.671770",
     "exception": false,
     "start_time": "2025-10-28T16:30:24.148343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86500,)\n",
      "(86500,)\n",
      "(86500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Indices train and test, in this experimentations only is relevante test indexes\n",
    "df_split_indices = pd.read_csv(f\"{zero_shot_path}/split_indices_train.csv\")\n",
    "df_split_indices_test = pd.read_csv(f\"{zero_shot_path}/split_indices_test.csv\")\n",
    "\n",
    "X,y, index = get_song_and_target(csv_path,\"faltantes_according_token.json\", sample_size=NROWS, path_test_indexes=f\"{zero_shot_path}/split_indices_train.csv\")\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(index.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e612849",
   "metadata": {
    "id": "5N-2vq2m_xbw",
    "papermill": {
     "duration": 0.006165,
     "end_time": "2025-10-28T16:30:26.685160",
     "exception": false,
     "start_time": "2025-10-28T16:30:26.678995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# meta-llama/Llama-3.1-8B-Instruct\n",
    "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b07b33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:30:26.699157Z",
     "iopub.status.busy": "2025-10-28T16:30:26.698875Z",
     "iopub.status.idle": "2025-10-28T16:34:03.014939Z",
     "shell.execute_reply": "2025-10-28T16:34:03.014277Z"
    },
    "papermill": {
     "duration": 216.324992,
     "end_time": "2025-10-28T16:34:03.016620",
     "exception": false,
     "start_time": "2025-10-28T16:30:26.691628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c53f7230>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 746931a9-c4f6-4d96-ac5b-17465b580ef9)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c54839d0>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 3e8c67c8-3408-44d2-9508-74417f33f4a3)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c5482210>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 5b0ddd37-80e1-4c91-8bbd-e1bed7bc34cb)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c54802d0>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: b9d2b89c-15a6-4966-91bd-613f2571adf9)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b4550>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: b214ae4f-91b2-4a8d-9138-41aa0992e6a4)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 5/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b4a50>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 3c731c03-cb03-47dc-8805-07fed435ec2a)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163a824752af45d99851cca8adcd9a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b5090>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 3f36e012-231e-4997-83be-0679fb80ce0a)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b5310>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: aa5eecb4-190c-45b5-9280-410901cc1b96)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b56d0>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 0f56221a-f6a2-42e1-b6b4-b9527a3034ee)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b5a90>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: a4cd192d-0a90-4e6a-8e31-31baa2d00cd5)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b5e50>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 42e7f8b0-c1c4-47dc-bb0b-a383ba42633b)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 5/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b6210>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 1a7772f5-079f-4a82-bad1-2b9fdd1811d4)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b6c10>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 25bec821-9e94-4c3c-af19-13b8a5a1edf4)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b6fd0>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: be9becae-39c2-4d97-adce-91fc1483c988)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b7390>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 7e008930-4fe5-400c-8bdf-911500782290)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b7750>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: a7958d5a-e5be-46bd-ab05-63039f993e6d)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c15b7b10>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: bfd3b846-32d0-415e-96d5-07b0686bb4ad)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying in 8s [Retry 5/5].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f99c2f60b90>: Failed to resolve \\'huggingface.co\\' ([Errno -2] Name or service not known)\"))'), '(Request ID: 615dbfb6-553e-4bbf-ac3b-f7b1ba960f27)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/resolve/main/custom_generate/generate.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'Non-Explicit. The lyrics of this song appear to be melancholic and nostalgic, focusing on lost childhood memories, souvenirs, and the pain of remembering past loves. There is no language or content that is considered explicit, such as strong profanity, graphic violence, or mature themes. The tone is more introspective and sentimental.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=128001\n",
    "    # pad_token_id` to `eos_token_id`:128001\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a expert detecting if a song is explicit or not based on its lyrics. Answer with 'Explicit' or 'Non-Explicit'.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"song lyric: {X.iloc[1]} Is this song explicit or non-explicit?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217e9841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:34:03.034186Z",
     "iopub.status.busy": "2025-10-28T16:34:03.033899Z",
     "iopub.status.idle": "2025-10-28T16:34:03.037017Z",
     "shell.execute_reply": "2025-10-28T16:34:03.036676Z"
    },
    "papermill": {
     "duration": 0.013002,
     "end_time": "2025-10-28T16:34:03.038239",
     "exception": false,
     "start_time": "2025-10-28T16:34:03.025237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (86500,)\n",
      "y_test shape: (86500,)\n",
      "index: (86500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"index:\", index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff908fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T16:34:03.054601Z",
     "iopub.status.busy": "2025-10-28T16:34:03.054453Z",
     "iopub.status.idle": "2025-10-28T23:14:39.352210Z",
     "shell.execute_reply": "2025-10-28T23:14:39.351747Z"
    },
    "papermill": {
     "duration": 24036.319783,
     "end_time": "2025-10-28T23:14:39.365768",
     "exception": false,
     "start_time": "2025-10-28T16:34:03.045985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_scores length: 86500\n",
      "y_indexes length: 86500\n",
      "Accuracy en test: 0.81700578\n",
      "Precision en test: 0.58720719\n",
      "Recall en test: 0.78463104\n",
      "F1 en test: 0.67171330\n",
      "Resultados guardados en resultados_train_llama_8B.json\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "\n",
    "i_tested = 0\n",
    "\n",
    "answers_debug = []\n",
    "sons_debug = []\n",
    "for lyric in X_test:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert detecting if a song is explicit or not based on its lyrics. Answer ONLY with one word: 'Explicit' or 'Non-Explicit'.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"song lyric: {lyric}\"},\n",
    "    ]\n",
    "    output = pipeline(messages, max_new_tokens=64)\n",
    "    # print()\n",
    "    # answer = output[0][\"generated_text\"].strip().split()[-1]\n",
    "    answer = output[0][\"generated_text\"][-1]['content']\n",
    "    if TESTING:\n",
    "        answers_debug.append(answer)\n",
    "        sons_debug.append(lyric)\n",
    "    score_explicit = 1 if answer.lower() == \"explicit\" else 0\n",
    "    test_scores.append(score_explicit)\n",
    "    i_tested += 1\n",
    "\n",
    "    if i_tested == NROWS and TESTING:\n",
    "        break\n",
    "\n",
    "test_scores = np.array(test_scores)\n",
    "\n",
    "# M√©tricas\n",
    "f1_test = f1_score(y_test, test_scores)\n",
    "accuracy_test = accuracy_score(y_test, test_scores)\n",
    "precision_test = precision_score(y_test, test_scores)\n",
    "recall_test = recall_score(y_test, test_scores)\n",
    "\n",
    "print(\"test_scores length:\", len(test_scores))\n",
    "print(\"y_indexes length:\", len(index))\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    \"original_index\": index,\n",
    "    \"explicit_score\": test_scores\n",
    "})\n",
    "df_results.to_csv(f\"{zero_shot_path}/llama_8B_results.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"Accuracy en test: {accuracy_test:.8f}\")\n",
    "print(f\"Precision en test: {precision_test:.8f}\")\n",
    "print(f\"Recall en test: {recall_test:.8f}\")\n",
    "print(f\"F1 en test: {f1_test:.8f}\")\n",
    "\n",
    "\n",
    "resultados = {\n",
    "    \"accuracy\": float(f\"{accuracy_test:.8f}\"),\n",
    "    \"precision\": float(f\"{precision_test:.8f}\"),\n",
    "    \"recall\": float(f\"{recall_test:.8f}\"),\n",
    "    \"f1\": float(f\"{f1_test:.8f}\")\n",
    "}\n",
    "\n",
    "if TESTING:\n",
    "    test_ou = \"test\"\n",
    "else:\n",
    "    test_ou = \"\"\n",
    "\n",
    "ruta_resultados = f\"resultados_train_llama_8B{test_ou}.json\"\n",
    "with open(ruta_resultados, \"w\") as f:\n",
    "    json.dump(resultados, f, indent=4)\n",
    "\n",
    "print(f\"Resultados guardados en {ruta_resultados}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357f3125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T23:14:39.383832Z",
     "iopub.status.busy": "2025-10-28T23:14:39.383664Z",
     "iopub.status.idle": "2025-10-28T23:14:39.386522Z",
     "shell.execute_reply": "2025-10-28T23:14:39.386168Z"
    },
    "papermill": {
     "duration": 0.012661,
     "end_time": "2025-10-28T23:14:39.387378",
     "exception": false,
     "start_time": "2025-10-28T23:14:39.374717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    import textwrap\n",
    "    print(\"Answers debug:\", answers_debug)\n",
    "    print(\"test_scores:\", test_scores)\n",
    "    print(\"y true     :\", y_test.values)\n",
    "\n",
    "    print(\"song 7:\", sons_debug[7])\n",
    "    wrapped_song = textwrap.fill(sons_debug[7], width=80)\n",
    "    print(\"song 7:\")\n",
    "    print(wrapped_song)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24302.587502,
   "end_time": "2025-10-28T23:14:43.054137",
   "environment_variables": {},
   "exception": null,
   "input_path": "llama_3dot1_8B_indexes_train.ipynb",
   "output_path": "llama_3dot1_8B_indexes_train_20251028_112939.ipynb",
   "parameters": {},
   "start_time": "2025-10-28T16:29:40.466635",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "163a824752af45d99851cca8adcd9a4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b60c896f6d134d7c81163f9252fb4903",
        "IPY_MODEL_f9598d8ab88d4e4fa3601f5f6cc2410b",
        "IPY_MODEL_ca982367cd0147ca84343083eb7b9c21"
       ],
       "layout": "IPY_MODEL_dde2873069354b93977b8b0c89d9edf7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2c66f248950e4a34bd9c49e98e328c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fa49ea52fa54bb39b5a38165d81670d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ef3374d37574cf1aba840100b6fbe93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ffe23060e30458688ce60fdda10bfd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7346094b081849b0a2cd8b9f8c51efa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab1a2c7bd43344fc85ad52308ed14e80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b60c896f6d134d7c81163f9252fb4903": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2c66f248950e4a34bd9c49e98e328c41",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4ffe23060e30458688ce60fdda10bfd6",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
      }
     },
     "ca982367cd0147ca84343083eb7b9c21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2fa49ea52fa54bb39b5a38165d81670d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ab1a2c7bd43344fc85ad52308ed14e80",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá4/4‚Äá[02:18&lt;00:00,‚Äá29.81s/it]"
      }
     },
     "dde2873069354b93977b8b0c89d9edf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9598d8ab88d4e4fa3601f5f6cc2410b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ef3374d37574cf1aba840100b6fbe93",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7346094b081849b0a2cd8b9f8c51efa5",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}