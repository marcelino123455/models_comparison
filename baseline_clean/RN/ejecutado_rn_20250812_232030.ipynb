{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0366ea",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62017b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T04:20:32.864229Z",
     "iopub.status.busy": "2025-08-13T04:20:32.864064Z",
     "iopub.status.idle": "2025-08-13T04:20:40.830682Z",
     "shell.execute_reply": "2025-08-13T04:20:40.829908Z"
    },
    "papermill": {
     "duration": 7.972303,
     "end_time": "2025-08-13T04:20:40.831861",
     "exception": false,
     "start_time": "2025-08-13T04:20:32.859558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelino.maita/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import papermill\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faa5861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T04:20:40.840516Z",
     "iopub.status.busy": "2025-08-13T04:20:40.839832Z",
     "iopub.status.idle": "2025-08-13T04:20:40.844216Z",
     "shell.execute_reply": "2025-08-13T04:20:40.843679Z"
    },
    "papermill": {
     "duration": 0.009351,
     "end_time": "2025-08-13T04:20:40.845093",
     "exception": false,
     "start_time": "2025-08-13T04:20:40.835742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(papermill.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32eb027",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4775409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T04:20:40.852621Z",
     "iopub.status.busy": "2025-08-13T04:20:40.851974Z",
     "iopub.status.idle": "2025-08-13T04:20:41.131067Z",
     "shell.execute_reply": "2025-08-13T04:20:41.130039Z"
    },
    "papermill": {
     "duration": 0.283292,
     "end_time": "2025-08-13T04:20:41.131655",
     "exception": true,
     "start_time": "2025-08-13T04:20:40.848363",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/embbedings_khipu/lb_khipu_A.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Para hacer pruebitas y luego mandarlo como sbatch\u001b[39;00m\n\u001b[32m      6\u001b[39m TESTING = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m _EMBEDDINGS = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_lb_embb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TESTING:\n\u001b[32m     10\u001b[39m     _NROWS = \u001b[32m1000\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:451\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    449\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/embbedings_khipu/lb_khipu_A.npy'"
     ]
    }
   ],
   "source": [
    "DATA_PATH =\"../data\"\n",
    "path_lb_embb = os.path.join(DATA_PATH, \"embbedings_khipu/lb_khipu_A.npy\")\n",
    "path_dataset = os.path.join(DATA_PATH, \"spotify_dataset_sin_duplicados_4.csv\")\n",
    "\n",
    "# Para hacer pruebitas y luego mandarlo como sbatch\n",
    "TESTING = True\n",
    "_EMBEDDINGS = np.load(path_lb_embb)\n",
    "\n",
    "if TESTING:\n",
    "    _NROWS = 1000\n",
    "    _EMBEDDINGS = _EMBEDDINGS[:1000]\n",
    "    _EPHOCS = 1000\n",
    "else:\n",
    "    _NROWS = None\n",
    "    _EPHOCS = 10000\n",
    "    \n",
    "\n",
    "df = pd.read_csv(path_dataset, nrows = _NROWS)\n",
    "df['Explicit_binary'] = df['Explicit'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "X = _EMBEDDINGS\n",
    "\n",
    "y = df['Explicit_binary']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42 \n",
    ")\n",
    "\n",
    "y_train = y_train.values.reshape(-1, 1).astype(np.float32)\n",
    "y_test = y_test.values.reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "\n",
    "def seeRam():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"RAM usada (MB): {process.memory_info().rss / (1024 * 1024):.2f}\")\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "seeRam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890be7e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE HERE for backward pass\n",
    "\n",
    "# f0, f1, f2\n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W = np.random.randn(in_dim, out_dim) * np.sqrt(2.0 / in_dim)\n",
    "        self.b = np.zeros((1, out_dim))\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x @ self.W + self.b\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.grad_W = self.x.T @ grad_output\n",
    "        self.grad_b = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        return grad_output @ self.W.T\n",
    "\n",
    "# h0, h1, h2, ....\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.mask = x > 0\n",
    "        return x * self.mask\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask\n",
    "\n",
    "class Sigmoid:\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.out * (1 - self.out)\n",
    "\n",
    "# error\n",
    "class MSELoss:\n",
    "    def forward(self, pred, target):\n",
    "        self.diff = pred - target\n",
    "        return np.mean(self.diff ** 2)\n",
    "    def backward(self):\n",
    "        return 2.0 * self.diff / self.diff.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea177d6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, dims):\n",
    "        self.layers = []\n",
    "        for i in range(len(dims)-2):\n",
    "            self.layers.append(Linear(dims[i], dims[i+1])) #fi\n",
    "            self.layers.append(ReLU()) # hi\n",
    "\n",
    "        self.layers.append(Linear(dims[-2], dims[-1]))\n",
    "\n",
    "    # CODE HERE (forward, backward pass)\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for l in reversed(self.layers):\n",
    "            grad = l.backward(grad)\n",
    "\n",
    "    @property\n",
    "    def n_params(self):\n",
    "        total = 0\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, Linear):\n",
    "                total += l.W.size + l.b.size\n",
    "        return total\n",
    "\n",
    "    def train(self, X, y, lr=0.1, epochs=10000, print_every=100):\n",
    "      loss_fn = MSELoss()\n",
    "      history = []\n",
    "      for epoch in range(epochs):\n",
    "          #forward\n",
    "          pred = self.forward(X)\n",
    "          loss = loss_fn.forward(pred, y)\n",
    "          #backward\n",
    "          grad = loss_fn.backward()\n",
    "          self.backward(grad)\n",
    "\n",
    "          # Descenso de la gradiente\n",
    "          for layer in self.layers:\n",
    "              if isinstance(layer, Linear):\n",
    "                  layer.W -= lr * layer.grad_W\n",
    "                  layer.b -= lr * layer.grad_b\n",
    "          history.append(loss)\n",
    "          if epoch % print_every == 0:\n",
    "              print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
    "      return history\n",
    "\n",
    "    def train_batches(self, X, y, lr=0.1, epochs=10000, batch_size=32, print_every=100):\n",
    "        loss_fn = MSELoss()\n",
    "        history = []\n",
    "\n",
    "        n = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            # Barajamos los datos al inicio de cada época\n",
    "            perm = np.random.permutation(n)\n",
    "            X_shuffled = X[perm]\n",
    "            y_shuffled = y[perm]\n",
    "\n",
    "            for i in range(0, n, batch_size):\n",
    "                xb = X_shuffled[i:i+batch_size]\n",
    "                yb = y_shuffled[i:i+batch_size]\n",
    "\n",
    "                # Forward\n",
    "                pred = self.forward(xb)\n",
    "                loss = loss_fn.forward(pred, yb)\n",
    "\n",
    "                # Backward\n",
    "                grad = loss_fn.backward()\n",
    "                self.backward(grad)\n",
    "\n",
    "                # Actualización\n",
    "                for layer in self.layers:\n",
    "                    if isinstance(layer, Linear):\n",
    "                        layer.W -= lr * layer.grad_W\n",
    "                        layer.b -= lr * layer.grad_b\n",
    "\n",
    "            pred_full = self.forward(X)\n",
    "            epoch_loss = loss_fn.forward(pred_full, y)\n",
    "            history.append(epoch_loss)\n",
    "\n",
    "            if epoch % print_every == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0bd1c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "# y_train = Y.values.reshape(-1, 1).astype(np.float32) \n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107320ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLP([300, 32,32, 1])\n",
    "history= mlp.train(X_train, y_train, lr=0.5, epochs=_EPHOCS, print_every=1000)\n",
    "print('Parámetros totales:', mlp.n_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43e8cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perdida\n",
    "plt.figure()\n",
    "plt.plot(history)\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Evolución de la pérdida (XOR)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8a644",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pasando test a la red\n",
    "pred_test = mlp.forward(X_test)\n",
    "\n",
    "# Se hace la predicción\n",
    "pred_labels = (pred_test >= 0.5).astype(int).flatten()\n",
    "y_test_true = y_test.flatten()\n",
    "\n",
    "# Calcular Accuracy y Reporte\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"Accuracy en Test: {accuracy_score(y_test_true, pred_labels):.4f}\")\n",
    "print(classification_report(y_test_true, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc1450",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_true, pred_labels)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Explicit', 'Explicit'], yticklabels=['Not Explicit', 'Explicit'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.168792,
   "end_time": "2025-08-13T04:20:42.352662",
   "environment_variables": {},
   "exception": true,
   "input_path": "rn.ipynb",
   "output_path": "ejecutado_rn_20250812_232030.ipynb",
   "parameters": {},
   "start_time": "2025-08-13T04:20:31.183870",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}