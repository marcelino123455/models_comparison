2025-09-19 02:57:52.639829: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-19 02:57:52.704166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-19 02:57:55.241495: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_3.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'Artist(s)', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
After removing some columns that doesn't love me, for TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
After removing some columns that doesn't love me, for numeric cols you are selecteing this columns:
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 5020)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 5020)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [5020, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4553, Test Loss: 0.4313, F1: 0.8180, AUC: 0.8995
Epoch [10/30] Train Loss: 0.2216, Test Loss: 0.3717, F1: 0.8292, AUC: 0.9504
Epoch [20/30] Train Loss: 0.1778, Test Loss: 0.3103, F1: 0.8715, AUC: 0.9511
Mejores resultados en la época:  26
f1-score 0.8808139534883721
AUC según el mejor F1-score 0.95469034031158

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4720, Test Loss: 0.4400, F1: 0.7654, AUC: 0.8974
Epoch [10/30] Train Loss: 0.2319, Test Loss: 0.2622, F1: 0.8888, AUC: 0.9583
Epoch [20/30] Train Loss: 0.1840, Test Loss: 0.3071, F1: 0.8700, AUC: 0.9607
Mejores resultados en la época:  29
f1-score 0.893320518981259
AUC según el mejor F1-score 0.9603815266134847

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4656, Test Loss: 0.4076, F1: 0.8199, AUC: 0.8981
Epoch [10/30] Train Loss: 0.2253, Test Loss: 0.2756, F1: 0.8835, AUC: 0.9552
Epoch [20/30] Train Loss: 0.1915, Test Loss: 0.2746, F1: 0.8846, AUC: 0.9565
Mejores resultados en la época:  29
f1-score 0.8863772995070338
AUC según el mejor F1-score 0.9560502568486721

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4651, Test Loss: 0.4115, F1: 0.8169, AUC: 0.8953
Epoch [10/30] Train Loss: 0.2240, Test Loss: 0.2728, F1: 0.8824, AUC: 0.9546
Epoch [20/30] Train Loss: 0.1881, Test Loss: 0.2882, F1: 0.8789, AUC: 0.9556
Mejores resultados en la época:  27
f1-score 0.8828405295063714
AUC según el mejor F1-score 0.9555431956411081

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4729, Test Loss: 0.4167, F1: 0.8113, AUC: 0.8922
Epoch [10/30] Train Loss: 0.2278, Test Loss: 0.2795, F1: 0.8844, AUC: 0.9534
Epoch [20/30] Train Loss: 0.1898, Test Loss: 0.2830, F1: 0.8845, AUC: 0.9558
Mejores resultados en la época:  27
f1-score 0.8886218911450198
AUC según el mejor F1-score 0.9562058118873066
Epoch [0/30] Train Loss: 0.4563, Test Loss: 0.3355, F1: 0.7193, AUC: 0.9075
Epoch [10/30] Train Loss: 0.2302, Test Loss: 0.2133, F1: 0.8146, AUC: 0.9574
Epoch [20/30] Train Loss: 0.1869, Test Loss: 0.2679, F1: 0.7923, AUC: 0.9580
Mejores resultados en la época:  24
f1-score 0.8243868807249088
AUC según el mejor F1-score 0.9611859311624141
Confusion matrix Test saved: outputs_without_artist/3/tfidf/cm_mlp_1.png

========================================
Entrenando red 6 con capas [5020, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4629, Test Loss: 0.4205, F1: 0.7888, AUC: 0.9042
Epoch [10/30] Train Loss: 0.2095, Test Loss: 0.5313, F1: 0.7928, AUC: 0.9507
Epoch [20/30] Train Loss: 0.1405, Test Loss: 0.3564, F1: 0.8767, AUC: 0.9535
Mejores resultados en la época:  26
f1-score 0.8920915586774858
AUC según el mejor F1-score 0.9594826618930653

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4566, Test Loss: 0.4359, F1: 0.7764, AUC: 0.9199
Epoch [10/30] Train Loss: 0.2225, Test Loss: 0.2735, F1: 0.8852, AUC: 0.9583
Epoch [20/30] Train Loss: 0.1420, Test Loss: 0.3168, F1: 0.8865, AUC: 0.9594
Mejores resultados en la época:  18
f1-score 0.9009924957637376
AUC según el mejor F1-score 0.9657629487692296

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4597, Test Loss: 0.3883, F1: 0.8335, AUC: 0.9164
Epoch [10/30] Train Loss: 0.2156, Test Loss: 0.2811, F1: 0.8798, AUC: 0.9556
Epoch [20/30] Train Loss: 0.1403, Test Loss: 0.3376, F1: 0.8723, AUC: 0.9567
Mejores resultados en la época:  21
f1-score 0.8942687747035574
AUC según el mejor F1-score 0.9612192131351031

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4595, Test Loss: 0.4074, F1: 0.8285, AUC: 0.9175
Epoch [10/30] Train Loss: 0.2104, Test Loss: 0.2892, F1: 0.8847, AUC: 0.9572
Epoch [20/30] Train Loss: 0.1533, Test Loss: 0.3259, F1: 0.8735, AUC: 0.9526
Mejores resultados en la época:  22
f1-score 0.8948643410852714
AUC según el mejor F1-score 0.9610678836946333

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4675, Test Loss: 0.4614, F1: 0.7491, AUC: 0.9010
Epoch [10/30] Train Loss: 0.2098, Test Loss: 0.2964, F1: 0.8804, AUC: 0.9580
Epoch [20/30] Train Loss: 0.1382, Test Loss: 0.2811, F1: 0.8901, AUC: 0.9614
Mejores resultados en la época:  26
f1-score 0.8939959090362171
AUC según el mejor F1-score 0.9607343010107384
Epoch [0/30] Train Loss: 0.4477, Test Loss: 0.2796, F1: 0.7522, AUC: 0.9251
Epoch [10/30] Train Loss: 0.2104, Test Loss: 0.2380, F1: 0.8097, AUC: 0.9604
Epoch [20/30] Train Loss: 0.1458, Test Loss: 0.3232, F1: 0.7719, AUC: 0.9603
Mejores resultados en la época:  28
f1-score 0.8236392493698067
AUC según el mejor F1-score 0.9627640084558037
Confusion matrix Test saved: outputs_without_artist/3/tfidf/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}}}
Saved on: outputs_without_artist/3/tfidf

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021}
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:43:57] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:46:45] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:49:31] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:52:18] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:55:05] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:58:00] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 45, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/3/tfidf/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 45, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.68      0.78     16465
           1       0.43      0.78      0.56      5160

    accuracy                           0.70     21625
   macro avg       0.67      0.73      0.67     21625
weighted avg       0.79      0.70      0.72     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/3/tfidf/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 45, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.88      0.90     16465
           1       0.66      0.78      0.72      5160

    accuracy                           0.85     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.87      0.85      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/3/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 45, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.86      0.89     16465
           1       0.64      0.76      0.69      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.81      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/3/tfidf/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 45, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.85      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.86     21625
weighted avg       0.90      0.90      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/3/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058}
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     16465
           1       0.68      0.81      0.74      5160

    accuracy                           0.87     21625
   macro avg       0.81      0.85      0.83     21625
weighted avg       0.88      0.87      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/3/tfidf/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/3/tfidf/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}
Logistic Regression: {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}
Naive Bayes: {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}
Decision Tree: {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_3.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
Random Forest: {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}
SVM: {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}, 'Logistic Regression': {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}, 'SVM': {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}, 'Decision Tree': {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}, 'Random Forest': {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}, 'XGBoost': {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}, 'Naive Bayes': {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}}}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 320)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 320)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [320, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4516, Test Loss: 0.4074, F1: 0.8220, AUC: 0.8957
Epoch [10/30] Train Loss: 0.3198, Test Loss: 0.3510, F1: 0.8515, AUC: 0.9254
Epoch [20/30] Train Loss: 0.2943, Test Loss: 0.3676, F1: 0.8306, AUC: 0.9317
Mejores resultados en la época:  26
f1-score 0.8608936528965434
AUC según el mejor F1-score 0.9337762576242413

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4433, Test Loss: 0.4403, F1: 0.8192, AUC: 0.9065
Epoch [10/30] Train Loss: 0.3336, Test Loss: 0.3222, F1: 0.8645, AUC: 0.9357
Epoch [20/30] Train Loss: 0.3004, Test Loss: 0.3080, F1: 0.8709, AUC: 0.9420
Mejores resultados en la época:  28
f1-score 0.8752986144290492
AUC según el mejor F1-score 0.9456746397264288

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.5097, Test Loss: 0.4280, F1: 0.8183, AUC: 0.8998
Epoch [10/30] Train Loss: 0.3293, Test Loss: 0.3464, F1: 0.8520, AUC: 0.9335
Epoch [20/30] Train Loss: 0.3046, Test Loss: 0.3198, F1: 0.8586, AUC: 0.9387
Mejores resultados en la época:  28
f1-score 0.8652605459057072
AUC según el mejor F1-score 0.9404985239769243

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4520, Test Loss: 0.4133, F1: 0.8257, AUC: 0.9035
Epoch [10/30] Train Loss: 0.3196, Test Loss: 0.3246, F1: 0.8631, AUC: 0.9366
Epoch [20/30] Train Loss: 0.2912, Test Loss: 0.3114, F1: 0.8677, AUC: 0.9406
Mejores resultados en la época:  18
f1-score 0.8708157099697885
AUC según el mejor F1-score 0.9402756098523056

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4643, Test Loss: 0.4028, F1: 0.8296, AUC: 0.8997
Epoch [10/30] Train Loss: 0.3164, Test Loss: 0.3406, F1: 0.8572, AUC: 0.9330
Epoch [20/30] Train Loss: 0.2906, Test Loss: 0.3210, F1: 0.8539, AUC: 0.9396
Mejores resultados en la época:  24
f1-score 0.868486944080124
AUC según el mejor F1-score 0.9410585870510515
Epoch [0/30] Train Loss: 0.4464, Test Loss: 0.4114, F1: 0.6972, AUC: 0.9044
Epoch [10/30] Train Loss: 0.3201, Test Loss: 0.2906, F1: 0.7708, AUC: 0.9350
Epoch [20/30] Train Loss: 0.2891, Test Loss: 0.3248, F1: 0.7505, AUC: 0.9401
Mejores resultados en la época:  24
f1-score 0.7850184432043885
AUC según el mejor F1-score 0.9414173652356302
Confusion matrix Test saved: outputs_without_artist/3/lyrics_bert/cm_mlp_1.png

========================================
Entrenando red 6 con capas [320, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4379, Test Loss: 0.4178, F1: 0.7905, AUC: 0.9004
Epoch [10/30] Train Loss: 0.2871, Test Loss: 0.3278, F1: 0.8587, AUC: 0.9357
Epoch [20/30] Train Loss: 0.2376, Test Loss: 0.3376, F1: 0.8679, AUC: 0.9415
Mejores resultados en la época:  25
f1-score 0.8723119912525817
AUC según el mejor F1-score 0.9435145945067906

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4466, Test Loss: 0.3710, F1: 0.8407, AUC: 0.9147
Epoch [10/30] Train Loss: 0.2982, Test Loss: 0.3476, F1: 0.8565, AUC: 0.9351
Epoch [20/30] Train Loss: 0.2432, Test Loss: 0.3022, F1: 0.8632, AUC: 0.9455
Mejores resultados en la época:  27
f1-score 0.8861788617886179
AUC según el mejor F1-score 0.9509346737726099

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4426, Test Loss: 0.3937, F1: 0.8309, AUC: 0.9096
Epoch [10/30] Train Loss: 0.2959, Test Loss: 0.3133, F1: 0.8619, AUC: 0.9404
Epoch [20/30] Train Loss: 0.2380, Test Loss: 0.3253, F1: 0.8747, AUC: 0.9473
Mejores resultados en la época:  26
f1-score 0.8795240456122955
AUC según el mejor F1-score 0.9536326763528334

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4442, Test Loss: 0.3925, F1: 0.8295, AUC: 0.9097
Epoch [10/30] Train Loss: 0.2936, Test Loss: 0.3061, F1: 0.8648, AUC: 0.9432
Epoch [20/30] Train Loss: 0.2379, Test Loss: 0.3175, F1: 0.8606, AUC: 0.9436
Mejores resultados en la época:  25
f1-score 0.8797131907528742
AUC según el mejor F1-score 0.9504317145739065

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4453, Test Loss: 0.3891, F1: 0.8308, AUC: 0.9072
Epoch [10/30] Train Loss: 0.2906, Test Loss: 0.3151, F1: 0.8656, AUC: 0.9402
Epoch [20/30] Train Loss: 0.2402, Test Loss: 0.3161, F1: 0.8719, AUC: 0.9456
Mejores resultados en la época:  27
f1-score 0.8777603475322795
AUC según el mejor F1-score 0.9494167615231891
Epoch [0/30] Train Loss: 0.4359, Test Loss: 0.4446, F1: 0.6697, AUC: 0.9113
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
Epoch [10/30] Train Loss: 0.2861, Test Loss: 0.2645, F1: 0.7845, AUC: 0.9431
Epoch [20/30] Train Loss: 0.2373, Test Loss: 0.3395, F1: 0.7757, AUC: 0.9514
Mejores resultados en la época:  22
f1-score 0.8031345565749235
AUC según el mejor F1-score 0.9502713413701134
Confusion matrix Test saved: outputs_without_artist/3/lyrics_bert/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}, 'Logistic Regression': {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}, 'SVM': {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}, 'Decision Tree': {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}, 'Random Forest': {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}, 'XGBoost': {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}, 'Naive Bayes': {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0045, 'precision_cv_mean': 0.866, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8707, 'recall_cv_std': 0.015, 'f1_cv_mean': 0.8682, 'f1_cv_std': 0.0049, 'params': 10305, 'accuracy_test': 0.8949, 'precision_test': 0.7667, 'recall_test': 0.8043, 'f1_score_test': 0.785}, 'MLP_1028097': {'accuracy_cv_mean': 0.8798, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8846, 'precision_cv_std': 0.012, 'recall_cv_mean': 0.874, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8791, 'f1_cv_std': 0.0044, 'params': 1028097, 'accuracy_test': 0.9047, 'precision_test': 0.7922, 'recall_test': 0.8143, 'f1_score_test': 0.8031}}}
Saved on: outputs_without_artist/3/lyrics_bert

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 45, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.87      0.90     16465
           1       0.66      0.82      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.87      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 45, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.85      0.54      0.66     16465
           1       0.32      0.68      0.43      5160

    accuracy                           0.57     21625
   macro avg       0.58      0.61      0.55     21625
weighted avg       0.72      0.57      0.61     21625

Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 45, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.84      0.87     16465
           1       0.59      0.75      0.66      5160

    accuracy                           0.81     21625
   macro avg       0.75      0.79      0.76     21625
weighted avg       0.84      0.81      0.82     21625

Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 45, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.90      0.92     16465
           1       0.72      0.80      0.76      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:08] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:39] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:11] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:43] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:26:14] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:26:46] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 45, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.74      0.85      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7807, 'f1_cv_std': 0.0044}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.75      0.83     16465
           1       0.50      0.81      0.62      5160

    accuracy                           0.76     21625
   macro avg       0.71      0.78      0.72     21625
weighted avg       0.82      0.76      0.78     21625

Confusion matrix Test saved as: outputs_without_artist/3/lyrics_bert/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/3/lyrics_bert/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8915, 'precision_test': 0.737, 'recall_test': 0.8477, 'f1_score_test': 0.7885}
Random Forest: {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8763, 'precision_test': 0.7154, 'recall_test': 0.7994, 'f1_score_test': 0.7551}
Logistic Regression: {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8581, 'precision_test': 0.6628, 'recall_test': 0.825, 'f1_score_test': 0.735}
Decision Tree: {'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8141, 'precision_test': 0.587, 'recall_test': 0.7452, 'f1_score_test': 0.6567}
Naive Bayes: {'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7807, 'f1_cv_std': 0.0044, 'accuracy_test': 0.7612, 'precision_test': 0.4998, 'recall_test': 0.8072, 'f1_score_test': 0.6174}
SVM: {'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222, 'accuracy_test': 0.5749, 'precision_test': 0.3183, 'recall_test': 0.6843, 'f1_score_test': 0.4345}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}, 'Logistic Regression': {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}, 'SVM': {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}, 'Decision Tree': {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}, 'Random Forest': {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}, 'XGBoost': {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}, 'Naive Bayes': {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0045, 'precision_cv_mean': 0.866, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8707, 'recall_cv_std': 0.015, 'f1_cv_mean': 0.8682, 'f1_cv_std': 0.0049, 'params': 10305, 'accuracy_test': 0.8949, 'precision_test': 0.7667, 'recall_test': 0.8043, 'f1_score_test': 0.785}, 'MLP_1028097': {'accuracy_cv_mean': 0.8798, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8846, 'precision_cv_std': 0.012, 'recall_cv_mean': 0.874, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8791, 'f1_cv_std': 0.0044, 'params': 1028097, 'accuracy_test': 0.9047, 'precision_test': 0.7922, 'recall_test': 0.8143, 'f1_score_test': 0.8031}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8581, 'precision_test': 0.6628, 'recall_test': 0.825, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222, 'accuracy_test': 0.5749, 'precision_test': 0.3183, 'recall_test': 0.6843, 'f1_score_test': 0.4345}, 'Decision Tree': {'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8141, 'precision_test': 0.587, 'recall_test': 0.7452, 'f1_score_test': 0.6567}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8763, 'precision_test': 0.7154, 'recall_test': 0.7994, 'f1_score_test': 0.7551}, 'XGBoost': {'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8915, 'precision_test': 0.737, 'recall_test': 0.8477, 'f1_score_test': 0.7885}, 'Naive Bayes': {'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0./home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_3.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
7807, 'f1_cv_std': 0.0044, 'accuracy_test': 0.7612, 'precision_test': 0.4998, 'recall_test': 0.8072, 'f1_score_test': 0.6174}}}

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
E eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El último valor de eliminar es:  98849
Shape original y: (108138,)
Shape filtrado  y: (108125,)
Label distribution: {0: 82336, 1: 25802}
X shape: (108125, 1536)
y shape: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 1556)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 1556)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [1556, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4175, Test Loss: 0.3847, F1: 0.8277, AUC: 0.9074
Epoch [10/30] Train Loss: 0.3244, Test Loss: 0.3434, F1: 0.8510, AUC: 0.9277
Epoch [20/30] Train Loss: 0.3042, Test Loss: 0.3390, F1: 0.8560, AUC: 0.9309
Mejores resultados en la época:  24
f1-score 0.864
AUC según el mejor F1-score 0.9340762508638303

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4234, Test Loss: 0.4288, F1: 0.8348, AUC: 0.9164
Epoch [10/30] Train Loss: 0.3283, Test Loss: 0.3219, F1: 0.8559, AUC: 0.9384
Epoch [20/30] Train Loss: 0.3088, Test Loss: 0.3104, F1: 0.8636, AUC: 0.9430
Mejores resultados en la época:  28
f1-score 0.8724614134849715
AUC según el mejor F1-score 0.9437401175935941

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4500, Test Loss: 0.4198, F1: 0.7840, AUC: 0.9069
Epoch [10/30] Train Loss: 0.3293, Test Loss: 0.3395, F1: 0.8381, AUC: 0.9354
Epoch [20/30] Train Loss: 0.3099, Test Loss: 0.3148, F1: 0.8625, AUC: 0.9392
Mejores resultados en la época:  23
f1-score 0.8686262747450509
AUC según el mejor F1-score 0.9405819141164894

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4244, Test Loss: 0.3776, F1: 0.8337, AUC: 0.9131
Epoch [10/30] Train Loss: 0.3261, Test Loss: 0.3396, F1: 0.8528, AUC: 0.9310
Epoch [20/30] Train Loss: 0.3054, Test Loss: 0.3220, F1: 0.8622, AUC: 0.9362
Mejores resultados en la época:  27
f1-score 0.863579785909883
AUC según el mejor F1-score 0.9373462690393946

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4256, Test Loss: 0.3854, F1: 0.8110, AUC: 0.9126
Epoch [10/30] Train Loss: 0.3263, Test Loss: 0.3464, F1: 0.8585, AUC: 0.9330
Epoch [20/30] Train Loss: 0.3025, Test Loss: 0.3144, F1: 0.8662, AUC: 0.9406
Mejores resultados en la época:  27
f1-score 0.8662466682820451
AUC según el mejor F1-score 0.9405473244825623
Epoch [0/30] Train Loss: 0.4161, Test Loss: 0.4227, F1: 0.6993, AUC: 0.9156
Epoch [10/30] Train Loss: 0.3216, Test Loss: 0.2710, F1: 0.7621, AUC: 0.9346
Epoch [20/30] Train Loss: 0.3039, Test Loss: 0.3478, F1: 0.7422, AUC: 0.9397
Mejores resultados en la época:  24
f1-score 0.7787875948655486
AUC según el mejor F1-score 0.9401908440972983
Confusion matrix Test saved: outputs_without_artist/3/gpt/cm_mlp_1.png

========================================
Entrenando red 6 con capas [1556, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4185, Test Loss: 0.3823, F1: 0.8311, AUC: 0.9121
Epoch [10/30] Train Loss: 0.3107, Test Loss: 0.3293, F1: 0.8591, AUC: 0.9339
Epoch [20/30] Train Loss: 0.2760, Test Loss: 0.3226, F1: 0.8703, AUC: 0.9383
Mejores resultados en la época:  28
f1-score 0.8741865509761388
AUC según el mejor F1-score 0.9411789957315515

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4312, Test Loss: 0.3556, F1: 0.8440, AUC: 0.9222
Epoch [10/30] Train Loss: 0.3213, Test Loss: 0.3361, F1: 0.8396, AUC: 0.9376
Epoch [20/30] Train Loss: 0.2833, Test Loss: 0.2984, F1: 0.8824, AUC: 0.9472
Mejores resultados en la época:  21
f1-score 0.8824672170956775
AUC según el mejor F1-score 0.9472429729283097

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4262, Test Loss: 0.3696, F1: 0.8290, AUC: 0.9158
Epoch [10/30] Train Loss: 0.3142, Test Loss: 0.3167, F1: 0.8486, AUC: 0.9400
Epoch [20/30] Train Loss: 0.2821, Test Loss: 0.3092, F1: 0.8730, AUC: 0.9441
Mejores resultados en la época:  14
f1-score 0.8737119578241074
AUC según el mejor F1-score 0.9446689405590859

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4207, Test Loss: 0.3685, F1: 0.8237, AUC: 0.9163
Epoch [10/30] Train Loss: 0.3151, Test Loss: 0.3366, F1: 0.8425, AUC: 0.9377
Epoch [20/30] Train Loss: 0.2770, Test Loss: 0.3116, F1: 0.8661, AUC: 0.9435
Mejores resultados en la época:  26
f1-score 0.876022963234396
AUC según el mejor F1-score 0.9448152810100998

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4285, Test Loss: 0.3731, F1: 0.8297, AUC: 0.9140
Epoch [10/30] Train Loss: 0.3149, Test Loss: 0.3168, F1: 0.8639, AUC: 0.9391
Epoch [20/30] Train Loss: 0.2822, Test Loss: 0.2978, F1: 0.8724, AUC: 0.9466
Mejores resultados en la época:  27
f1-score 0.8780190290314711
AUC según el mejor F1-score 0.9493917853781957
Epoch [0/30] Train Loss: 0.4185, Test Loss: 0.3458, F1: 0.7303, AUC: 0.9193
Epoch [10/30] Train Loss: 0.3100, Test Loss: 0.3736, F1: 0.7266, AUC: 0.9400
Epoch [20/30] Train Loss: 0.2780, Test Loss: 0.2812, F1: 0.7762, AUC: 0.9467
Mejores resultados en la época:  29
f1-score 0.8001519756838906
AUC según el mejor F1-score 0.9471965903714009
Confusion matrix Test saved: outputs_without_artist/3/gpt/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}, 'Logistic Regression': {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}, 'SVM': {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}, 'Decision Tree': {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}, 'Random Forest': {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}, 'XGBoost': {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}, 'Naive Bayes': {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0045, 'precision_cv_mean': 0.866, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8707, 'recall_cv_std': 0.015, 'f1_cv_mean': 0.8682, 'f1_cv_std': 0.0049, 'params': 10305, 'accuracy_test': 0.8949, 'precision_test': 0.7667, 'recall_test': 0.8043, 'f1_score_test': 0.785}, 'MLP_1028097': {'accuracy_cv_mean': 0.8798, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8846, 'precision_cv_std': 0.012, 'recall_cv_mean': 0.874, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8791, 'f1_cv_std': 0.0044, 'params': 1028097, 'accuracy_test': 0.9047, 'precision_test': 0.7922, 'recall_test': 0.8143, 'f1_score_test': 0.8031}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8581, 'precision_test': 0.6628, 'recall_test': 0.825, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222, 'accuracy_test': 0.5749, 'precision_test': 0.3183, 'recall_test': 0.6843, 'f1_score_test': 0.4345}, 'Decision Tree': {'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8141, 'precision_test': 0.587, 'recall_test': 0.7452, 'f1_score_test': 0.6567}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8763, 'precision_test': 0.7154, 'recall_test': 0.7994, 'f1_score_test': 0.7551}, 'XGBoost': {'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8915, 'precision_test': 0.737, 'recall_test': 0.8477, 'f1_score_test': 0.7885}, 'Naive Bayes': {'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0./home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:20:32] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:23:20] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:26:08] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:28:57] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:31:45] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:34:34] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
7807, 'f1_cv_std': 0.0044, 'accuracy_test': 0.7612, 'precision_test': 0.4998, 'recall_test': 0.8072, 'f1_score_test': 0.6174}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8664, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8715, 'recall_cv_std': 0.0229, 'f1_cv_mean': 0.867, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8908, 'precision_test': 0.7539, 'recall_test': 0.8054, 'f1_score_test': 0.7788}, 'MLP_2293761': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8773, 'precision_cv_std': 0.0085, 'recall_cv_mean': 0.8766, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8769, 'f1_cv_std': 0.0032, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7846, 'recall_test': 0.8163, 'f1_score_test': 0.8002}}}
Saved on: outputs_without_artist/3/gpt

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8519, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8572, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.8444, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0033}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 45, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.86      0.90     16465
           1       0.65      0.84      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/3/gpt/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7563, 'accuracy_cv_std': 0.0125, 'precision_cv_mean': 0.7339, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8047, 'recall_cv_std': 0.0346, 'f1_cv_mean': 0.7672, 'f1_cv_std': 0.0159}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 45, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.53      0.67     16465
           1       0.36      0.84      0.50      5160

    accuracy                           0.60     21625
   macro avg       0.64      0.68      0.59     21625
weighted avg       0.78      0.60      0.63     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/3/gpt/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7824, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.7873, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7737, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7804, 'f1_cv_std': 0.0054}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 45, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.82      0.86     16465
           1       0.57      0.76      0.65      5160

    accuracy                           0.80     21625
   macro avg       0.74      0.79      0.76     21625
weighted avg       0.83      0.80      0.81     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/3/gpt/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8198, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8585, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.7659, 'recall_cv_std': 0.0083, 'f1_cv_mean': 0.8095, 'f1_cv_std': 0.0046}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 45, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.90     16465
           1       0.65      0.76      0.70      5160

    accuracy                           0.85     21625
   macro avg       0.79      0.82      0.80     21625
weighted avg       0.86      0.85      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/3/gpt/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.866, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8858, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8403, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8624, 'f1_cv_std': 0.0036}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 45, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.92     16465
           1       0.72      0.84      0.78      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/3/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8007, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8579, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.7208, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0052}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.88      0.89     16465
           1       0.65      0.72      0.68      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.80      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/3/gpt/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/3/gpt/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.866, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8858, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8403, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8624, 'f1_cv_std': 0.0036, 'accuracy_test': 0.8834, 'precision_test': 0.7177, 'recall_test': 0.8428, 'f1_score_test': 0.7752}
Logistic Regression: {'accuracy_cv_mean': 0.8519, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8572, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.8444, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8556, 'precision_test': 0.6535, 'recall_test': 0.8405, 'f1_score_test': 0.7353}
Random Forest: {'accuracy_cv_mean': 0.8198, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8585, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.7659, 'recall_cv_std': 0.0083, 'f1_cv_mean': 0.8095, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8463, 'precision_test': 0.6517, 'recall_test': 0.7643, 'f1_score_test': 0.7035}
Naive Bayes: {'accuracy_cv_mean': 0.8007, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8579, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.7208, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8414, 'precision_test': 0.6532, 'recall_test': 0.7153, 'f1_score_test': 0.6828}
Decision Tree: {'accuracy_cv_mean': 0.7824, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.7873, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7737, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7804, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8043, 'precision_test': 0.5669, 'recall_test': 0.763, 'f1_score_test': 0.6505}
SVM: {'accuracy_cv_mean': 0.7563, 'accuracy_cv_std': 0.0125, 'precision_cv_mean': 0.7339, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8047, 'recall_cv_std': 0.0346, 'f1_cv_mean': 0.7672, 'f1_cv_std': 0.0159, 'accuracy_test': 0.6048, 'precision_test': 0.3591, 'recall_test': 0.8368, 'f1_score_test': 0.5026}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}, 'MLP_5840897': {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}, 'Logistic Regression': {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}, 'SVM': {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}, 'Decision Tree': {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}, 'Random Forest': {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}, 'XGBoost': {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}, 'Naive Bayes': {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0045, 'precision_cv_mean': 0.866, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8707, 'recall_cv_std': 0.015, 'f1_cv_mean': 0.8682, 'f1_cv_std': 0.0049, 'params': 10305, 'accuracy_test': 0.8949, 'precision_test': 0.7667, 'recall_test': 0.8043, 'f1_score_test': 0.785}, 'MLP_1028097': {'accuracy_cv_mean': 0.8798, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8846, 'precision_cv_std': 0.012, 'recall_cv_mean': 0.874, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8791, 'f1_cv_std': 0.0044, 'params': 1028097, 'accuracy_test': 0.9047, 'precision_test': 0.7922, 'recall_test': 0.8143, 'f1_score_test': 0.8031}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8581, 'precision_test': 0.6628, 'recall_test': 0.825, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222, 'accuracy_test': 0.5749, 'precision_test': 0.3183, 'recall_test': 0.6843, 'f1_score_test': 0.4345}, 'Decision Tree': {'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8141, 'precision_test': 0.587, 'recall_test': 0.7452, 'f1_score_test': 0.6567}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8763, 'precision_test': 0.7154, 'recall_test': 0.7994, 'f1_score_test': 0.7551}, 'XGBoost': {'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8915, 'precision_test': 0.737, 'recall_test': 0.8477, 'f1_score_test': 0.7885}, 'Naive Bayes': {'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7807, 'f1_cv_std': 0.0044, 'accuracy_test': 0.7612, 'precision_test': 0.4998, 'recall_test': 0.8072, 'f1_score_test': 0.6174}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8664, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8715, 'recall_cv_std': 0.0229, 'f1_cv_mean': 0.867, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8908, 'precision_test': 0.7539, 'recall_test': 0.8054, 'f1_score_test': 0.7788}, 'MLP_2293761': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8773, 'precision_cv_std': 0.0085, 'recall_cv_mean': 0.8766, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8769, 'f1_cv_std': 0.0032, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7846, 'recall_test': 0.8163, 'f1_score_test': 0.8002}, 'Logistic Regression': {'accuracy_cv_mean': 0.8519, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8572, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.8444, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8556, 'precision_test': 0.6535, 'recall_test': 0.8405, 'f1_score_test': 0.7353}, 'SVM': {'accuracy_cv_mean': 0.7563, 'accuracy_cv_std': 0.0125, 'precision_cv_mean': 0.7339, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8047, 'recall_cv_std': 0.0346, 'f1_cv_mean': 0.7672, 'f1_cv_std': 0.0159, 'accuracy_test': 0.6048, 'precision_test': 0.3591, 'recall_test': 0.8368, 'f1_score_test': 0.5026}, 'Decision Tree': {'accuracy_cv_mean': 0.7824, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.7873, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7737, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7804, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8043, 'precision_test': 0.5669, 'recall_test': 0.763, 'f1_score_test': 0.6505}, 'Random Forest': {'accuracy_cv_mean': 0.8198, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8585, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.7659, 'recall_cv_std': 0.0083, 'f1_cv_mean': 0.8095, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8463, 'precision_test': 0.6517, 'recall_test': 0.7643, 'f1_score_test': 0.7035}, 'XGBoost': {'accuracy_cv_mean': 0.866, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8858, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8403, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8624, 'f1_cv_std': 0.0036, 'accuracy_test': 0.8834, 'precision_test': 0.7177, 'recall_test': 0.8428, 'f1_score_test': 0.7752}, 'Naive Bayes': {'accuracy_cv_mean': 0.8007, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8579, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.7208, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8414, 'precision_test': 0.6532, 'recall_test': 0.7153, 'f1_score_test': 0.6828}}}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_160705: {'accuracy_cv_mean': 0.8864, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.887, 'recall_cv_std': 0.013, 'f1_cv_mean': 0.8864, 'f1_cv_std': 0.0044, 'params': 160705, 'accuracy_test': 0.9175, 'precision_test': 0.8382, 'recall_test': 0.811, 'f1_score_test': 0.8244}
MLP_5840897: {'accuracy_cv_mean': 0.8955, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8975, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8932, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8952, 'f1_cv_std': 0.003, 'params': 5840897, 'accuracy_test': 0.9126, 'precision_test': 0.7946, 'recall_test': 0.8548, 'f1_score_test': 0.8236}
XGBoost: {'accuracy_cv_mean': 0.8776, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0068, 'recall_cv_mean': 0.8491, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.874, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8975, 'precision_test': 0.7529, 'recall_test': 0.849, 'f1_score_test': 0.7981}
Logistic Regression: {'accuracy_cv_mean': 0.8787, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8621, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8767, 'f1_cv_std': 0.0021, 'accuracy_test': 0.8901, 'precision_test': 0.7278, 'recall_test': 0.8618, 'f1_score_test': 0.7892}
Naive Bayes: {'accuracy_cv_mean': 0.8479, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8738, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8132, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0058, 'accuracy_test': 0.8658, 'precision_test': 0.684, 'recall_test': 0.8136, 'f1_score_test': 0.7432}
Decision Tree: {'accuracy_cv_mean': 0.8275, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8699, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.771, 'recall_cv_std': 0.0151, 'f1_cv_mean': 0.8171, 'f1_cv_std': 0.0014, 'accuracy_test': 0.8536, 'precision_test': 0.6634, 'recall_test': 0.7849, 'f1_score_test': 0.719}
Random Forest: {'accuracy_cv_mean': 0.8149, 'accuracy_cv_std': 0.0016, 'precision_cv_mean': 0.8489, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.7663, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8055, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8392, 'precision_test': 0.6356, 'recall_test': 0.7645, 'f1_score_test': 0.6941}
SVM: {'accuracy_cv_mean': 0.7267, 'accuracy_cv_std': 0.0343, 'precision_cv_mean': 0.6904, 'precision_cv_std': 0.0505, 'recall_cv_mean': 0.8372, 'recall_cv_std': 0.027, 'f1_cv_mean': 0.7548, 'f1_cv_std': 0.0195, 'accuracy_test': 0.703, 'precision_test': 0.4324, 'recall_test': 0.7824, 'f1_score_test': 0.557}


EMBEDDINGS TYPE: LYRICS_BERT
MLP_1028097: {'accuracy_cv_mean': 0.8798, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8846, 'precision_cv_std': 0.012, 'recall_cv_mean': 0.874, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8791, 'f1_cv_std': 0.0044, 'params': 1028097, 'accuracy_test': 0.9047, 'precision_test': 0.7922, 'recall_test': 0.8143, 'f1_score_test': 0.8031}
XGBoost: {'accuracy_cv_mean': 0.8759, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8952, 'precision_cv_std': 0.0061, 'recall_cv_mean': 0.8516, 'recall_cv_std': 0.005, 'f1_cv_mean': 0.8728, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8915, 'precision_test': 0.737, 'recall_test': 0.8477, 'f1_score_test': 0.7885}
MLP_10305: {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0045, 'precision_cv_mean': 0.866, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8707, 'recall_cv_std': 0.015, 'f1_cv_mean': 0.8682, 'f1_cv_std': 0.0049, 'params': 10305, 'accuracy_test': 0.8949, 'precision_test': 0.7667, 'recall_test': 0.8043, 'f1_score_test': 0.785}
Random Forest: {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8852, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8036, 'recall_cv_std': 0.0052, 'f1_cv_mean': 0.8424, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8763, 'precision_test': 0.7154, 'recall_test': 0.7994, 'f1_score_test': 0.7551}
Logistic Regression: {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.8624, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8269, 'recall_cv_std': 0.0046, 'f1_cv_mean': 0.8442, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8581, 'precision_test': 0.6628, 'recall_test': 0.825, 'f1_score_test': 0.735}
Decision Tree: {'accuracy_cv_mean': 0.7901, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8152, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.7505, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7814, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8141, 'precision_test': 0.587, 'recall_test': 0.7452, 'f1_score_test': 0.6567}
Naive Bayes: {'accuracy_cv_mean': 0.7735, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.7568, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8061, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7807, 'f1_cv_std': 0.0044, 'accuracy_test': 0.7612, 'precision_test': 0.4998, 'recall_test': 0.8072, 'f1_score_test': 0.6174}
SVM: {'accuracy_cv_mean': 0.6512, 'accuracy_cv_std': 0.033, 'precision_cv_mean': 0.6217, 'precision_cv_std': 0.0391, 'recall_cv_mean': 0.7905, 'recall_cv_std': 0.0519, 'f1_cv_mean': 0.694, 'f1_cv_std': 0.0222, 'accuracy_test': 0.5749, 'precision_test': 0.3183, 'recall_test': 0.6843, 'f1_score_test': 0.4345}


EMBEDDINGS TYPE: GPT
MLP_2293761: {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8773, 'precision_cv_std': 0.0085, 'recall_cv_mean': 0.8766, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8769, 'f1_cv_std': 0.0032, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7846, 'recall_test': 0.8163, 'f1_score_test': 0.8002}
MLP_49857: {'accuracy_cv_mean': 0.8664, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8715, 'recall_cv_std': 0.0229, 'f1_cv_mean': 0.867, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8908, 'precision_test': 0.7539, 'recall_test': 0.8054, 'f1_score_test': 0.7788}
XGBoost: {'accuracy_cv_mean': 0.866, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8858, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8403, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8624, 'f1_cv_std': 0.0036, 'accuracy_test': 0.8834, 'precision_test': 0.7177, 'recall_test': 0.8428, 'f1_score_test': 0.7752}
Logistic Regression: {'accuracy_cv_mean': 0.8519, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8572, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.8444, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8556, 'precision_test': 0.6535, 'recall_test': 0.8405, 'f1_score_test': 0.7353}
Random Forest: {'accuracy_cv_mean': 0.8198, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.8585, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.7659, 'recall_cv_std': 0.0083, 'f1_cv_mean': 0.8095, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8463, 'precision_test': 0.6517, 'recall_test': 0.7643, 'f1_score_test': 0.7035}
Naive Bayes: {'accuracy_cv_mean': 0.8007, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8579, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.7208, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8414, 'precision_test': 0.6532, 'recall_test': 0.7153, 'f1_score_test': 0.6828}
Decision Tree: {'accuracy_cv_mean': 0.7824, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.7873, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7737, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.7804, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8043, 'precision_test': 0.5669, 'recall_test': 0.763, 'f1_score_test': 0.6505}
SVM: {'accuracy_cv_mean': 0.7563, 'accuracy_cv_std': 0.0125, 'precision_cv_mean': 0.7339, 'precision_cv_std': 0.0115, 'recall_cv_mean': 0.8047, 'recall_cv_std': 0.0346, 'f1_cv_mean': 0.7672, 'f1_cv_std': 0.0159, 'accuracy_test': 0.6048, 'precision_test': 0.3591, 'recall_test': 0.8368, 'f1_score_test': 0.5026}
Diccionario global guardado en: outputs_without_artist/3/gpt/global_metrics.json

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
====================================

