2025-09-19 02:58:05.541001: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-19 02:58:05.605945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-19 02:58:08.285690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_5.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'Artist(s)', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
After removing some columns that doesn't love me, for TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
After removing some columns that doesn't love me, for numeric cols you are selecteing this columns:
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 5020)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 5020)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [5020, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4655, Test Loss: 0.4222, F1: 0.7941, AUC: 0.8916
Epoch [10/30] Train Loss: 0.2249, Test Loss: 0.3090, F1: 0.8535, AUC: 0.9538
Epoch [20/30] Train Loss: 0.1842, Test Loss: 0.2836, F1: 0.8867, AUC: 0.9564
Mejores resultados en la época:  26
f1-score 0.8884004884004884
AUC según el mejor F1-score 0.9577395380291901

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4703, Test Loss: 0.4189, F1: 0.7961, AUC: 0.8903
Epoch [10/30] Train Loss: 0.2325, Test Loss: 0.2845, F1: 0.8712, AUC: 0.9518
Epoch [20/30] Train Loss: 0.1901, Test Loss: 0.2948, F1: 0.8640, AUC: 0.9540
Mejores resultados en la época:  26
f1-score 0.8836659974016771
AUC según el mejor F1-score 0.9552157099276637

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4654, Test Loss: 0.4449, F1: 0.7599, AUC: 0.8942
Epoch [10/30] Train Loss: 0.2259, Test Loss: 0.2753, F1: 0.8812, AUC: 0.9543
Epoch [20/30] Train Loss: 0.1861, Test Loss: 0.3463, F1: 0.8487, AUC: 0.9571
Mejores resultados en la época:  29
f1-score 0.8891543239369326
AUC según el mejor F1-score 0.9588465553358422

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4619, Test Loss: 0.4065, F1: 0.8259, AUC: 0.9026
Epoch [10/30] Train Loss: 0.2246, Test Loss: 0.3142, F1: 0.8702, AUC: 0.9548
Epoch [20/30] Train Loss: 0.1828, Test Loss: 0.2827, F1: 0.8863, AUC: 0.9563
Mejores resultados en la época:  14
f1-score 0.8872675923746763
AUC según el mejor F1-score 0.9559702554364057

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4654, Test Loss: 0.4335, F1: 0.8256, AUC: 0.8988
Epoch [10/30] Train Loss: 0.2266, Test Loss: 0.2811, F1: 0.8830, AUC: 0.9564
Epoch [20/30] Train Loss: 0.1846, Test Loss: 0.3095, F1: 0.8802, AUC: 0.9553
Mejores resultados en la época:  19
f1-score 0.8922299735386096
AUC según el mejor F1-score 0.9575513833555918
Epoch [0/30] Train Loss: 0.4656, Test Loss: 0.4205, F1: 0.6979, AUC: 0.8965
Epoch [10/30] Train Loss: 0.2385, Test Loss: 0.3332, F1: 0.7526, AUC: 0.9536
Epoch [20/30] Train Loss: 0.2042, Test Loss: 0.2495, F1: 0.7979, AUC: 0.9538
Mejores resultados en la época:  27
f1-score 0.8143484067925968
AUC según el mejor F1-score 0.9558648895825534
Confusion matrix Test saved: outputs_without_artist/5/tfidf/cm_mlp_1.png

========================================
Entrenando red 6 con capas [5020, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4640, Test Loss: 0.3851, F1: 0.8373, AUC: 0.9149
Epoch [10/30] Train Loss: 0.2074, Test Loss: 0.2614, F1: 0.8865, AUC: 0.9588
Epoch [20/30] Train Loss: 0.1389, Test Loss: 0.3538, F1: 0.8804, AUC: 0.9540
Mejores resultados en la época:  28
f1-score 0.8963363363363364
AUC según el mejor F1-score 0.961305478796722

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4585, Test Loss: 0.4274, F1: 0.8111, AUC: 0.9162
Epoch [10/30] Train Loss: 0.2136, Test Loss: 0.2937, F1: 0.8823, AUC: 0.9558
Epoch [20/30] Train Loss: 0.1363, Test Loss: 0.2974, F1: 0.8845, AUC: 0.9587
Mejores resultados en la época:  29
f1-score 0.8913200288530897
AUC según el mejor F1-score 0.9592677312905623

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4614, Test Loss: 0.4347, F1: 0.8032, AUC: 0.9107
Epoch [10/30] Train Loss: 0.2097, Test Loss: 0.2887, F1: 0.8817, AUC: 0.9544
Epoch [20/30] Train Loss: 0.1478, Test Loss: 0.3057, F1: 0.8862, AUC: 0.9554
Mejores resultados en la época:  23
f1-score 0.8896462569044541
AUC según el mejor F1-score 0.9604741595025088

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4686, Test Loss: 0.4216, F1: 0.7574, AUC: 0.9000
Epoch [10/30] Train Loss: 0.2088, Test Loss: 0.2971, F1: 0.8653, AUC: 0.9579
Epoch [20/30] Train Loss: 0.1391, Test Loss: 0.3088, F1: 0.8934, AUC: 0.9618
Mejores resultados en la época:  20
f1-score 0.8934184675834971
AUC según el mejor F1-score 0.9618464291684745

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4484, Test Loss: 0.3612, F1: 0.8245, AUC: 0.9270
Epoch [10/30] Train Loss: 0.2190, Test Loss: 0.2937, F1: 0.8902, AUC: 0.9595
Epoch [20/30] Train Loss: 0.1410, Test Loss: 0.2962, F1: 0.8942, AUC: 0.9606
Mejores resultados en la época:  27
f1-score 0.8981001727115717
AUC según el mejor F1-score 0.9646861963097996
Epoch [0/30] Train Loss: 0.4520, Test Loss: 0.3035, F1: 0.7514, AUC: 0.9214
Epoch [10/30] Train Loss: 0.2134, Test Loss: 0.3007, F1: 0.7813, AUC: 0.9578
Epoch [20/30] Train Loss: 0.1400, Test Loss: 0.4106, F1: 0.7356, AUC: 0.9565
Mejores resultados en la época:  23
f1-score 0.8225984173094261
AUC según el mejor F1-score 0.9612719075228875
Confusion matrix Test saved: outputs_without_artist/5/tfidf/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}}}
Saved on: outputs_without_artist/5/tfidf

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026}
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:44:39] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:47:27] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:50:14] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:53:03] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:55:52] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:58:46] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 47, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.92     16465
           1       0.72      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/5/tfidf/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 47, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.72      0.81     16465
           1       0.47      0.80      0.59      5160

    accuracy                           0.74     21625
   macro avg       0.70      0.76      0.70     21625
weighted avg       0.81      0.74      0.76     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/5/tfidf/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 47, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.87      0.90     16465
           1       0.65      0.78      0.71      5160

    accuracy                           0.85     21625
   macro avg       0.79      0.82      0.80     21625
weighted avg       0.86      0.85      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/5/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 47, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.86      0.89     16465
           1       0.64      0.76      0.69      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.81      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/5/tfidf/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 47, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.85      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.86     21625
weighted avg       0.90      0.90      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/5/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041}
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     16465
           1       0.68      0.81      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.81      0.85      0.82     21625
weighted avg       0.88      0.86      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/5/tfidf/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/5/tfidf/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}
Logistic Regression: {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}
Naive Bayes: {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}
Decision Tree: {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_5.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
Random Forest: {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}
SVM: {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}, 'Logistic Regression': {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}, 'SVM': {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}, 'Decision Tree': {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}, 'Random Forest': {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}, 'XGBoost': {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}}}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 320)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 320)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [320, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4885, Test Loss: 0.4024, F1: 0.8206, AUC: 0.8980
Epoch [10/30] Train Loss: 0.3290, Test Loss: 0.3291, F1: 0.8598, AUC: 0.9325
Epoch [20/30] Train Loss: 0.3072, Test Loss: 0.3172, F1: 0.8592, AUC: 0.9383
Mejores resultados en la época:  25
f1-score 0.867749970347527
AUC según el mejor F1-score 0.9403958561027733

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4879, Test Loss: 0.4033, F1: 0.8141, AUC: 0.8997
Epoch [10/30] Train Loss: 0.3272, Test Loss: 0.3344, F1: 0.8503, AUC: 0.9319
Epoch [20/30] Train Loss: 0.2978, Test Loss: 0.3169, F1: 0.8592, AUC: 0.9381
Mejores resultados en la época:  28
f1-score 0.8670137245622338
AUC según el mejor F1-score 0.9411606862850038

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4374, Test Loss: 0.4002, F1: 0.8067, AUC: 0.9044
Epoch [10/30] Train Loss: 0.3162, Test Loss: 0.3366, F1: 0.8486, AUC: 0.9301
Epoch [20/30] Train Loss: 0.2900, Test Loss: 0.3326, F1: 0.8573, AUC: 0.9355
Mejores resultados en la época:  26
f1-score 0.8658112483511212
AUC según el mejor F1-score 0.9396940820112974

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4451, Test Loss: 0.4229, F1: 0.7883, AUC: 0.9019
Epoch [10/30] Train Loss: 0.3205, Test Loss: 0.3382, F1: 0.8512, AUC: 0.9303
Epoch [20/30] Train Loss: 0.2943, Test Loss: 0.3284, F1: 0.8540, AUC: 0.9330
Mejores resultados en la época:  26
f1-score 0.8611799702528508
AUC según el mejor F1-score 0.9374340230623442

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4771, Test Loss: 0.3960, F1: 0.8332, AUC: 0.9067
Epoch [10/30] Train Loss: 0.3325, Test Loss: 0.3209, F1: 0.8551, AUC: 0.9356
Epoch [20/30] Train Loss: 0.2995, Test Loss: 0.3105, F1: 0.8625, AUC: 0.9397
Mejores resultados en la época:  24
f1-score 0.8681073025335321
AUC según el mejor F1-score 0.9419156415588026
Epoch [0/30] Train Loss: 0.4539, Test Loss: 0.3405, F1: 0.7324, AUC: 0.9041
Epoch [10/30] Train Loss: 0.3163, Test Loss: 0.3062, F1: 0.7660, AUC: 0.9392
Epoch [20/30] Train Loss: 0.2908, Test Loss: 0.2786, F1: 0.7855, AUC: 0.9424
Mejores resultados en la época:  29
f1-score 0.7919340054995417
AUC según el mejor F1-score 0.9473823967683388
Confusion matrix Test saved: outputs_without_artist/5/lyrics_bert/cm_mlp_1.png

========================================
Entrenando red 6 con capas [320, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4421, Test Loss: 0.4263, F1: 0.7639, AUC: 0.9043
Epoch [10/30] Train Loss: 0.3004, Test Loss: 0.3143, F1: 0.8644, AUC: 0.9402
Epoch [20/30] Train Loss: 0.2524, Test Loss: 0.3052, F1: 0.8756, AUC: 0.9473
Mejores resultados en la época:  24
f1-score 0.8818029249580437
AUC según el mejor F1-score 0.9518771994809506

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4420, Test Loss: 0.3973, F1: 0.8142, AUC: 0.9093
Epoch [10/30] Train Loss: 0.2941, Test Loss: 0.3106, F1: 0.8587, AUC: 0.9392
Epoch [20/30] Train Loss: 0.2429, Test Loss: 0.3121, F1: 0.8667, AUC: 0.9461
Mejores resultados en la época:  28
f1-score 0.8820163155972239
AUC según el mejor F1-score 0.951421517261583

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4334, Test Loss: 0.4123, F1: 0.8005, AUC: 0.9033
Epoch [10/30] Train Loss: 0.2962, Test Loss: 0.3416, F1: 0.8301, AUC: 0.9354
Epoch [20/30] Train Loss: 0.2406, Test Loss: 0.3169, F1: 0.8678, AUC: 0.9444
Mejores resultados en la época:  29
f1-score 0.8744220004867365
AUC según el mejor F1-score 0.9458317371251728

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4372, Test Loss: 0.4416, F1: 0.7912, AUC: 0.9051
Epoch [10/30] Train Loss: 0.2919, Test Loss: 0.3480, F1: 0.8554, AUC: 0.9317
Epoch [20/30] Train Loss: 0.2450, Test Loss: 0.3133, F1: 0.8633, AUC: 0.9424
Mejores resultados en la época:  28
f1-score 0.8718127837932239
AUC según el mejor F1-score 0.9471147005539245

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4418, Test Loss: 0.3985, F1: 0.8350, AUC: 0.9142
Epoch [10/30] Train Loss: 0.3007, Test Loss: 0.3027, F1: 0.8658, AUC: 0.9432
Epoch [20/30] Train Loss: 0.2419, Test Loss: 0.2938, F1: 0.8785, AUC: 0.9500
Mejores resultados en la época:  20
f1-score 0.8784611614800294
AUC según el mejor F1-score 0.9500121388173551
Epoch [0/30] Train Loss: 0.4366, Test Loss: 0.4767, F1: 0.6792, AUC: 0.9101
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
Epoch [10/30] Train Loss: 0.2907, Test Loss: 0.3496, F1: 0.7441, AUC: 0.9460
Epoch [20/30] Train Loss: 0.2394, Test Loss: 0.2821, F1: 0.7813, AUC: 0.9452
Mejores resultados en la época:  28
f1-score 0.8149543271494492
AUC según el mejor F1-score 0.95577725360584
Confusion matrix Test saved: outputs_without_artist/5/lyrics_bert/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}, 'Logistic Regression': {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}, 'SVM': {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}, 'Decision Tree': {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}, 'Random Forest': {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}, 'XGBoost': {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8658, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8654, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.8673, 'recall_cv_std': 0.0195, 'f1_cv_mean': 0.866, 'f1_cv_std': 0.0025, 'params': 10305, 'accuracy_test': 0.895, 'precision_test': 0.7513, 'recall_test': 0.8372, 'f1_score_test': 0.7919}, 'MLP_1028097': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8731, 'precision_cv_std': 0.018, 'recall_cv_mean': 0.8829, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8777, 'f1_cv_std': 0.004, 'params': 1028097, 'accuracy_test': 0.9091, 'precision_test': 0.7926, 'recall_test': 0.8386, 'f1_score_test': 0.815}}}
Saved on: outputs_without_artist/5/lyrics_bert

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 47, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.87      0.90     16465
           1       0.67      0.83      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 47, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.82      0.46      0.59     16465
           1       0.29      0.69      0.40      5160

    accuracy                           0.52     21625
   macro avg       0.56      0.57      0.50     21625
weighted avg       0.70      0.52      0.55     21625

Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 47, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.82      0.87     16465
           1       0.57      0.76      0.65      5160

    accuracy                           0.81     21625
   macro avg       0.74      0.79      0.76     21625
weighted avg       0.83      0.81      0.82     21625

Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 47, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.90      0.92     16465
           1       0.71      0.80      0.75      5160

    accuracy                           0.88     21625
   macro avg       0.82      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:56] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:28] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:59] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:26:31] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:27:02] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:27:34] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 47, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.7829, 'f1_cv_std': 0.0042}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.74      0.82     16465
           1       0.50      0.80      0.61      5160

    accuracy                           0.76     21625
   macro avg       0.71      0.77      0.72     21625
weighted avg       0.82      0.76      0.77     21625

Confusion matrix Test saved as: outputs_without_artist/5/lyrics_bert/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/5/lyrics_bert/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022, 'accuracy_test': 0.8912, 'precision_test': 0.7331, 'recall_test': 0.8554, 'f1_score_test': 0.7896}
Random Forest: {'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003, 'accuracy_test': 0.8753, 'precision_test': 0.7113, 'recall_test': 0.8035, 'f1_score_test': 0.7546}
Logistic Regression: {'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008, 'accuracy_test': 0.8603, 'precision_test': 0.6661, 'recall_test': 0.8308, 'f1_score_test': 0.7394}
Decision Tree: {'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8073, 'precision_test': 0.5724, 'recall_test': 0.761, 'f1_score_test': 0.6534}
Naive Bayes: {'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.7829, 'f1_cv_std': 0.0042, 'accuracy_test': 0.7579, 'precision_test': 0.4955, 'recall_test': 0.8023, 'f1_score_test': 0.6126}
SVM: {'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221, 'accuracy_test': 0.5151, 'precision_test': 0.2857, 'recall_test': 0.6878, 'f1_score_test': 0.4037}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}, 'Logistic Regression': {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}, 'SVM': {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}, 'Decision Tree': {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}, 'Random Forest': {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}, 'XGBoost': {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8658, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8654, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.8673, 'recall_cv_std': 0.0195, 'f1_cv_mean': 0.866, 'f1_cv_std': 0.0025, 'params': 10305, 'accuracy_test': 0.895, 'precision_test': 0.7513, 'recall_test': 0.8372, 'f1_score_test': 0.7919}, 'MLP_1028097': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8731, 'precision_cv_std': 0.018, 'recall_cv_mean': 0.8829, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8777, 'f1_cv_std': 0.004, 'params': 1028097, 'accuracy_test': 0.9091, 'precision_test': 0.7926, 'recall_test': 0.8386, 'f1_score_test': 0.815}, 'Logistic Regression': {'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008, 'accuracy_test': 0.8603, 'precision_test': 0.6661, 'recall_test': 0.8308, 'f1_score_test': 0.7394}, 'SVM': {'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221, 'accuracy_test': 0.5151, 'precision_test': 0.2857, 'recall_test': 0.6878, 'f1_score_test': 0.4037}, 'Decision Tree': {'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8073, 'precision_test': 0.5724, 'recall_test': 0.761, 'f1_score_test': 0.6534}, 'Random Forest': {'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003, 'accuracy_test': 0.8753, 'precision_test': 0.7113, 'recall_test': 0.8035, 'f1_score_test': 0.7546}, 'XGBoost': {'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022, 'accuracy_test': 0.8912, 'precision_test': 0.7331, 'recall_test': 0.8554, 'f1_score_test': 0.7896}, 'Naive Bayes': {'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_5.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
mean': 0.7829, 'f1_cv_std': 0.0042, 'accuracy_test': 0.7579, 'precision_test': 0.4955, 'recall_test': 0.8023, 'f1_score_test': 0.6126}}}

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
E eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El último valor de eliminar es:  98849
Shape original y: (108138,)
Shape filtrado  y: (108125,)
Label distribution: {0: 82336, 1: 25802}
X shape: (108125, 1536)
y shape: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 1556)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 1556)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [1556, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4408, Test Loss: 0.3795, F1: 0.8290, AUC: 0.9104
Epoch [10/30] Train Loss: 0.3286, Test Loss: 0.3293, F1: 0.8562, AUC: 0.9337
Epoch [20/30] Train Loss: 0.3088, Test Loss: 0.3307, F1: 0.8572, AUC: 0.9364
Mejores resultados en la época:  22
f1-score 0.8682358650812909
AUC según el mejor F1-score 0.9391541000484497

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4398, Test Loss: 0.3834, F1: 0.8248, AUC: 0.9081
Epoch [10/30] Train Loss: 0.3297, Test Loss: 0.3357, F1: 0.8548, AUC: 0.9305
Epoch [20/30] Train Loss: 0.3086, Test Loss: 0.3779, F1: 0.8267, AUC: 0.9338
Mejores resultados en la época:  28
f1-score 0.8660322108345534
AUC según el mejor F1-score 0.9352154857543117

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4318, Test Loss: 0.3884, F1: 0.8317, AUC: 0.9110
Epoch [10/30] Train Loss: 0.3290, Test Loss: 0.3350, F1: 0.8448, AUC: 0.9326
Epoch [20/30] Train Loss: 0.3119, Test Loss: 0.3433, F1: 0.8425, AUC: 0.9343
Mejores resultados en la época:  19
f1-score 0.8620648687180705
AUC según el mejor F1-score 0.9354369596365903

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4129, Test Loss: 0.3713, F1: 0.8364, AUC: 0.9154
Epoch [10/30] Train Loss: 0.3254, Test Loss: 0.3365, F1: 0.8426, AUC: 0.9340
Epoch [20/30] Train Loss: 0.3069, Test Loss: 0.3122, F1: 0.8625, AUC: 0.9407
Mejores resultados en la época:  28
f1-score 0.870817954518395
AUC según el mejor F1-score 0.9419180775400415

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4190, Test Loss: 0.3746, F1: 0.8428, AUC: 0.9183
Epoch [10/30] Train Loss: 0.3278, Test Loss: 0.3247, F1: 0.8503, AUC: 0.9392
Epoch [20/30] Train Loss: 0.3085, Test Loss: 0.3064, F1: 0.8684, AUC: 0.9422
Mejores resultados en la época:  29
f1-score 0.87170647623738
AUC según el mejor F1-score 0.9436191261742017
Epoch [0/30] Train Loss: 0.4156, Test Loss: 0.3580, F1: 0.7210, AUC: 0.9142
Epoch [10/30] Train Loss: 0.3222, Test Loss: 0.3191, F1: 0.7540, AUC: 0.9366
Epoch [20/30] Train Loss: 0.3045, Test Loss: 0.3152, F1: 0.7604, AUC: 0.9396
Mejores resultados en la época:  27
f1-score 0.7788554801163918
AUC según el mejor F1-score 0.9396237026156022
Confusion matrix Test saved: outputs_without_artist/5/gpt/cm_mlp_1.png

========================================
Entrenando red 6 con capas [1556, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4215, Test Loss: 0.3772, F1: 0.8386, AUC: 0.9161
Epoch [10/30] Train Loss: 0.3160, Test Loss: 0.3181, F1: 0.8712, AUC: 0.9402
Epoch [20/30] Train Loss: 0.2826, Test Loss: 0.3248, F1: 0.8455, AUC: 0.9431
Mejores resultados en la época:  25
f1-score 0.8770580459079438
AUC según el mejor F1-score 0.9424567544956732

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4267, Test Loss: 0.3789, F1: 0.8342, AUC: 0.9150
Epoch [10/30] Train Loss: 0.3140, Test Loss: 0.3452, F1: 0.8561, AUC: 0.9310
Epoch [20/30] Train Loss: 0.2817, Test Loss: 0.3188, F1: 0.8679, AUC: 0.9398
Mejores resultados en la época:  25
f1-score 0.8795762213066509
AUC según el mejor F1-score 0.9453701278093263

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4221, Test Loss: 0.3993, F1: 0.7792, AUC: 0.9149
Epoch [10/30] Train Loss: 0.3155, Test Loss: 0.3717, F1: 0.8179, AUC: 0.9354
Epoch [20/30] Train Loss: 0.2772, Test Loss: 0.3326, F1: 0.8651, AUC: 0.9424
Mejores resultados en la época:  29
f1-score 0.8739082297945627
AUC según el mejor F1-score 0.9468049546301305

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4176, Test Loss: 0.3921, F1: 0.8235, AUC: 0.9136
Epoch [10/30] Train Loss: 0.3131, Test Loss: 0.3105, F1: 0.8702, AUC: 0.9412
Epoch [20/30] Train Loss: 0.2809, Test Loss: 0.3351, F1: 0.8466, AUC: 0.9413
Mejores resultados en la época:  23
f1-score 0.8809581417856279
AUC según el mejor F1-score 0.9474274159768438

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4257, Test Loss: 0.3723, F1: 0.8315, AUC: 0.9204
Epoch [10/30] Train Loss: 0.3168, Test Loss: 0.3292, F1: 0.8698, AUC: 0.9402
Epoch [20/30] Train Loss: 0.2845, Test Loss: 0.2955, F1: 0.8776, AUC: 0.9472
Mejores resultados en la época:  29
f1-score 0.8823239783357951
AUC según el mejor F1-score 0.9496941698927276
Epoch [0/30] Train Loss: 0.4148, Test Loss: 0.3253, F1: 0.7221, AUC: 0.9192
Epoch [10/30] Train Loss: 0.3110, Test Loss: 0.2754, F1: 0.7647, AUC: 0.9385
Epoch [20/30] Train Loss: 0.2679, Test Loss: 0.3182, F1: 0.7571, AUC: 0.9459
Mejores resultados en la época:  27
f1-score 0.7970228797206652
AUC según el mejor F1-score 0.9495400038135863
Confusion matrix Test saved: outputs_without_artist/5/gpt/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}, 'Logistic Regression': {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}, 'SVM': {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}, 'Decision Tree': {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}, 'Random Forest': {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}, 'XGBoost': {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8658, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8654, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.8673, 'recall_cv_std': 0.0195, 'f1_cv_mean': 0.866, 'f1_cv_std': 0.0025, 'params': 10305, 'accuracy_test': 0.895, 'precision_test': 0.7513, 'recall_test': 0.8372, 'f1_score_test': 0.7919}, 'MLP_1028097': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8731, 'precision_cv_std': 0.018, 'recall_cv_mean': 0.8829, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8777, 'f1_cv_std': 0.004, 'params': 1028097, 'accuracy_test': 0.9091, 'precision_test': 0.7926, 'recall_test': 0.8386, 'f1_score_test': 0.815}, 'Logistic Regression': {'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008, 'accuracy_test': 0.8603, 'precision_test': 0.6661, 'recall_test': 0.8308, 'f1_score_test': 0.7394}, 'SVM': {'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221, 'accuracy_test': 0.5151, 'precision_test': 0.2857, 'recall_test': 0.6878, 'f1_score_test': 0.4037}, 'Decision Tree': {'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8073, 'precision_test': 0.5724, 'recall_test': 0.761, 'f1_score_test': 0.6534}, 'Random Forest': {'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003, 'accuracy_test': 0.8753, 'precision_test': 0.7113, 'recall_test': 0.8035, 'f1_score_test': 0.7546}, 'XGBoost': {'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022, 'accuracy_test': 0.8912, 'precision_test': 0.7331, 'recall_test': 0.8554, 'f1_score_test': 0.7896}, 'Naive Bayes': {'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:21:25] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:24:14] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:27:04] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:29:52] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:32:39] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:35:26] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
mean': 0.7829, 'f1_cv_std': 0.0042, 'accuracy_test': 0.7579, 'precision_test': 0.4955, 'recall_test': 0.8023, 'f1_score_test': 0.6126}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8674, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.8661, 'precision_cv_std': 0.0139, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.011, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0035, 'params': 49857, 'accuracy_test': 0.8946, 'precision_test': 0.7796, 'recall_test': 0.7781, 'f1_score_test': 0.7789}, 'MLP_2293761': {'accuracy_cv_mean': 0.8786, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.878, 'precision_cv_std': 0.0143, 'recall_cv_mean': 0.88, 'recall_cv_std': 0.0153, 'f1_cv_mean': 0.8788, 'f1_cv_std': 0.003, 'params': 2293761, 'accuracy_test': 0.8978, 'precision_test': 0.7578, 'recall_test': 0.8405, 'f1_score_test': 0.797}}}
Saved on: outputs_without_artist/5/gpt

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.852, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8576, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8442, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0045}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 47, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.86      0.90     16465
           1       0.65      0.84      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/5/gpt/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7513, 'accuracy_cv_std': 0.0223, 'precision_cv_mean': 0.7304, 'precision_cv_std': 0.0311, 'recall_cv_mean': 0.8002, 'recall_cv_std': 0.0103, 'f1_cv_mean': 0.7633, 'f1_cv_std': 0.0163}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 47, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.62      0.74     16465
           1       0.41      0.85      0.55      5160

    accuracy                           0.67     21625
   macro avg       0.67      0.73      0.65     21625
weighted avg       0.80      0.67      0.70     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/5/gpt/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7831, 'accuracy_cv_std': 0.0061, 'precision_cv_mean': 0.7881, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.7742, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.7811, 'f1_cv_std': 0.0068}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 47, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.79      0.85     16465
           1       0.54      0.78      0.64      5160

    accuracy                           0.79     21625
   macro avg       0.73      0.79      0.75     21625
weighted avg       0.83      0.79      0.80     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/5/gpt/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8209, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8594, 'precision_cv_std': 0.0075, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.8108, 'f1_cv_std': 0.006}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 47, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.90     16465
           1       0.65      0.77      0.71      5160

    accuracy                           0.85     21625
   macro avg       0.79      0.82      0.80     21625
weighted avg       0.86      0.85      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/5/gpt/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8657, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8863, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.8391, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0044}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 47, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.77      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.88     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/5/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8586, 'precision_cv_std': 0.0047, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.7826, 'f1_cv_std': 0.0033}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.88      0.89     16465
           1       0.65      0.72      0.69      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.80      0.79     21625
weighted avg       0.85      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/5/gpt/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/5/gpt/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8657, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8863, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.8391, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8815, 'precision_test': 0.7099, 'recall_test': 0.8512, 'f1_score_test': 0.7741}
Logistic Regression: {'accuracy_cv_mean': 0.852, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8576, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8442, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0045, 'accuracy_test': 0.856, 'precision_test': 0.6538, 'recall_test': 0.8424, 'f1_score_test': 0.7362}
Random Forest: {'accuracy_cv_mean': 0.8209, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8594, 'precision_cv_std': 0.0075, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.8108, 'f1_cv_std': 0.006, 'accuracy_test': 0.8458, 'precision_test': 0.6484, 'recall_test': 0.7731, 'f1_score_test': 0.7053}
Naive Bayes: {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8586, 'precision_cv_std': 0.0047, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.7826, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8424, 'precision_test': 0.6531, 'recall_test': 0.724, 'f1_score_test': 0.6868}
Decision Tree: {'accuracy_cv_mean': 0.7831, 'accuracy_cv_std': 0.0061, 'precision_cv_mean': 0.7881, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.7742, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.7811, 'f1_cv_std': 0.0068, 'accuracy_test': 0.7901, 'precision_test': 0.5415, 'recall_test': 0.7849, 'f1_score_test': 0.6409}
SVM: {'accuracy_cv_mean': 0.7513, 'accuracy_cv_std': 0.0223, 'precision_cv_mean': 0.7304, 'precision_cv_std': 0.0311, 'recall_cv_mean': 0.8002, 'recall_cv_std': 0.0103, 'f1_cv_mean': 0.7633, 'f1_cv_std': 0.0163, 'accuracy_test': 0.6732, 'precision_test': 0.4104, 'recall_test': 0.8459, 'f1_score_test': 0.5526}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}, 'MLP_5840897': {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}, 'Logistic Regression': {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}, 'SVM': {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}, 'Decision Tree': {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}, 'Random Forest': {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}, 'XGBoost': {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8658, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8654, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.8673, 'recall_cv_std': 0.0195, 'f1_cv_mean': 0.866, 'f1_cv_std': 0.0025, 'params': 10305, 'accuracy_test': 0.895, 'precision_test': 0.7513, 'recall_test': 0.8372, 'f1_score_test': 0.7919}, 'MLP_1028097': {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8731, 'precision_cv_std': 0.018, 'recall_cv_mean': 0.8829, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8777, 'f1_cv_std': 0.004, 'params': 1028097, 'accuracy_test': 0.9091, 'precision_test': 0.7926, 'recall_test': 0.8386, 'f1_score_test': 0.815}, 'Logistic Regression': {'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008, 'accuracy_test': 0.8603, 'precision_test': 0.6661, 'recall_test': 0.8308, 'f1_score_test': 0.7394}, 'SVM': {'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221, 'accuracy_test': 0.5151, 'precision_test': 0.2857, 'recall_test': 0.6878, 'f1_score_test': 0.4037}, 'Decision Tree': {'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8073, 'precision_test': 0.5724, 'recall_test': 0.761, 'f1_score_test': 0.6534}, 'Random Forest': {'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003, 'accuracy_test': 0.8753, 'precision_test': 0.7113, 'recall_test': 0.8035, 'f1_score_test': 0.7546}, 'XGBoost': {'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022, 'accuracy_test': 0.8912, 'precision_test': 0.7331, 'recall_test': 0.8554, 'f1_score_test': 0.7896}, 'Naive Bayes': {'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.7829, 'f1_cv_std': 0.0042, 'accuracy_test': 0.7579, 'precision_test': 0.4955, 'recall_test': 0.8023, 'f1_score_test': 0.6126}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8674, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.8661, 'precision_cv_std': 0.0139, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.011, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0035, 'params': 49857, 'accuracy_test': 0.8946, 'precision_test': 0.7796, 'recall_test': 0.7781, 'f1_score_test': 0.7789}, 'MLP_2293761': {'accuracy_cv_mean': 0.8786, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.878, 'precision_cv_std': 0.0143, 'recall_cv_mean': 0.88, 'recall_cv_std': 0.0153, 'f1_cv_mean': 0.8788, 'f1_cv_std': 0.003, 'params': 2293761, 'accuracy_test': 0.8978, 'precision_test': 0.7578, 'recall_test': 0.8405, 'f1_score_test': 0.797}, 'Logistic Regression': {'accuracy_cv_mean': 0.852, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8576, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8442, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0045, 'accuracy_test': 0.856, 'precision_test': 0.6538, 'recall_test': 0.8424, 'f1_score_test': 0.7362}, 'SVM': {'accuracy_cv_mean': 0.7513, 'accuracy_cv_std': 0.0223, 'precision_cv_mean': 0.7304, 'precision_cv_std': 0.0311, 'recall_cv_mean': 0.8002, 'recall_cv_std': 0.0103, 'f1_cv_mean': 0.7633, 'f1_cv_std': 0.0163, 'accuracy_test': 0.6732, 'precision_test': 0.4104, 'recall_test': 0.8459, 'f1_score_test': 0.5526}, 'Decision Tree': {'accuracy_cv_mean': 0.7831, 'accuracy_cv_std': 0.0061, 'precision_cv_mean': 0.7881, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.7742, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.7811, 'f1_cv_std': 0.0068, 'accuracy_test': 0.7901, 'precision_test': 0.5415, 'recall_test': 0.7849, 'f1_score_test': 0.6409}, 'Random Forest': {'accuracy_cv_mean': 0.8209, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8594, 'precision_cv_std': 0.0075, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.8108, 'f1_cv_std': 0.006, 'accuracy_test': 0.8458, 'precision_test': 0.6484, 'recall_test': 0.7731, 'f1_score_test': 0.7053}, 'XGBoost': {'accuracy_cv_mean': 0.8657, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8863, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.8391, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8815, 'precision_test': 0.7099, 'recall_test': 0.8512, 'f1_score_test': 0.7741}, 'Naive Bayes': {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8586, 'precision_cv_std': 0.0047, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.7826, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8424, 'precision_test': 0.6531, 'recall_test': 0.724, 'f1_score_test': 0.6868}}}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_5840897: {'accuracy_cv_mean': 0.8934, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.8917, 'precision_cv_std': 0.0177, 'recall_cv_mean': 0.8964, 'recall_cv_std': 0.0135, 'f1_cv_mean': 0.8938, 'f1_cv_std': 0.0031, 'params': 5840897, 'accuracy_test': 0.9181, 'precision_test': 0.8513, 'recall_test': 0.7957, 'f1_score_test': 0.8226}
MLP_160705: {'accuracy_cv_mean': 0.8866, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8767, 'precision_cv_std': 0.0131, 'recall_cv_mean': 0.9002, 'recall_cv_std': 0.0107, 'f1_cv_mean': 0.8881, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.91, 'precision_test': 0.802, 'recall_test': 0.8271, 'f1_score_test': 0.8143}
XGBoost: {'accuracy_cv_mean': 0.8773, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.902, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8466, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8734, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8963, 'precision_test': 0.7488, 'recall_test': 0.851, 'f1_score_test': 0.7966}
Logistic Regression: {'accuracy_cv_mean': 0.8803, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.8929, 'precision_cv_std': 0.0038, 'recall_cv_mean': 0.8642, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.8783, 'f1_cv_std': 0.0026, 'accuracy_test': 0.8882, 'precision_test': 0.7225, 'recall_test': 0.8628, 'f1_score_test': 0.7864}
Naive Bayes: {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8747, 'precision_cv_std': 0.0072, 'recall_cv_mean': 0.8112, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.8418, 'f1_cv_std': 0.0041, 'accuracy_test': 0.8628, 'precision_test': 0.6771, 'recall_test': 0.8124, 'f1_score_test': 0.7386}
Decision Tree: {'accuracy_cv_mean': 0.8232, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.877, 'precision_cv_std': 0.0136, 'recall_cv_mean': 0.7524, 'recall_cv_std': 0.0174, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8459, 'precision_test': 0.6463, 'recall_test': 0.782, 'f1_score_test': 0.7077}
Random Forest: {'accuracy_cv_mean': 0.8157, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8495, 'precision_cv_std': 0.0092, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0056, 'f1_cv_mean': 0.8064, 'f1_cv_std': 0.005, 'accuracy_test': 0.8394, 'precision_test': 0.6361, 'recall_test': 0.7645, 'f1_score_test': 0.6944}
SVM: {'accuracy_cv_mean': 0.7377, 'accuracy_cv_std': 0.0278, 'precision_cv_mean': 0.7029, 'precision_cv_std': 0.0314, 'recall_cv_mean': 0.8273, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.7597, 'f1_cv_std': 0.0202, 'accuracy_test': 0.7391, 'precision_test': 0.4724, 'recall_test': 0.8, 'f1_score_test': 0.594}


EMBEDDINGS TYPE: LYRICS_BERT
MLP_1028097: {'accuracy_cv_mean': 0.8769, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8731, 'precision_cv_std': 0.018, 'recall_cv_mean': 0.8829, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8777, 'f1_cv_std': 0.004, 'params': 1028097, 'accuracy_test': 0.9091, 'precision_test': 0.7926, 'recall_test': 0.8386, 'f1_score_test': 0.815}
MLP_10305: {'accuracy_cv_mean': 0.8658, 'accuracy_cv_std': 0.0028, 'precision_cv_mean': 0.8654, 'precision_cv_std': 0.0175, 'recall_cv_mean': 0.8673, 'recall_cv_std': 0.0195, 'f1_cv_mean': 0.866, 'f1_cv_std': 0.0025, 'params': 10305, 'accuracy_test': 0.895, 'precision_test': 0.7513, 'recall_test': 0.8372, 'f1_score_test': 0.7919}
XGBoost: {'accuracy_cv_mean': 0.8729, 'accuracy_cv_std': 0.002, 'precision_cv_mean': 0.8926, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8479, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8697, 'f1_cv_std': 0.0022, 'accuracy_test': 0.8912, 'precision_test': 0.7331, 'recall_test': 0.8554, 'f1_score_test': 0.7896}
Random Forest: {'accuracy_cv_mean': 0.8488, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8834, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.8038, 'recall_cv_std': 0.0015, 'f1_cv_mean': 0.8417, 'f1_cv_std': 0.003, 'accuracy_test': 0.8753, 'precision_test': 0.7113, 'recall_test': 0.8035, 'f1_score_test': 0.7546}
Logistic Regression: {'accuracy_cv_mean': 0.8476, 'accuracy_cv_std': 0.0008, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0019, 'recall_cv_mean': 0.8279, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8445, 'f1_cv_std': 0.0008, 'accuracy_test': 0.8603, 'precision_test': 0.6661, 'recall_test': 0.8308, 'f1_score_test': 0.7394}
Decision Tree: {'accuracy_cv_mean': 0.7866, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8144, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7428, 'recall_cv_std': 0.0122, 'f1_cv_mean': 0.7768, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8073, 'precision_test': 0.5724, 'recall_test': 0.761, 'f1_score_test': 0.6534}
Naive Bayes: {'accuracy_cv_mean': 0.7761, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.7599, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8073, 'recall_cv_std': 0.0043, 'f1_cv_mean': 0.7829, 'f1_cv_std': 0.0042, 'accuracy_test': 0.7579, 'precision_test': 0.4955, 'recall_test': 0.8023, 'f1_score_test': 0.6126}
SVM: {'accuracy_cv_mean': 0.6454, 'accuracy_cv_std': 0.0188, 'precision_cv_mean': 0.6157, 'precision_cv_std': 0.0142, 'recall_cv_mean': 0.7743, 'recall_cv_std': 0.0439, 'f1_cv_mean': 0.6854, 'f1_cv_std': 0.0221, 'accuracy_test': 0.5151, 'precision_test': 0.2857, 'recall_test': 0.6878, 'f1_score_test': 0.4037}


EMBEDDINGS TYPE: GPT
MLP_2293761: {'accuracy_cv_mean': 0.8786, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.878, 'precision_cv_std': 0.0143, 'recall_cv_mean': 0.88, 'recall_cv_std': 0.0153, 'f1_cv_mean': 0.8788, 'f1_cv_std': 0.003, 'params': 2293761, 'accuracy_test': 0.8978, 'precision_test': 0.7578, 'recall_test': 0.8405, 'f1_score_test': 0.797}
MLP_49857: {'accuracy_cv_mean': 0.8674, 'accuracy_cv_std': 0.0046, 'precision_cv_mean': 0.8661, 'precision_cv_std': 0.0139, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.011, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0035, 'params': 49857, 'accuracy_test': 0.8946, 'precision_test': 0.7796, 'recall_test': 0.7781, 'f1_score_test': 0.7789}
XGBoost: {'accuracy_cv_mean': 0.8657, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8863, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.8391, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8815, 'precision_test': 0.7099, 'recall_test': 0.8512, 'f1_score_test': 0.7741}
Logistic Regression: {'accuracy_cv_mean': 0.852, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.8576, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.8442, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.8508, 'f1_cv_std': 0.0045, 'accuracy_test': 0.856, 'precision_test': 0.6538, 'recall_test': 0.8424, 'f1_score_test': 0.7362}
Random Forest: {'accuracy_cv_mean': 0.8209, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.8594, 'precision_cv_std': 0.0075, 'recall_cv_mean': 0.7675, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.8108, 'f1_cv_std': 0.006, 'accuracy_test': 0.8458, 'precision_test': 0.6484, 'recall_test': 0.7731, 'f1_score_test': 0.7053}
Naive Bayes: {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8586, 'precision_cv_std': 0.0047, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.7826, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8424, 'precision_test': 0.6531, 'recall_test': 0.724, 'f1_score_test': 0.6868}
Decision Tree: {'accuracy_cv_mean': 0.7831, 'accuracy_cv_std': 0.0061, 'precision_cv_mean': 0.7881, 'precision_cv_std': 0.0051, 'recall_cv_mean': 0.7742, 'recall_cv_std': 0.0097, 'f1_cv_mean': 0.7811, 'f1_cv_std': 0.0068, 'accuracy_test': 0.7901, 'precision_test': 0.5415, 'recall_test': 0.7849, 'f1_score_test': 0.6409}
SVM: {'accuracy_cv_mean': 0.7513, 'accuracy_cv_std': 0.0223, 'precision_cv_mean': 0.7304, 'precision_cv_std': 0.0311, 'recall_cv_mean': 0.8002, 'recall_cv_std': 0.0103, 'f1_cv_mean': 0.7633, 'f1_cv_std': 0.0163, 'accuracy_test': 0.6732, 'precision_test': 0.4104, 'recall_test': 0.8459, 'f1_score_test': 0.5526}
Diccionario global guardado en: outputs_without_artist/5/gpt/global_metrics.json

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
====================================

