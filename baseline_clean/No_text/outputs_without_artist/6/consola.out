2025-09-19 10:57:42.204894: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-19 10:57:42.274996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-19 10:57:47.679113: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_6.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'Artist(s)', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
After removing some columns that doesn't love me, for TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
After removing some columns that doesn't love me, for numeric cols you are selecteing this columns:
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 5020)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 5020)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [5020, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4625, Test Loss: 0.4011, F1: 0.8037, AUC: 0.9055
Epoch [10/30] Train Loss: 0.2238, Test Loss: 0.3067, F1: 0.8761, AUC: 0.9553
Epoch [20/30] Train Loss: 0.1828, Test Loss: 0.3235, F1: 0.8623, AUC: 0.9562
Mejores resultados en la época:  12
f1-score 0.8886241810601548
AUC según el mejor F1-score 0.9569369152713929

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4686, Test Loss: 0.4215, F1: 0.8184, AUC: 0.8915
Epoch [10/30] Train Loss: 0.2319, Test Loss: 0.2750, F1: 0.8772, AUC: 0.9570
Epoch [20/30] Train Loss: 0.1849, Test Loss: 0.3356, F1: 0.8730, AUC: 0.9600
Mejores resultados en la época:  27
f1-score 0.8899855560905152
AUC según el mejor F1-score 0.9598512275310229

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4648, Test Loss: 0.4186, F1: 0.8085, AUC: 0.8925
Epoch [10/30] Train Loss: 0.2320, Test Loss: 0.2873, F1: 0.8775, AUC: 0.9512
Epoch [20/30] Train Loss: 0.1944, Test Loss: 0.3273, F1: 0.8790, AUC: 0.9520
Mejores resultados en la época:  26
f1-score 0.8822452715070165
AUC según el mejor F1-score 0.9514837517746079

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4689, Test Loss: 0.4172, F1: 0.7940, AUC: 0.8930
Epoch [10/30] Train Loss: 0.2310, Test Loss: 0.2768, F1: 0.8778, AUC: 0.9555
Epoch [20/30] Train Loss: 0.1837, Test Loss: 0.2889, F1: 0.8777, AUC: 0.9570
Mejores resultados en la época:  23
f1-score 0.8876459143968871
AUC según el mejor F1-score 0.9569022970774801

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4639, Test Loss: 0.4313, F1: 0.7771, AUC: 0.8923
Epoch [10/30] Train Loss: 0.2205, Test Loss: 0.3036, F1: 0.8744, AUC: 0.9509
Epoch [20/30] Train Loss: 0.1778, Test Loss: 0.3391, F1: 0.8567, AUC: 0.9526
Mejores resultados en la época:  24
f1-score 0.8819753086419753
AUC según el mejor F1-score 0.9530011171468661
Epoch [0/30] Train Loss: 0.4563, Test Loss: 0.4125, F1: 0.7086, AUC: 0.9065
Epoch [10/30] Train Loss: 0.2251, Test Loss: 0.2317, F1: 0.8111, AUC: 0.9548
Epoch [20/30] Train Loss: 0.1877, Test Loss: 0.2231, F1: 0.8165, AUC: 0.9580
Mejores resultados en la época:  16
f1-score 0.8178075634274773
AUC según el mejor F1-score 0.9578918047914651
Confusion matrix Test saved: outputs_without_artist/6/tfidf/cm_mlp_1.png

========================================
Entrenando red 6 con capas [5020, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4614, Test Loss: 0.3735, F1: 0.8261, AUC: 0.9211
Epoch [10/30] Train Loss: 0.2084, Test Loss: 0.2771, F1: 0.8828, AUC: 0.9549
Epoch [20/30] Train Loss: 0.1345, Test Loss: 0.3061, F1: 0.8931, AUC: 0.9604
Mejores resultados en la época:  14
f1-score 0.894476006285507
AUC según el mejor F1-score 0.9593694895607986

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4676, Test Loss: 0.4148, F1: 0.7928, AUC: 0.9138
Epoch [10/30] Train Loss: 0.2190, Test Loss: 0.2565, F1: 0.8924, AUC: 0.9606
Epoch [20/30] Train Loss: 0.1380, Test Loss: 0.3172, F1: 0.8956, AUC: 0.9629
Mejores resultados en la época:  28
f1-score 0.8998897193971327
AUC según el mejor F1-score 0.9664782788932456

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4676, Test Loss: 0.4351, F1: 0.7738, AUC: 0.9011
Epoch [10/30] Train Loss: 0.2144, Test Loss: 0.2910, F1: 0.8809, AUC: 0.9534
Epoch [20/30] Train Loss: 0.1382, Test Loss: 0.3252, F1: 0.8905, AUC: 0.9583
Mejores resultados en la época:  24
f1-score 0.8938561133504336
AUC según el mejor F1-score 0.9583596238206838

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4486, Test Loss: 0.3900, F1: 0.8378, AUC: 0.9173
Epoch [10/30] Train Loss: 0.2188, Test Loss: 0.2787, F1: 0.8858, AUC: 0.9575
Epoch [20/30] Train Loss: 0.1370, Test Loss: 0.2996, F1: 0.8873, AUC: 0.9596
Mejores resultados en la época:  23
f1-score 0.8915722030556925
AUC según el mejor F1-score 0.9610002338541989

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4482, Test Loss: 0.3823, F1: 0.8210, AUC: 0.9149
Epoch [10/30] Train Loss: 0.2097, Test Loss: 0.3061, F1: 0.8743, AUC: 0.9538
Epoch [20/30] Train Loss: 0.1470, Test Loss: 0.3624, F1: 0.8810, AUC: 0.9585
Mejores resultados en la época:  25
f1-score 0.8899684236094243
AUC según el mejor F1-score 0.9576868884806616
Epoch [0/30] Train Loss: 0.4487, Test Loss: 0.3088, F1: 0.7327, AUC: 0.9101
Epoch [10/30] Train Loss: 0.2114, Test Loss: 0.4102, F1: 0.6838, AUC: 0.9510
Epoch [20/30] Train Loss: 0.1387, Test Loss: 0.3112, F1: 0.7914, AUC: 0.9643
Mejores resultados en la época:  27
f1-score 0.8398277071020736
AUC según el mejor F1-score 0.9659534495300109
Confusion matrix Test saved: outputs_without_artist/6/tfidf/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}}}
Saved on: outputs_without_artist/6/tfidf

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037}
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:42:39] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:45:27] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:48:15] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:51:02] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:53:49] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [11:56:43] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 48, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/6/tfidf/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 48, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.55      0.69     16465
           1       0.38      0.89      0.54      5160

    accuracy                           0.63     21625
   macro avg       0.66      0.72      0.62     21625
weighted avg       0.81      0.63      0.66     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/6/tfidf/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 48, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.86      0.89     16465
           1       0.64      0.80      0.71      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.83      0.80     21625
weighted avg       0.86      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/6/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 48, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.86      0.89     16465
           1       0.63      0.77      0.70      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.82      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/6/tfidf/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 48, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.85      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.87     21625
weighted avg       0.90      0.90      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/6/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003}
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     16465
           1       0.69      0.81      0.75      5160

    accuracy                           0.87     21625
   macro avg       0.81      0.85      0.83     21625
weighted avg       0.88      0.87      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/6/tfidf/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/6/tfidf/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}
Logistic Regression: {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}
Naive Bayes: {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}
Decision Tree: {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_6.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
Random Forest: {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}
SVM: {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}, 'Logistic Regression': {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}, 'SVM': {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}, 'Decision Tree': {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}, 'Random Forest': {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}, 'XGBoost': {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}, 'Naive Bayes': {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}}}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 320)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 320)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [320, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4454, Test Loss: 0.3928, F1: 0.8199, AUC: 0.9068
Epoch [10/30] Train Loss: 0.3268, Test Loss: 0.3243, F1: 0.8600, AUC: 0.9347
Epoch [20/30] Train Loss: 0.3001, Test Loss: 0.3403, F1: 0.8424, AUC: 0.9411
Mejores resultados en la época:  27
f1-score 0.8659585230146687
AUC según el mejor F1-score 0.9429081527740221

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4613, Test Loss: 0.3995, F1: 0.8193, AUC: 0.9004
Epoch [10/30] Train Loss: 0.3307, Test Loss: 0.3322, F1: 0.8535, AUC: 0.9326
Epoch [20/30] Train Loss: 0.3037, Test Loss: 0.3162, F1: 0.8651, AUC: 0.9402
Mejores resultados en la época:  29
f1-score 0.8677171124954196
AUC según el mejor F1-score 0.9425177566421039

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4441, Test Loss: 0.4094, F1: 0.8212, AUC: 0.8965
Epoch [10/30] Train Loss: 0.3185, Test Loss: 0.3437, F1: 0.8567, AUC: 0.9312
Epoch [20/30] Train Loss: 0.2937, Test Loss: 0.3162, F1: 0.8651, AUC: 0.9383
Mejores resultados en la época:  22
f1-score 0.8665367754505602
AUC según el mejor F1-score 0.9372642365336369

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4746, Test Loss: 0.4022, F1: 0.8118, AUC: 0.9021
Epoch [10/30] Train Loss: 0.3323, Test Loss: 0.3426, F1: 0.8469, AUC: 0.9305
Epoch [20/30] Train Loss: 0.3080, Test Loss: 0.3155, F1: 0.8640, AUC: 0.9389
Mejores resultados en la época:  27
f1-score 0.8700322234156821
AUC según el mejor F1-score 0.9415781260859192

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4625, Test Loss: 0.4034, F1: 0.8172, AUC: 0.8976
Epoch [10/30] Train Loss: 0.3251, Test Loss: 0.3477, F1: 0.8446, AUC: 0.9263
Epoch [20/30] Train Loss: 0.3003, Test Loss: 0.3293, F1: 0.8558, AUC: 0.9342
Mejores resultados en la época:  28
f1-score 0.8586516026034631
AUC según el mejor F1-score 0.9363589042099392
Epoch [0/30] Train Loss: 0.4571, Test Loss: 0.4185, F1: 0.7016, AUC: 0.9048
Epoch [10/30] Train Loss: 0.3221, Test Loss: 0.3552, F1: 0.7360, AUC: 0.9340
Epoch [20/30] Train Loss: 0.3009, Test Loss: 0.4202, F1: 0.7041, AUC: 0.9405
Mejores resultados en la época:  22
f1-score 0.787448421456674
AUC según el mejor F1-score 0.9414246275279722
Confusion matrix Test saved: outputs_without_artist/6/lyrics_bert/cm_mlp_1.png

========================================
Entrenando red 6 con capas [320, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4411, Test Loss: 0.4285, F1: 0.8156, AUC: 0.9137
Epoch [10/30] Train Loss: 0.2961, Test Loss: 0.3140, F1: 0.8639, AUC: 0.9408
Epoch [20/30] Train Loss: 0.2416, Test Loss: 0.2924, F1: 0.8777, AUC: 0.9486
Mejores resultados en la época:  29
f1-score 0.8818294190358468
AUC según el mejor F1-score 0.9510440609789075

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4373, Test Loss: 0.4578, F1: 0.7692, AUC: 0.9076
Epoch [10/30] Train Loss: 0.2952, Test Loss: 0.3235, F1: 0.8525, AUC: 0.9420
Epoch [20/30] Train Loss: 0.2450, Test Loss: 0.3462, F1: 0.8218, AUC: 0.9456
Mejores resultados en la época:  24
f1-score 0.8803398058252427
AUC según el mejor F1-score 0.9505932201997327

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4438, Test Loss: 0.3998, F1: 0.8275, AUC: 0.9053
Epoch [10/30] Train Loss: 0.2936, Test Loss: 0.3245, F1: 0.8558, AUC: 0.9354
Epoch [20/30] Train Loss: 0.2409, Test Loss: 0.3040, F1: 0.8696, AUC: 0.9466
Mejores resultados en la época:  28
f1-score 0.8761072685353719
AUC según el mejor F1-score 0.9493172806434409

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4463, Test Loss: 0.3898, F1: 0.8364, AUC: 0.9135
Epoch [10/30] Train Loss: 0.2918, Test Loss: 0.3167, F1: 0.8588, AUC: 0.9462
Epoch [20/30] Train Loss: 0.2395, Test Loss: 0.2994, F1: 0.8772, AUC: 0.9469
Mejores resultados en la época:  26
f1-score 0.8851293367659678
AUC según el mejor F1-score 0.9521311490036308

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4386, Test Loss: 0.3976, F1: 0.8161, AUC: 0.9032
Epoch [10/30] Train Loss: 0.2949, Test Loss: 0.3304, F1: 0.8476, AUC: 0.9352
Epoch [20/30] Train Loss: 0.2393, Test Loss: 0.3178, F1: 0.8651, AUC: 0.9411
Mejores resultados en la época:  28
f1-score 0.8731039585645579
AUC según el mejor F1-score 0.9462235716579981
Epoch [0/30] Train Loss: 0.4364, Test Loss: 0.3305, F1: 0.7367, AUC: 0.9133
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
Epoch [10/30] Train Loss: 0.2872, Test Loss: 0.2727, F1: 0.7746, AUC: 0.9447
Epoch [20/30] Train Loss: 0.2344, Test Loss: 0.3207, F1: 0.7624, AUC: 0.9491
Mejores resultados en la época:  18
f1-score 0.8055446323240267
AUC según el mejor F1-score 0.9517768781323785
Confusion matrix Test saved: outputs_without_artist/6/lyrics_bert/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}, 'Logistic Regression': {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}, 'SVM': {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}, 'Decision Tree': {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}, 'Random Forest': {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}, 'XGBoost': {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}, 'Naive Bayes': {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8673, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.876, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8564, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8658, 'f1_cv_std': 0.0038, 'params': 10305, 'accuracy_test': 0.8976, 'precision_test': 0.7799, 'recall_test': 0.7952, 'f1_score_test': 0.7874}, 'MLP_1028097': {'accuracy_cv_mean': 0.8806, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.889, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8699, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.8793, 'f1_cv_std': 0.0042, 'params': 1028097, 'accuracy_test': 0.9085, 'precision_test': 0.8174, 'recall_test': 0.794, 'f1_score_test': 0.8055}}}
Saved on: outputs_without_artist/6/lyrics_bert

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 48, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.87      0.90     16465
           1       0.67      0.83      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 48, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.86      0.59      0.70     16465
           1       0.35      0.71      0.47      5160

    accuracy                           0.62     21625
   macro avg       0.61      0.65      0.58     21625
weighted avg       0.74      0.62      0.64     21625

Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 48, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.83      0.87     16465
           1       0.58      0.74      0.65      5160

    accuracy                           0.81     21625
   macro avg       0.75      0.79      0.76     21625
weighted avg       0.83      0.81      0.82     21625

Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 48, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.90      0.92     16465
           1       0.72      0.81      0.76      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:22:20] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:22:52] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:23:24] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:23:55] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:24:27] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:24:59] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 48, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.74      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075, 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.74      0.83     16465
           1       0.50      0.81      0.62      5160

    accuracy                           0.76     21625
   macro avg       0.71      0.78      0.72     21625
weighted avg       0.82      0.76      0.78     21625

Confusion matrix Test saved as: outputs_without_artist/6/lyrics_bert/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/6/lyrics_bert/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8928, 'precision_test': 0.7356, 'recall_test': 0.8599, 'f1_score_test': 0.7929}
Random Forest: {'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8775, 'precision_test': 0.7161, 'recall_test': 0.8066, 'f1_score_test': 0.7587}
Logistic Regression: {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8601, 'precision_test': 0.6653, 'recall_test': 0.8326, 'f1_score_test': 0.7396}
Decision Tree: {'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067, 'accuracy_test': 0.811, 'precision_test': 0.5817, 'recall_test': 0.7393, 'f1_score_test': 0.6511}
Naive Bayes: {'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075, 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053, 'accuracy_test': 0.7605, 'precision_test': 0.4989, 'recall_test': 0.8105, 'f1_score_test': 0.6176}
SVM: {'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174, 'accuracy_test': 0.6161, 'precision_test': 0.3493, 'recall_test': 0.7056, 'f1_score_test': 0.4673}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}, 'Logistic Regression': {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}, 'SVM': {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}, 'Decision Tree': {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}, 'Random Forest': {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}, 'XGBoost': {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}, 'Naive Bayes': {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8673, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.876, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8564, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8658, 'f1_cv_std': 0.0038, 'params': 10305, 'accuracy_test': 0.8976, 'precision_test': 0.7799, 'recall_test': 0.7952, 'f1_score_test': 0.7874}, 'MLP_1028097': {'accuracy_cv_mean': 0.8806, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.889, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8699, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.8793, 'f1_cv_std': 0.0042, 'params': 1028097, 'accuracy_test': 0.9085, 'precision_test': 0.8174, 'recall_test': 0.794, 'f1_score_test': 0.8055}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8601, 'precision_test': 0.6653, 'recall_test': 0.8326, 'f1_score_test': 0.7396}, 'SVM': {'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174, 'accuracy_test': 0.6161, 'precision_test': 0.3493, 'recall_test': 0.7056, 'f1_score_test': 0.4673}, 'Decision Tree': {'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067, 'accuracy_test': 0.811, 'precision_test': 0.5817, 'recall_test': 0.7393, 'f1_score_test': 0.6511}, 'Random Forest': {'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8775, 'precision_test': 0.7161, 'recall_test': 0.8066, 'f1_score_test': 0.7587}, 'XGBoost': {'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8928, 'precision_test': 0.7356, 'recall_test': 0.8599, 'f1_score_test': 0.7929}, 'Naive Bayes': {'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075,/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_6.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053, 'accuracy_test': 0.7605, 'precision_test': 0.4989, 'recall_test': 0.8105, 'f1_score_test': 0.6176}}}

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
E eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El último valor de eliminar es:  98849
Shape original y: (108138,)
Shape filtrado  y: (108125,)
Label distribution: {0: 82336, 1: 25802}
X shape: (108125, 1536)
y shape: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 1556)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 1556)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [1556, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4241, Test Loss: 0.4046, F1: 0.8391, AUC: 0.9166
Epoch [10/30] Train Loss: 0.3351, Test Loss: 0.3243, F1: 0.8610, AUC: 0.9350
Epoch [20/30] Train Loss: 0.3138, Test Loss: 0.3398, F1: 0.8592, AUC: 0.9382
Mejores resultados en la época:  21
f1-score 0.8710432319251139
AUC según el mejor F1-score 0.9404300982888648

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4305, Test Loss: 0.3754, F1: 0.8294, AUC: 0.9139
Epoch [10/30] Train Loss: 0.3311, Test Loss: 0.3367, F1: 0.8473, AUC: 0.9333
Epoch [20/30] Train Loss: 0.3120, Test Loss: 0.3440, F1: 0.8424, AUC: 0.9369
Mejores resultados en la época:  25
f1-score 0.8695143358689292
AUC según el mejor F1-score 0.939124816670798

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4127, Test Loss: 0.3994, F1: 0.8004, AUC: 0.9108
Epoch [10/30] Train Loss: 0.3266, Test Loss: 0.3343, F1: 0.8521, AUC: 0.9323
Epoch [20/30] Train Loss: 0.3079, Test Loss: 0.3220, F1: 0.8610, AUC: 0.9369
Mejores resultados en la época:  26
f1-score 0.868189388532001
AUC según el mejor F1-score 0.9392269563878373

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4259, Test Loss: 0.3855, F1: 0.8389, AUC: 0.9133
Epoch [10/30] Train Loss: 0.3264, Test Loss: 0.3294, F1: 0.8661, AUC: 0.9349
Epoch [20/30] Train Loss: 0.3055, Test Loss: 0.3595, F1: 0.8585, AUC: 0.9366
Mejores resultados en la época:  23
f1-score 0.8730769230769231
AUC según el mejor F1-score 0.9404228252968257

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4355, Test Loss: 0.3933, F1: 0.8057, AUC: 0.9087
Epoch [10/30] Train Loss: 0.3250, Test Loss: 0.3391, F1: 0.8465, AUC: 0.9311
Epoch [20/30] Train Loss: 0.3052, Test Loss: 0.3454, F1: 0.8604, AUC: 0.9362
Mejores resultados en la época:  18
f1-score 0.8615158564956532
AUC según el mejor F1-score 0.9361942553575153
Epoch [0/30] Train Loss: 0.4159, Test Loss: 0.3082, F1: 0.7310, AUC: 0.9173
Epoch [10/30] Train Loss: 0.3239, Test Loss: 0.2993, F1: 0.7622, AUC: 0.9361
Epoch [20/30] Train Loss: 0.3058, Test Loss: 0.2742, F1: 0.7761, AUC: 0.9403
Mejores resultados en la época:  29
f1-score 0.779685393258427
AUC según el mejor F1-score 0.9434503127376136
Confusion matrix Test saved: outputs_without_artist/6/gpt/cm_mlp_1.png

========================================
Entrenando red 6 con capas [1556, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4262, Test Loss: 0.3791, F1: 0.8439, AUC: 0.9195
Epoch [10/30] Train Loss: 0.3169, Test Loss: 0.3106, F1: 0.8638, AUC: 0.9406
Epoch [20/30] Train Loss: 0.2800, Test Loss: 0.3017, F1: 0.8773, AUC: 0.9465
Mejores resultados en la época:  29
f1-score 0.8825851011346818
AUC según el mejor F1-score 0.9490214833186859

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4172, Test Loss: 0.3636, F1: 0.8352, AUC: 0.9199
Epoch [10/30] Train Loss: 0.3165, Test Loss: 0.3388, F1: 0.8393, AUC: 0.9354
Epoch [20/30] Train Loss: 0.2834, Test Loss: 0.3118, F1: 0.8555, AUC: 0.9446
Mejores resultados en la época:  26
f1-score 0.8783973758200563
AUC según el mejor F1-score 0.9480985874496726

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4283, Test Loss: 0.4020, F1: 0.8308, AUC: 0.9158
Epoch [10/30] Train Loss: 0.3131, Test Loss: 0.3261, F1: 0.8562, AUC: 0.9370
Epoch [20/30] Train Loss: 0.2798, Test Loss: 0.3163, F1: 0.8671, AUC: 0.9426
Mejores resultados en la época:  29
f1-score 0.8792635430190016
AUC según el mejor F1-score 0.9470218804928339

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4274, Test Loss: 0.4021, F1: 0.8094, AUC: 0.9141
Epoch [10/30] Train Loss: 0.3132, Test Loss: 0.3242, F1: 0.8672, AUC: 0.9378
Epoch [20/30] Train Loss: 0.2795, Test Loss: 0.3376, F1: 0.8499, AUC: 0.9443
Mejores resultados en la época:  29
f1-score 0.8806734992679356
AUC según el mejor F1-score 0.9466082805987418

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4220, Test Loss: 0.3788, F1: 0.8290, AUC: 0.9136
Epoch [10/30] Train Loss: 0.3146, Test Loss: 0.3310, F1: 0.8562, AUC: 0.9344
Epoch [20/30] Train Loss: 0.2774, Test Loss: 0.3344, F1: 0.8526, AUC: 0.9356
Mejores resultados en la época:  24
f1-score 0.8686307655155759
AUC según el mejor F1-score 0.9397304783398417
Epoch [0/30] Train Loss: 0.4151, Test Loss: 0.3114, F1: 0.7363, AUC: 0.9203
Epoch [10/30] Train Loss: 0.3125, Test Loss: 0.3725, F1: 0.7211, AUC: 0.9417
Epoch [20/30] Train Loss: 0.2772, Test Loss: 0.3401, F1: 0.7575, AUC: 0.9462
Mejores resultados en la época:  29
f1-score 0.8052188396409734
AUC según el mejor F1-score 0.9508098456439192
Confusion matrix Test saved: outputs_without_artist/6/gpt/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}, 'Logistic Regression': {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}, 'SVM': {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}, 'Decision Tree': {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}, 'Random Forest': {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}, 'XGBoost': {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}, 'Naive Bayes': {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8673, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.876, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8564, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8658, 'f1_cv_std': 0.0038, 'params': 10305, 'accuracy_test': 0.8976, 'precision_test': 0.7799, 'recall_test': 0.7952, 'f1_score_test': 0.7874}, 'MLP_1028097': {'accuracy_cv_mean': 0.8806, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.889, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8699, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.8793, 'f1_cv_std': 0.0042, 'params': 1028097, 'accuracy_test': 0.9085, 'precision_test': 0.8174, 'recall_test': 0.794, 'f1_score_test': 0.8055}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8601, 'precision_test': 0.6653, 'recall_test': 0.8326, 'f1_score_test': 0.7396}, 'SVM': {'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174, 'accuracy_test': 0.6161, 'precision_test': 0.3493, 'recall_test': 0.7056, 'f1_score_test': 0.4673}, 'Decision Tree': {'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067, 'accuracy_test': 0.811, 'precision_test': 0.5817, 'recall_test': 0.7393, 'f1_score_test': 0.6511}, 'Random Forest': {'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8775, 'precision_test': 0.7161, 'recall_test': 0.8066, 'f1_score_test': 0.7587}, 'XGBoost': {'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8928, 'precision_test': 0.7356, 'recall_test': 0.8599, 'f1_score_test': 0.7929}, 'Naive Bayes': {'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075,/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:17:47] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:20:35] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:23:23] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:26:10] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:28:59] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:31:52] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053, 'accuracy_test': 0.7605, 'precision_test': 0.4989, 'recall_test': 0.8105, 'f1_score_test': 0.6176}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0154, 'recall_cv_mean': 0.8746, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8687, 'f1_cv_std': 0.0039, 'params': 49857, 'accuracy_test': 0.8867, 'precision_test': 0.7271, 'recall_test': 0.8405, 'f1_score_test': 0.7797}, 'MLP_2293761': {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8719, 'precision_cv_std': 0.0183, 'recall_cv_mean': 0.8846, 'recall_cv_std': 0.0171, 'f1_cv_mean': 0.8779, 'f1_cv_std': 0.0049, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7705, 'recall_test': 0.8432, 'f1_score_test': 0.8052}}}
Saved on: outputs_without_artist/6/gpt

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8514, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8573, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8433, 'recall_cv_std': 0.0072, 'f1_cv_mean': 0.8502, 'f1_cv_std': 0.0046}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 48, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.86      0.90     16465
           1       0.66      0.85      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/6/gpt/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7009, 'accuracy_cv_std': 0.0238, 'precision_cv_mean': 0.6685, 'precision_cv_std': 0.0321, 'recall_cv_mean': 0.8053, 'recall_cv_std': 0.0215, 'f1_cv_mean': 0.7296, 'f1_cv_std': 0.0111}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 48, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.89      0.64      0.74     16465
           1       0.40      0.76      0.52      5160

    accuracy                           0.67     21625
   macro avg       0.65      0.70      0.63     21625
weighted avg       0.78      0.67      0.69     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/6/gpt/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7788, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.7839, 'precision_cv_std': 0.0105, 'recall_cv_mean': 0.7703, 'recall_cv_std': 0.0113, 'f1_cv_mean': 0.7769, 'f1_cv_std': 0.0061}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 48, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.79      0.85     16465
           1       0.54      0.79      0.64      5160

    accuracy                           0.79     21625
   macro avg       0.73      0.79      0.75     21625
weighted avg       0.83      0.79      0.80     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/6/gpt/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8203, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8597, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7655, 'recall_cv_std': 0.0074, 'f1_cv_mean': 0.8099, 'f1_cv_std': 0.0052}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 48, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.87      0.90     16465
           1       0.65      0.78      0.71      5160

    accuracy                           0.85     21625
   macro avg       0.79      0.82      0.80     21625
weighted avg       0.86      0.85      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/6/gpt/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8656, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8854, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8399, 'recall_cv_std': 0.0032, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0025}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 48, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.78      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/6/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8002, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8588, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.005}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.88      0.90     16465
           1       0.66      0.73      0.69      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.81      0.79     21625
weighted avg       0.85      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/6/gpt/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/6/gpt/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8656, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8854, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8399, 'recall_cv_std': 0.0032, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8825, 'precision_test': 0.7132, 'recall_test': 0.8492, 'f1_score_test': 0.7753}
Logistic Regression: {'accuracy_cv_mean': 0.8514, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8573, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8433, 'recall_cv_std': 0.0072, 'f1_cv_mean': 0.8502, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8577, 'precision_test': 0.6559, 'recall_test': 0.8492, 'f1_score_test': 0.7401}
Random Forest: {'accuracy_cv_mean': 0.8203, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8597, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7655, 'recall_cv_std': 0.0074, 'f1_cv_mean': 0.8099, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8471, 'precision_test': 0.6505, 'recall_test': 0.7764, 'f1_score_test': 0.7079}
Naive Bayes: {'accuracy_cv_mean': 0.8002, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8588, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.005, 'accuracy_test': 0.8441, 'precision_test': 0.6551, 'recall_test': 0.7318, 'f1_score_test': 0.6913}
Decision Tree: {'accuracy_cv_mean': 0.7788, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.7839, 'precision_cv_std': 0.0105, 'recall_cv_mean': 0.7703, 'recall_cv_std': 0.0113, 'f1_cv_mean': 0.7769, 'f1_cv_std': 0.0061, 'accuracy_test': 0.7917, 'precision_test': 0.5435, 'recall_test': 0.7922, 'f1_score_test': 0.6447}
SVM: {'accuracy_cv_mean': 0.7009, 'accuracy_cv_std': 0.0238, 'precision_cv_mean': 0.6685, 'precision_cv_std': 0.0321, 'recall_cv_mean': 0.8053, 'recall_cv_std': 0.0215, 'f1_cv_mean': 0.7296, 'f1_cv_std': 0.0111, 'accuracy_test': 0.6671, 'precision_test': 0.3969, 'recall_test': 0.761, 'f1_score_test': 0.5218}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}, 'MLP_5840897': {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}, 'Logistic Regression': {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}, 'SVM': {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}, 'Decision Tree': {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}, 'Random Forest': {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}, 'XGBoost': {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}, 'Naive Bayes': {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8673, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.876, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8564, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8658, 'f1_cv_std': 0.0038, 'params': 10305, 'accuracy_test': 0.8976, 'precision_test': 0.7799, 'recall_test': 0.7952, 'f1_score_test': 0.7874}, 'MLP_1028097': {'accuracy_cv_mean': 0.8806, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.889, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8699, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.8793, 'f1_cv_std': 0.0042, 'params': 1028097, 'accuracy_test': 0.9085, 'precision_test': 0.8174, 'recall_test': 0.794, 'f1_score_test': 0.8055}, 'Logistic Regression': {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8601, 'precision_test': 0.6653, 'recall_test': 0.8326, 'f1_score_test': 0.7396}, 'SVM': {'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174, 'accuracy_test': 0.6161, 'precision_test': 0.3493, 'recall_test': 0.7056, 'f1_score_test': 0.4673}, 'Decision Tree': {'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067, 'accuracy_test': 0.811, 'precision_test': 0.5817, 'recall_test': 0.7393, 'f1_score_test': 0.6511}, 'Random Forest': {'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8775, 'precision_test': 0.7161, 'recall_test': 0.8066, 'f1_score_test': 0.7587}, 'XGBoost': {'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8928, 'precision_test': 0.7356, 'recall_test': 0.8599, 'f1_score_test': 0.7929}, 'Naive Bayes': {'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075, 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053, 'accuracy_test': 0.7605, 'precision_test': 0.4989, 'recall_test': 0.8105, 'f1_score_test': 0.6176}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0154, 'recall_cv_mean': 0.8746, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8687, 'f1_cv_std': 0.0039, 'params': 49857, 'accuracy_test': 0.8867, 'precision_test': 0.7271, 'recall_test': 0.8405, 'f1_score_test': 0.7797}, 'MLP_2293761': {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8719, 'precision_cv_std': 0.0183, 'recall_cv_mean': 0.8846, 'recall_cv_std': 0.0171, 'f1_cv_mean': 0.8779, 'f1_cv_std': 0.0049, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7705, 'recall_test': 0.8432, 'f1_score_test': 0.8052}, 'Logistic Regression': {'accuracy_cv_mean': 0.8514, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8573, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8433, 'recall_cv_std': 0.0072, 'f1_cv_mean': 0.8502, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8577, 'precision_test': 0.6559, 'recall_test': 0.8492, 'f1_score_test': 0.7401}, 'SVM': {'accuracy_cv_mean': 0.7009, 'accuracy_cv_std': 0.0238, 'precision_cv_mean': 0.6685, 'precision_cv_std': 0.0321, 'recall_cv_mean': 0.8053, 'recall_cv_std': 0.0215, 'f1_cv_mean': 0.7296, 'f1_cv_std': 0.0111, 'accuracy_test': 0.6671, 'precision_test': 0.3969, 'recall_test': 0.761, 'f1_score_test': 0.5218}, 'Decision Tree': {'accuracy_cv_mean': 0.7788, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.7839, 'precision_cv_std': 0.0105, 'recall_cv_mean': 0.7703, 'recall_cv_std': 0.0113, 'f1_cv_mean': 0.7769, 'f1_cv_std': 0.0061, 'accuracy_test': 0.7917, 'precision_test': 0.5435, 'recall_test': 0.7922, 'f1_score_test': 0.6447}, 'Random Forest': {'accuracy_cv_mean': 0.8203, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8597, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7655, 'recall_cv_std': 0.0074, 'f1_cv_mean': 0.8099, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8471, 'precision_test': 0.6505, 'recall_test': 0.7764, 'f1_score_test': 0.7079}, 'XGBoost': {'accuracy_cv_mean': 0.8656, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8854, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8399, 'recall_cv_std': 0.0032, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8825, 'precision_test': 0.7132, 'recall_test': 0.8492, 'f1_score_test': 0.7753}, 'Naive Bayes': {'accuracy_cv_mean': 0.8002, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8588, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.005, 'accuracy_test': 0.8441, 'precision_test': 0.6551, 'recall_test': 0.7318, 'f1_score_test': 0.6913}}}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_5840897: {'accuracy_cv_mean': 0.8947, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.9008, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8873, 'recall_cv_std': 0.0063, 'f1_cv_mean': 0.894, 'f1_cv_std': 0.0034, 'params': 5840897, 'accuracy_test': 0.9261, 'precision_test': 0.8692, 'recall_test': 0.8124, 'f1_score_test': 0.8398}
MLP_160705: {'accuracy_cv_mean': 0.8863, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8875, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8849, 'recall_cv_std': 0.0136, 'f1_cv_mean': 0.8861, 'f1_cv_std': 0.0033, 'params': 160705, 'accuracy_test': 0.912, 'precision_test': 0.8081, 'recall_test': 0.8277, 'f1_score_test': 0.8178}
XGBoost: {'accuracy_cv_mean': 0.8771, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.9006, 'precision_cv_std': 0.0025, 'recall_cv_mean': 0.8477, 'recall_cv_std': 0.0054, 'f1_cv_mean': 0.8733, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8977, 'precision_test': 0.751, 'recall_test': 0.8545, 'f1_score_test': 0.7994}
Logistic Regression: {'accuracy_cv_mean': 0.8785, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.8597, 'recall_cv_std': 0.0049, 'f1_cv_mean': 0.8761, 'f1_cv_std': 0.0037, 'accuracy_test': 0.8898, 'precision_test': 0.7258, 'recall_test': 0.8645, 'f1_score_test': 0.7891}
Naive Bayes: {'accuracy_cv_mean': 0.8453, 'accuracy_cv_std': 0.0027, 'precision_cv_mean': 0.872, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8095, 'recall_cv_std': 0.0059, 'f1_cv_mean': 0.8396, 'f1_cv_std': 0.003, 'accuracy_test': 0.8671, 'precision_test': 0.6872, 'recall_test': 0.8136, 'f1_score_test': 0.7451}
Decision Tree: {'accuracy_cv_mean': 0.8257, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.8751, 'precision_cv_std': 0.0196, 'recall_cv_mean': 0.7613, 'recall_cv_std': 0.0288, 'f1_cv_mean': 0.8135, 'f1_cv_std': 0.0085, 'accuracy_test': 0.8428, 'precision_test': 0.6364, 'recall_test': 0.7963, 'f1_score_test': 0.7074}
Random Forest: {'accuracy_cv_mean': 0.8125, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8454, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.7649, 'recall_cv_std': 0.0061, 'f1_cv_mean': 0.8031, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8397, 'precision_test': 0.635, 'recall_test': 0.7723, 'f1_score_test': 0.6969}
SVM: {'accuracy_cv_mean': 0.7213, 'accuracy_cv_std': 0.0166, 'precision_cv_mean': 0.6842, 'precision_cv_std': 0.0141, 'recall_cv_mean': 0.8228, 'recall_cv_std': 0.0376, 'f1_cv_mean': 0.7467, 'f1_cv_std': 0.0182, 'accuracy_test': 0.6313, 'precision_test': 0.3831, 'recall_test': 0.8928, 'f1_score_test': 0.5361}


EMBEDDINGS TYPE: LYRICS_BERT
MLP_1028097: {'accuracy_cv_mean': 0.8806, 'accuracy_cv_std': 0.0043, 'precision_cv_mean': 0.889, 'precision_cv_std': 0.0084, 'recall_cv_mean': 0.8699, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.8793, 'f1_cv_std': 0.0042, 'params': 1028097, 'accuracy_test': 0.9085, 'precision_test': 0.8174, 'recall_test': 0.794, 'f1_score_test': 0.8055}
XGBoost: {'accuracy_cv_mean': 0.8745, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8489, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8712, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8928, 'precision_test': 0.7356, 'recall_test': 0.8599, 'f1_score_test': 0.7929}
MLP_10305: {'accuracy_cv_mean': 0.8673, 'accuracy_cv_std': 0.0037, 'precision_cv_mean': 0.876, 'precision_cv_std': 0.0161, 'recall_cv_mean': 0.8564, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8658, 'f1_cv_std': 0.0038, 'params': 10305, 'accuracy_test': 0.8976, 'precision_test': 0.7799, 'recall_test': 0.7952, 'f1_score_test': 0.7874}
Random Forest: {'accuracy_cv_mean': 0.8489, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8869, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.7999, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8411, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8775, 'precision_test': 0.7161, 'recall_test': 0.8066, 'f1_score_test': 0.7587}
Logistic Regression: {'accuracy_cv_mean': 0.8474, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.8618, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8277, 'recall_cv_std': 0.0077, 'f1_cv_mean': 0.8444, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8601, 'precision_test': 0.6653, 'recall_test': 0.8326, 'f1_score_test': 0.7396}
Decision Tree: {'accuracy_cv_mean': 0.7861, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8185, 'precision_cv_std': 0.0034, 'recall_cv_mean': 0.7353, 'recall_cv_std': 0.0144, 'f1_cv_mean': 0.7745, 'f1_cv_std': 0.0067, 'accuracy_test': 0.811, 'precision_test': 0.5817, 'recall_test': 0.7393, 'f1_score_test': 0.6511}
Naive Bayes: {'accuracy_cv_mean': 0.7749, 'accuracy_cv_std': 0.0051, 'precision_cv_mean': 0.7597, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0075, 'f1_cv_mean': 0.7813, 'f1_cv_std': 0.0053, 'accuracy_test': 0.7605, 'precision_test': 0.4989, 'recall_test': 0.8105, 'f1_score_test': 0.6176}
SVM: {'accuracy_cv_mean': 0.6489, 'accuracy_cv_std': 0.0136, 'precision_cv_mean': 0.6325, 'precision_cv_std': 0.0211, 'recall_cv_mean': 0.7184, 'recall_cv_std': 0.0557, 'f1_cv_mean': 0.671, 'f1_cv_std': 0.0174, 'accuracy_test': 0.6161, 'precision_test': 0.3493, 'recall_test': 0.7056, 'f1_score_test': 0.4673}


EMBEDDINGS TYPE: GPT
MLP_2293761: {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0057, 'precision_cv_mean': 0.8719, 'precision_cv_std': 0.0183, 'recall_cv_mean': 0.8846, 'recall_cv_std': 0.0171, 'f1_cv_mean': 0.8779, 'f1_cv_std': 0.0049, 'params': 2293761, 'accuracy_test': 0.9027, 'precision_test': 0.7705, 'recall_test': 0.8432, 'f1_score_test': 0.8052}
MLP_49857: {'accuracy_cv_mean': 0.8678, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8634, 'precision_cv_std': 0.0154, 'recall_cv_mean': 0.8746, 'recall_cv_std': 0.0178, 'f1_cv_mean': 0.8687, 'f1_cv_std': 0.0039, 'params': 49857, 'accuracy_test': 0.8867, 'precision_test': 0.7271, 'recall_test': 0.8405, 'f1_score_test': 0.7797}
XGBoost: {'accuracy_cv_mean': 0.8656, 'accuracy_cv_std': 0.0024, 'precision_cv_mean': 0.8854, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8399, 'recall_cv_std': 0.0032, 'f1_cv_mean': 0.862, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8825, 'precision_test': 0.7132, 'recall_test': 0.8492, 'f1_score_test': 0.7753}
Logistic Regression: {'accuracy_cv_mean': 0.8514, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.8573, 'precision_cv_std': 0.0031, 'recall_cv_mean': 0.8433, 'recall_cv_std': 0.0072, 'f1_cv_mean': 0.8502, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8577, 'precision_test': 0.6559, 'recall_test': 0.8492, 'f1_score_test': 0.7401}
Random Forest: {'accuracy_cv_mean': 0.8203, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8597, 'precision_cv_std': 0.0032, 'recall_cv_mean': 0.7655, 'recall_cv_std': 0.0074, 'f1_cv_mean': 0.8099, 'f1_cv_std': 0.0052, 'accuracy_test': 0.8471, 'precision_test': 0.6505, 'recall_test': 0.7764, 'f1_score_test': 0.7079}
Naive Bayes: {'accuracy_cv_mean': 0.8002, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8588, 'precision_cv_std': 0.003, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0078, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.005, 'accuracy_test': 0.8441, 'precision_test': 0.6551, 'recall_test': 0.7318, 'f1_score_test': 0.6913}
Decision Tree: {'accuracy_cv_mean': 0.7788, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.7839, 'precision_cv_std': 0.0105, 'recall_cv_mean': 0.7703, 'recall_cv_std': 0.0113, 'f1_cv_mean': 0.7769, 'f1_cv_std': 0.0061, 'accuracy_test': 0.7917, 'precision_test': 0.5435, 'recall_test': 0.7922, 'f1_score_test': 0.6447}
SVM: {'accuracy_cv_mean': 0.7009, 'accuracy_cv_std': 0.0238, 'precision_cv_mean': 0.6685, 'precision_cv_std': 0.0321, 'recall_cv_mean': 0.8053, 'recall_cv_std': 0.0215, 'f1_cv_mean': 0.7296, 'f1_cv_std': 0.0111, 'accuracy_test': 0.6671, 'precision_test': 0.3969, 'recall_test': 0.761, 'f1_score_test': 0.5218}
Diccionario global guardado en: outputs_without_artist/6/gpt/global_metrics.json

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
====================================

