2025-09-19 02:58:01.657904: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-19 02:58:01.722885: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-19 02:58:05.741919: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_4.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'Artist(s)', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
After removing some columns that doesn't love me, for TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
After removing some columns that doesn't love me, for numeric cols you are selecteing this columns:
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 5020)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 5020)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [5020, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4580, Test Loss: 0.3948, F1: 0.8123, AUC: 0.9054
Epoch [10/30] Train Loss: 0.2293, Test Loss: 0.2800, F1: 0.8851, AUC: 0.9545
Epoch [20/30] Train Loss: 0.1826, Test Loss: 0.2865, F1: 0.8875, AUC: 0.9567
Mejores resultados en la época:  20
f1-score 0.8875459177627681
AUC según el mejor F1-score 0.9566849843289916

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4666, Test Loss: 0.4266, F1: 0.7803, AUC: 0.8934
Epoch [10/30] Train Loss: 0.2327, Test Loss: 0.2788, F1: 0.8828, AUC: 0.9559
Epoch [20/30] Train Loss: 0.2003, Test Loss: 0.2739, F1: 0.8867, AUC: 0.9577
Mejores resultados en la época:  20
f1-score 0.8867229288006656
AUC según el mejor F1-score 0.957669205107115

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4632, Test Loss: 0.4075, F1: 0.8094, AUC: 0.9004
Epoch [10/30] Train Loss: 0.2259, Test Loss: 0.3500, F1: 0.8574, AUC: 0.9500
Epoch [20/30] Train Loss: 0.1919, Test Loss: 0.3096, F1: 0.8743, AUC: 0.9537
Mejores resultados en la época:  27
f1-score 0.8836477987421384
AUC según el mejor F1-score 0.9545736469319

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4718, Test Loss: 0.4360, F1: 0.8208, AUC: 0.8908
Epoch [10/30] Train Loss: 0.2340, Test Loss: 0.3024, F1: 0.8625, AUC: 0.9530
Epoch [20/30] Train Loss: 0.1914, Test Loss: 0.3366, F1: 0.8507, AUC: 0.9551
Mejores resultados en la época:  29
f1-score 0.8829305135951662
AUC según el mejor F1-score 0.9564275448784052

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4727, Test Loss: 0.4208, F1: 0.8012, AUC: 0.8895
Epoch [10/30] Train Loss: 0.2340, Test Loss: 0.3185, F1: 0.8694, AUC: 0.9519
Epoch [20/30] Train Loss: 0.1956, Test Loss: 0.2900, F1: 0.8821, AUC: 0.9528
Mejores resultados en la época:  21
f1-score 0.8831541218637993
AUC según el mejor F1-score 0.95231854346401
Epoch [0/30] Train Loss: 0.4461, Test Loss: 0.3516, F1: 0.7417, AUC: 0.9122
Epoch [10/30] Train Loss: 0.2286, Test Loss: 0.2346, F1: 0.8106, AUC: 0.9576
Epoch [20/30] Train Loss: 0.1883, Test Loss: 0.2208, F1: 0.8176, AUC: 0.9589
Mejores resultados en la época:  28
f1-score 0.8251484588556885
AUC según el mejor F1-score 0.9618249481517054
Confusion matrix Test saved: outputs_without_artist/4/tfidf/cm_mlp_1.png

========================================
Entrenando red 6 con capas [5020, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4681, Test Loss: 0.4201, F1: 0.8025, AUC: 0.9095
Epoch [10/30] Train Loss: 0.2117, Test Loss: 0.2915, F1: 0.8801, AUC: 0.9573
Epoch [20/30] Train Loss: 0.1373, Test Loss: 0.3235, F1: 0.8893, AUC: 0.9614
Mejores resultados en la época:  28
f1-score 0.8924642138885602
AUC según el mejor F1-score 0.9630761255145424

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4548, Test Loss: 0.4095, F1: 0.8257, AUC: 0.9119
Epoch [10/30] Train Loss: 0.2255, Test Loss: 0.3126, F1: 0.8784, AUC: 0.9580
Epoch [20/30] Train Loss: 0.1356, Test Loss: 0.3468, F1: 0.8845, AUC: 0.9562
Mejores resultados en la época:  18
f1-score 0.8934627528943984
AUC según el mejor F1-score 0.9617105166174659

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4608, Test Loss: 0.4117, F1: 0.7765, AUC: 0.9120
Epoch [10/30] Train Loss: 0.2102, Test Loss: 0.2990, F1: 0.8789, AUC: 0.9561
Epoch [20/30] Train Loss: 0.1346, Test Loss: 0.2614, F1: 0.8901, AUC: 0.9594
Mejores resultados en la época:  23
f1-score 0.8911404917830223
AUC según el mejor F1-score 0.9587496091637372

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4555, Test Loss: 0.3852, F1: 0.8210, AUC: 0.9128
Epoch [10/30] Train Loss: 0.2090, Test Loss: 0.3107, F1: 0.8780, AUC: 0.9523
Epoch [20/30] Train Loss: 0.1331, Test Loss: 0.3041, F1: 0.8924, AUC: 0.9595
Mejores resultados en la época:  25
f1-score 0.8960019622271278
AUC según el mejor F1-score 0.9615968731627419

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4613, Test Loss: 0.3793, F1: 0.8239, AUC: 0.9101
Epoch [10/30] Train Loss: 0.2007, Test Loss: 0.3281, F1: 0.8611, AUC: 0.9558
Epoch [20/30] Train Loss: 0.1310, Test Loss: 0.5724, F1: 0.8229, AUC: 0.9577
Mejores resultados en la época:  23
f1-score 0.8991678903573177
AUC según el mejor F1-score 0.9634509483773901
Epoch [0/30] Train Loss: 0.4437, Test Loss: 0.2888, F1: 0.7574, AUC: 0.9268
Epoch [10/30] Train Loss: 0.2140, Test Loss: 0.2230, F1: 0.8064, AUC: 0.9551
Epoch [20/30] Train Loss: 0.1440, Test Loss: 0.4061, F1: 0.7502, AUC: 0.9634
Mejores resultados en la época:  21
f1-score 0.8337108342770857
AUC según el mejor F1-score 0.964991890244046
Confusion matrix Test saved: outputs_without_artist/4/tfidf/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}}}
Saved on: outputs_without_artist/4/tfidf

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024}
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:43:46] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:46:34] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:49:22] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:52:09] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:54:55] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:57:49] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 46, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/4/tfidf/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 46, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.90      0.75      0.82     16465
           1       0.49      0.74      0.59      5160

    accuracy                           0.75     21625
   macro avg       0.69      0.75      0.70     21625
weighted avg       0.80      0.75      0.77     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/4/tfidf/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 46, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.89      0.91     16465
           1       0.69      0.76      0.72      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.83      0.81     21625
weighted avg       0.87      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/4/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 46, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.89     16465
           1       0.64      0.76      0.70      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.81      0.80     21625
weighted avg       0.85      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/4/tfidf/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 46, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.91      0.93     16465
           1       0.75      0.86      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.87     21625
weighted avg       0.90      0.90      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/4/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029}
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.89      0.91     16465
           1       0.69      0.81      0.75      5160

    accuracy                           0.87     21625
   macro avg       0.81      0.85      0.83     21625
weighted avg       0.88      0.87      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/4/tfidf/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/4/tfidf/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}
Logistic Regression: {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}
Naive Bayes: {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}
Decision Tree: {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_4.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
Random Forest: {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}
SVM: {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}, 'Logistic Regression': {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}, 'SVM': {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}, 'Decision Tree': {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}, 'Random Forest': {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}, 'XGBoost': {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}}}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 320)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 320)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [320, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4658, Test Loss: 0.4006, F1: 0.8130, AUC: 0.9037
Epoch [10/30] Train Loss: 0.3259, Test Loss: 0.3231, F1: 0.8591, AUC: 0.9356
Epoch [20/30] Train Loss: 0.3013, Test Loss: 0.3272, F1: 0.8614, AUC: 0.9407
Mejores resultados en la época:  29
f1-score 0.8684729064039409
AUC según el mejor F1-score 0.9421163865790818

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4424, Test Loss: 0.4063, F1: 0.8042, AUC: 0.9034
Epoch [10/30] Train Loss: 0.3189, Test Loss: 0.3282, F1: 0.8595, AUC: 0.9343
Epoch [20/30] Train Loss: 0.2894, Test Loss: 0.3116, F1: 0.8664, AUC: 0.9409
Mejores resultados en la época:  28
f1-score 0.869939089931924
AUC según el mejor F1-score 0.942246078492128

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4630, Test Loss: 0.4132, F1: 0.8264, AUC: 0.8991
Epoch [10/30] Train Loss: 0.3257, Test Loss: 0.3270, F1: 0.8572, AUC: 0.9344
Epoch [20/30] Train Loss: 0.2975, Test Loss: 0.3104, F1: 0.8655, AUC: 0.9406
Mejores resultados en la época:  28
f1-score 0.8701762744163888
AUC según el mejor F1-score 0.9437066969852322

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4341, Test Loss: 0.4095, F1: 0.8029, AUC: 0.9028
Epoch [10/30] Train Loss: 0.3195, Test Loss: 0.3241, F1: 0.8610, AUC: 0.9356
Epoch [20/30] Train Loss: 0.2869, Test Loss: 0.3074, F1: 0.8721, AUC: 0.9427
Mejores resultados en la época:  20
f1-score 0.8721168940949161
AUC según el mejor F1-score 0.9426832984899969

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4520, Test Loss: 0.3997, F1: 0.8248, AUC: 0.8987
Epoch [10/30] Train Loss: 0.3190, Test Loss: 0.3342, F1: 0.8538, AUC: 0.9306
Epoch [20/30] Train Loss: 0.2935, Test Loss: 0.3192, F1: 0.8588, AUC: 0.9368
Mejores resultados en la época:  28
f1-score 0.865478515625
AUC según el mejor F1-score 0.9395548235480848
Epoch [0/30] Train Loss: 0.4615, Test Loss: 0.4548, F1: 0.6758, AUC: 0.9033
Epoch [10/30] Train Loss: 0.3245, Test Loss: 0.2857, F1: 0.7715, AUC: 0.9336
Epoch [20/30] Train Loss: 0.3019, Test Loss: 0.3021, F1: 0.7672, AUC: 0.9413
Mejores resultados en la época:  28
f1-score 0.7906200941915228
AUC según el mejor F1-score 0.9430586021087718
Confusion matrix Test saved: outputs_without_artist/4/lyrics_bert/cm_mlp_1.png

========================================
Entrenando red 6 con capas [320, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4432, Test Loss: 0.3763, F1: 0.8294, AUC: 0.9128
Epoch [10/30] Train Loss: 0.2929, Test Loss: 0.3145, F1: 0.8625, AUC: 0.9386
Epoch [20/30] Train Loss: 0.2405, Test Loss: 0.2966, F1: 0.8803, AUC: 0.9478
Mejores resultados en la época:  22
f1-score 0.8861798430899216
AUC según el mejor F1-score 0.9515558158783277

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4392, Test Loss: 0.4008, F1: 0.8264, AUC: 0.9069
Epoch [10/30] Train Loss: 0.2906, Test Loss: 0.3096, F1: 0.8644, AUC: 0.9433
Epoch [20/30] Train Loss: 0.2346, Test Loss: 0.3142, F1: 0.8810, AUC: 0.9506
Mejores resultados en la época:  20
f1-score 0.8810296846011132
AUC según el mejor F1-score 0.9506064828116549

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4473, Test Loss: 0.4230, F1: 0.8186, AUC: 0.9065
Epoch [10/30] Train Loss: 0.2890, Test Loss: 0.3099, F1: 0.8647, AUC: 0.9407
Epoch [20/30] Train Loss: 0.2300, Test Loss: 0.3076, F1: 0.8662, AUC: 0.9489
Mejores resultados en la época:  26
f1-score 0.8779859484777518
AUC según el mejor F1-score 0.9482089136019469

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4445, Test Loss: 0.3976, F1: 0.8199, AUC: 0.9017
Epoch [10/30] Train Loss: 0.2890, Test Loss: 0.3112, F1: 0.8642, AUC: 0.9405
Epoch [20/30] Train Loss: 0.2372, Test Loss: 0.2988, F1: 0.8706, AUC: 0.9461
Mejores resultados en la época:  23
f1-score 0.8781542898341744
AUC según el mejor F1-score 0.9483682623693843

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4395, Test Loss: 0.3914, F1: 0.8332, AUC: 0.9083
Epoch [10/30] Train Loss: 0.2911, Test Loss: 0.3347, F1: 0.8570, AUC: 0.9384
Epoch [20/30] Train Loss: 0.2348, Test Loss: 0.3309, F1: 0.8619, AUC: 0.9443
Mejores resultados en la época:  28
f1-score 0.8777467524584194
AUC según el mejor F1-score 0.9482356334631271
Epoch [0/30] Train Loss: 0.4313, Test Loss: 0.4656, F1: 0.6742, AUC: 0.9126
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
Epoch [10/30] Train Loss: 0.2878, Test Loss: 0.2993, F1: 0.7616, AUC: 0.9408
Epoch [20/30] Train Loss: 0.2300, Test Loss: 0.3015, F1: 0.7766, AUC: 0.9505
Mejores resultados en la época:  23
f1-score 0.8130876269274163
AUC según el mejor F1-score 0.9531415240691434
Confusion matrix Test saved: outputs_without_artist/4/lyrics_bert/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}, 'Logistic Regression': {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}, 'SVM': {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}, 'Decision Tree': {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}, 'Random Forest': {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}, 'XGBoost': {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.869, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8677, 'precision_cv_std': 0.01, 'recall_cv_mean': 0.871, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8692, 'f1_cv_std': 0.0022, 'params': 10305, 'accuracy_test': 0.9013, 'precision_test': 0.8007, 'recall_test': 0.7808, 'f1_score_test': 0.7906}, 'MLP_1028097': {'accuracy_cv_mean': 0.8781, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8657, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.8958, 'recall_cv_std': 0.0162, 'f1_cv_mean': 0.8802, 'f1_cv_std': 0.0032, 'params': 1028097, 'accuracy_test': 0.9081, 'precision_test': 0.7896, 'recall_test': 0.838, 'f1_score_test': 0.8131}}}
Saved on: outputs_without_artist/4/lyrics_bert

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 46, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.87      0.90     16465
           1       0.66      0.82      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.87      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 46, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.86      0.61      0.72     16465
           1       0.36      0.68      0.47      5160

    accuracy                           0.63     21625
   macro avg       0.61      0.65      0.59     21625
weighted avg       0.74      0.63      0.66     21625

Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 46, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.84      0.88     16465
           1       0.60      0.75      0.66      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625

Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 46, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.93      0.90      0.91     16465
           1       0.71      0.80      0.75      5160

    accuracy                           0.87     21625
   macro avg       0.82      0.85      0.83     21625
weighted avg       0.88      0.87      0.88     21625

/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:23:49] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:21] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:52] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:23] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:54] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:26:26] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 46, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.85      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0029}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.75      0.82     16465
           1       0.50      0.80      0.61      5160

    accuracy                           0.76     21625
   macro avg       0.71      0.77      0.72     21625
weighted avg       0.82      0.76      0.77     21625

Confusion matrix Test saved as: outputs_without_artist/4/lyrics_bert/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/4/lyrics_bert/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8901, 'precision_test': 0.7322, 'recall_test': 0.8506, 'f1_score_test': 0.787}
Random Forest: {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8726, 'precision_test': 0.7058, 'recall_test': 0.7992, 'f1_score_test': 0.7496}
Logistic Regression: {'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8583, 'precision_test': 0.6636, 'recall_test': 0.8236, 'f1_score_test': 0.735}
Decision Tree: {'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019, 'accuracy_test': 0.8199, 'precision_test': 0.598, 'recall_test': 0.7484, 'f1_score_test': 0.6648}
Naive Bayes: {'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0029, 'accuracy_test': 0.7589, 'precision_test': 0.4968, 'recall_test': 0.8006, 'f1_score_test': 0.6131}
SVM: {'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143, 'accuracy_test': 0.6307, 'precision_test': 0.3568, 'recall_test': 0.6826, 'f1_score_test': 0.4686}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}, 'Logistic Regression': {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}, 'SVM': {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}, 'Decision Tree': {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}, 'Random Forest': {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}, 'XGBoost': {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.869, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8677, 'precision_cv_std': 0.01, 'recall_cv_mean': 0.871, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8692, 'f1_cv_std': 0.0022, 'params': 10305, 'accuracy_test': 0.9013, 'precision_test': 0.8007, 'recall_test': 0.7808, 'f1_score_test': 0.7906}, 'MLP_1028097': {'accuracy_cv_mean': 0.8781, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8657, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.8958, 'recall_cv_std': 0.0162, 'f1_cv_mean': 0.8802, 'f1_cv_std': 0.0032, 'params': 1028097, 'accuracy_test': 0.9081, 'precision_test': 0.7896, 'recall_test': 0.838, 'f1_score_test': 0.8131}, 'Logistic Regression': {'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8583, 'precision_test': 0.6636, 'recall_test': 0.8236, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143, 'accuracy_test': 0.6307, 'precision_test': 0.3568, 'recall_test': 0.6826, 'f1_score_test': 0.4686}, 'Decision Tree': {'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019, 'accuracy_test': 0.8199, 'precision_test': 0.598, 'recall_test': 0.7484, 'f1_score_test': 0.6648}, 'Random Forest': {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8726, 'precision_test': 0.7058, 'recall_test': 0.7992, 'f1_score_test': 0.7496}, 'XGBoost': {'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8901, 'precision_test': 0.7322, 'recall_test': 0.8506, 'f1_score_test': 0.787}, 'Naive Bayes': {'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_m/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_4.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
ean': 0.7833, 'f1_cv_std': 0.0029, 'accuracy_test': 0.7589, 'precision_test': 0.4968, 'recall_test': 0.8006, 'f1_score_test': 0.6131}}}

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
E eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El último valor de eliminar es:  98849
Shape original y: (108138,)
Shape filtrado  y: (108125,)
Label distribution: {0: 82336, 1: 25802}
X shape: (108125, 1536)
y shape: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 1556)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 1556)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [1556, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4201, Test Loss: 0.3747, F1: 0.8352, AUC: 0.9151
Epoch [10/30] Train Loss: 0.3265, Test Loss: 0.3246, F1: 0.8588, AUC: 0.9355
Epoch [20/30] Train Loss: 0.3039, Test Loss: 0.3181, F1: 0.8575, AUC: 0.9402
Mejores resultados en la época:  29
f1-score 0.8679817905918058
AUC según el mejor F1-score 0.9399410248031969

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4188, Test Loss: 0.3698, F1: 0.8385, AUC: 0.9166
Epoch [10/30] Train Loss: 0.3256, Test Loss: 0.3366, F1: 0.8622, AUC: 0.9350
Epoch [20/30] Train Loss: 0.3066, Test Loss: 0.3175, F1: 0.8640, AUC: 0.9388
Mejores resultados en la época:  19
f1-score 0.8689855775057569
AUC según el mejor F1-score 0.939015722885118

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4297, Test Loss: 0.4030, F1: 0.8331, AUC: 0.9142
Epoch [10/30] Train Loss: 0.3262, Test Loss: 0.3319, F1: 0.8464, AUC: 0.9361
Epoch [20/30] Train Loss: 0.3056, Test Loss: 0.3332, F1: 0.8644, AUC: 0.9408
Mejores resultados en la época:  24
f1-score 0.8710293766419871
AUC según el mejor F1-score 0.9416287215123791

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4130, Test Loss: 0.3978, F1: 0.8070, AUC: 0.9093
Epoch [10/30] Train Loss: 0.3258, Test Loss: 0.3341, F1: 0.8540, AUC: 0.9312
Epoch [20/30] Train Loss: 0.3111, Test Loss: 0.3267, F1: 0.8617, AUC: 0.9359
Mejores resultados en la época:  28
f1-score 0.8648840511121628
AUC según el mejor F1-score 0.9373402818083972

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4220, Test Loss: 0.3766, F1: 0.8260, AUC: 0.9124
Epoch [10/30] Train Loss: 0.3260, Test Loss: 0.3382, F1: 0.8468, AUC: 0.9323
Epoch [20/30] Train Loss: 0.3070, Test Loss: 0.3344, F1: 0.8529, AUC: 0.9323
Mejores resultados en la época:  29
f1-score 0.8659190638712823
AUC según el mejor F1-score 0.938784818683166
Epoch [0/30] Train Loss: 0.4144, Test Loss: 0.3436, F1: 0.7283, AUC: 0.9155
Epoch [10/30] Train Loss: 0.3217, Test Loss: 0.2947, F1: 0.7653, AUC: 0.9366
Epoch [20/30] Train Loss: 0.3043, Test Loss: 0.3178, F1: 0.7593, AUC: 0.9390
Mejores resultados en la época:  29
f1-score 0.7866116812122375
AUC según el mejor F1-score 0.9394760968180096
Confusion matrix Test saved: outputs_without_artist/4/gpt/cm_mlp_1.png

========================================
Entrenando red 6 con capas [1556, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4284, Test Loss: 0.3706, F1: 0.8217, AUC: 0.9171
Epoch [10/30] Train Loss: 0.3143, Test Loss: 0.3236, F1: 0.8491, AUC: 0.9401
Epoch [20/30] Train Loss: 0.2824, Test Loss: 0.3077, F1: 0.8661, AUC: 0.9461
Mejores resultados en la época:  29
f1-score 0.881447078953801
AUC según el mejor F1-score 0.9502334571803077

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4223, Test Loss: 0.3692, F1: 0.8260, AUC: 0.9173
Epoch [10/30] Train Loss: 0.3162, Test Loss: 0.3282, F1: 0.8520, AUC: 0.9393
Epoch [20/30] Train Loss: 0.2849, Test Loss: 0.3122, F1: 0.8737, AUC: 0.9460
Mejores resultados en la época:  20
f1-score 0.8737113402061856
AUC según el mejor F1-score 0.9459918860983415

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4268, Test Loss: 0.3608, F1: 0.8313, AUC: 0.9195
Epoch [10/30] Train Loss: 0.3169, Test Loss: 0.3169, F1: 0.8603, AUC: 0.9403
Epoch [20/30] Train Loss: 0.2791, Test Loss: 0.2963, F1: 0.8762, AUC: 0.9462
Mejores resultados en la época:  29
f1-score 0.8812241923730872
AUC según el mejor F1-score 0.9481441263295474

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4229, Test Loss: 0.4763, F1: 0.7981, AUC: 0.9077
Epoch [10/30] Train Loss: 0.3150, Test Loss: 0.3278, F1: 0.8609, AUC: 0.9364
Epoch [20/30] Train Loss: 0.2825, Test Loss: 0.3201, F1: 0.8611, AUC: 0.9398
Mejores resultados en la época:  27
f1-score 0.8741673731379436
AUC según el mejor F1-score 0.9440270209604739

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4215, Test Loss: 0.4038, F1: 0.8271, AUC: 0.9158
Epoch [10/30] Train Loss: 0.3153, Test Loss: 0.3232, F1: 0.8598, AUC: 0.9366
Epoch [20/30] Train Loss: 0.2782, Test Loss: 0.3154, F1: 0.8677, AUC: 0.9399
Mejores resultados en la época:  29
f1-score 0.8786853552440793
AUC según el mejor F1-score 0.9454039666931513
Epoch [0/30] Train Loss: 0.4133, Test Loss: 0.4365, F1: 0.6988, AUC: 0.9210
Epoch [10/30] Train Loss: 0.3122, Test Loss: 0.3204, F1: 0.7640, AUC: 0.9396
Epoch [20/30] Train Loss: 0.2790, Test Loss: 0.3317, F1: 0.7628, AUC: 0.9437
Mejores resultados en la época:  24
f1-score 0.8011347517730496
AUC según el mejor F1-score 0.9474822621157871
Confusion matrix Test saved: outputs_without_artist/4/gpt/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}, 'Logistic Regression': {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}, 'SVM': {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}, 'Decision Tree': {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}, 'Random Forest': {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}, 'XGBoost': {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.869, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8677, 'precision_cv_std': 0.01, 'recall_cv_mean': 0.871, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8692, 'f1_cv_std': 0.0022, 'params': 10305, 'accuracy_test': 0.9013, 'precision_test': 0.8007, 'recall_test': 0.7808, 'f1_score_test': 0.7906}, 'MLP_1028097': {'accuracy_cv_mean': 0.8781, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8657, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.8958, 'recall_cv_std': 0.0162, 'f1_cv_mean': 0.8802, 'f1_cv_std': 0.0032, 'params': 1028097, 'accuracy_test': 0.9081, 'precision_test': 0.7896, 'recall_test': 0.838, 'f1_score_test': 0.8131}, 'Logistic Regression': {'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8583, 'precision_test': 0.6636, 'recall_test': 0.8236, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143, 'accuracy_test': 0.6307, 'precision_test': 0.3568, 'recall_test': 0.6826, 'f1_score_test': 0.4686}, 'Decision Tree': {'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019, 'accuracy_test': 0.8199, 'precision_test': 0.598, 'recall_test': 0.7484, 'f1_score_test': 0.6648}, 'Random Forest': {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8726, 'precision_test': 0.7058, 'recall_test': 0.7992, 'f1_score_test': 0.7496}, 'XGBoost': {'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8901, 'precision_test': 0.7322, 'recall_test': 0.8506, 'f1_score_test': 0.787}, 'Naive Bayes': {'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_m/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:19:32] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:22:18] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:25:00] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:27:45] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:30:31] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:33:21] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
ean': 0.7833, 'f1_cv_std': 0.0029, 'accuracy_test': 0.7589, 'precision_test': 0.4968, 'recall_test': 0.8006, 'f1_score_test': 0.6131}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8659, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8565, 'precision_cv_std': 0.0133, 'recall_cv_mean': 0.8797, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0022, 'params': 49857, 'accuracy_test': 0.8971, 'precision_test': 0.7786, 'recall_test': 0.7948, 'f1_score_test': 0.7866}, 'MLP_2293761': {'accuracy_cv_mean': 0.8772, 'accuracy_cv_std': 0.0049, 'precision_cv_mean': 0.8739, 'precision_cv_std': 0.015, 'recall_cv_mean': 0.8822, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.8778, 'f1_cv_std': 0.0033, 'params': 2293761, 'accuracy_test': 0.9028, 'precision_test': 0.7823, 'recall_test': 0.8209, 'f1_score_test': 0.8011}}}
Saved on: outputs_without_artist/4/gpt

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8513, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8584, 'precision_cv_std': 0.0018, 'recall_cv_mean': 0.8415, 'recall_cv_std': 0.0065, 'f1_cv_mean': 0.8498, 'f1_cv_std': 0.0032}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 46, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.86      0.90     16465
           1       0.66      0.85      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/4/gpt/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7218, 'accuracy_cv_std': 0.0093, 'precision_cv_mean': 0.6986, 'precision_cv_std': 0.0168, 'recall_cv_mean': 0.783, 'recall_cv_std': 0.0413, 'f1_cv_mean': 0.7375, 'f1_cv_std': 0.0133}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 46, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.90      0.58      0.70     16465
           1       0.37      0.79      0.51      5160

    accuracy                           0.63     21625
   macro avg       0.64      0.69      0.61     21625
weighted avg       0.77      0.63      0.66     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/4/gpt/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7848, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.7921, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7725, 'recall_cv_std': 0.0087, 'f1_cv_mean': 0.7821, 'f1_cv_std': 0.0046}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 46, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.81      0.86     16465
           1       0.56      0.77      0.65      5160

    accuracy                           0.80     21625
   macro avg       0.74      0.79      0.76     21625
weighted avg       0.84      0.80      0.81     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/4/gpt/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8189, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8574, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.765, 'recall_cv_std': 0.0062, 'f1_cv_mean': 0.8085, 'f1_cv_std': 0.0047}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 46, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.89     16465
           1       0.65      0.77      0.70      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.82      0.80     21625
weighted avg       0.86      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/4/gpt/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8654, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8386, 'recall_cv_std': 0.0033, 'f1_cv_mean': 0.8616, 'f1_cv_std': 0.0023}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 46, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.77      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.88     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/4/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8589, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.0046}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.88      0.89     16465
           1       0.65      0.73      0.68      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.80      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/4/gpt/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/4/gpt/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8654, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8386, 'recall_cv_std': 0.0033, 'f1_cv_mean': 0.8616, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8809, 'precision_test': 0.7099, 'recall_test': 0.8471, 'f1_score_test': 0.7725}
Logistic Regression: {'accuracy_cv_mean': 0.8513, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8584, 'precision_cv_std': 0.0018, 'recall_cv_mean': 0.8415, 'recall_cv_std': 0.0065, 'f1_cv_mean': 0.8498, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8576, 'precision_test': 0.6555, 'recall_test': 0.8494, 'f1_score_test': 0.74}
Random Forest: {'accuracy_cv_mean': 0.8189, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8574, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.765, 'recall_cv_std': 0.0062, 'f1_cv_mean': 0.8085, 'f1_cv_std': 0.0047, 'accuracy_test': 0.8445, 'precision_test': 0.6461, 'recall_test': 0.7703, 'f1_score_test': 0.7028}
Naive Bayes: {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8589, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.0046, 'accuracy_test': 0.84, 'precision_test': 0.6467, 'recall_test': 0.7267, 'f1_score_test': 0.6844}
Decision Tree: {'accuracy_cv_mean': 0.7848, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.7921, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7725, 'recall_cv_std': 0.0087, 'f1_cv_mean': 0.7821, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8034, 'precision_test': 0.5641, 'recall_test': 0.7748, 'f1_score_test': 0.6528}
SVM: {'accuracy_cv_mean': 0.7218, 'accuracy_cv_std': 0.0093, 'precision_cv_mean': 0.6986, 'precision_cv_std': 0.0168, 'recall_cv_mean': 0.783, 'recall_cv_std': 0.0413, 'f1_cv_mean': 0.7375, 'f1_cv_std': 0.0133, 'accuracy_test': 0.6305, 'precision_test': 0.3716, 'recall_test': 0.794, 'f1_score_test': 0.5063}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}, 'MLP_5840897': {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}, 'Logistic Regression': {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}, 'SVM': {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}, 'Decision Tree': {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}, 'Random Forest': {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}, 'XGBoost': {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}, 'Naive Bayes': {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.869, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8677, 'precision_cv_std': 0.01, 'recall_cv_mean': 0.871, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8692, 'f1_cv_std': 0.0022, 'params': 10305, 'accuracy_test': 0.9013, 'precision_test': 0.8007, 'recall_test': 0.7808, 'f1_score_test': 0.7906}, 'MLP_1028097': {'accuracy_cv_mean': 0.8781, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8657, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.8958, 'recall_cv_std': 0.0162, 'f1_cv_mean': 0.8802, 'f1_cv_std': 0.0032, 'params': 1028097, 'accuracy_test': 0.9081, 'precision_test': 0.7896, 'recall_test': 0.838, 'f1_score_test': 0.8131}, 'Logistic Regression': {'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8583, 'precision_test': 0.6636, 'recall_test': 0.8236, 'f1_score_test': 0.735}, 'SVM': {'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143, 'accuracy_test': 0.6307, 'precision_test': 0.3568, 'recall_test': 0.6826, 'f1_score_test': 0.4686}, 'Decision Tree': {'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019, 'accuracy_test': 0.8199, 'precision_test': 0.598, 'recall_test': 0.7484, 'f1_score_test': 0.6648}, 'Random Forest': {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8726, 'precision_test': 0.7058, 'recall_test': 0.7992, 'f1_score_test': 0.7496}, 'XGBoost': {'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8901, 'precision_test': 0.7322, 'recall_test': 0.8506, 'f1_score_test': 0.787}, 'Naive Bayes': {'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0029, 'accuracy_test': 0.7589, 'precision_test': 0.4968, 'recall_test': 0.8006, 'f1_score_test': 0.6131}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8659, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8565, 'precision_cv_std': 0.0133, 'recall_cv_mean': 0.8797, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0022, 'params': 49857, 'accuracy_test': 0.8971, 'precision_test': 0.7786, 'recall_test': 0.7948, 'f1_score_test': 0.7866}, 'MLP_2293761': {'accuracy_cv_mean': 0.8772, 'accuracy_cv_std': 0.0049, 'precision_cv_mean': 0.8739, 'precision_cv_std': 0.015, 'recall_cv_mean': 0.8822, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.8778, 'f1_cv_std': 0.0033, 'params': 2293761, 'accuracy_test': 0.9028, 'precision_test': 0.7823, 'recall_test': 0.8209, 'f1_score_test': 0.8011}, 'Logistic Regression': {'accuracy_cv_mean': 0.8513, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8584, 'precision_cv_std': 0.0018, 'recall_cv_mean': 0.8415, 'recall_cv_std': 0.0065, 'f1_cv_mean': 0.8498, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8576, 'precision_test': 0.6555, 'recall_test': 0.8494, 'f1_score_test': 0.74}, 'SVM': {'accuracy_cv_mean': 0.7218, 'accuracy_cv_std': 0.0093, 'precision_cv_mean': 0.6986, 'precision_cv_std': 0.0168, 'recall_cv_mean': 0.783, 'recall_cv_std': 0.0413, 'f1_cv_mean': 0.7375, 'f1_cv_std': 0.0133, 'accuracy_test': 0.6305, 'precision_test': 0.3716, 'recall_test': 0.794, 'f1_score_test': 0.5063}, 'Decision Tree': {'accuracy_cv_mean': 0.7848, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.7921, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7725, 'recall_cv_std': 0.0087, 'f1_cv_mean': 0.7821, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8034, 'precision_test': 0.5641, 'recall_test': 0.7748, 'f1_score_test': 0.6528}, 'Random Forest': {'accuracy_cv_mean': 0.8189, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8574, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.765, 'recall_cv_std': 0.0062, 'f1_cv_mean': 0.8085, 'f1_cv_std': 0.0047, 'accuracy_test': 0.8445, 'precision_test': 0.6461, 'recall_test': 0.7703, 'f1_score_test': 0.7028}, 'XGBoost': {'accuracy_cv_mean': 0.8654, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8386, 'recall_cv_std': 0.0033, 'f1_cv_mean': 0.8616, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8809, 'precision_test': 0.7099, 'recall_test': 0.8471, 'f1_score_test': 0.7725}, 'Naive Bayes': {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8589, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.0046, 'accuracy_test': 0.84, 'precision_test': 0.6467, 'recall_test': 0.7267, 'f1_score_test': 0.6844}}}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_5840897: {'accuracy_cv_mean': 0.8941, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8922, 'precision_cv_std': 0.02, 'recall_cv_mean': 0.8976, 'recall_cv_std': 0.0191, 'f1_cv_mean': 0.8944, 'f1_cv_std': 0.0028, 'params': 5840897, 'accuracy_test': 0.9185, 'precision_test': 0.8125, 'recall_test': 0.856, 'f1_score_test': 0.8337}
MLP_160705: {'accuracy_cv_mean': 0.8844, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8823, 'precision_cv_std': 0.0189, 'recall_cv_mean': 0.8882, 'recall_cv_std': 0.0207, 'f1_cv_mean': 0.8848, 'f1_cv_std': 0.0019, 'params': 160705, 'accuracy_test': 0.9142, 'precision_test': 0.8033, 'recall_test': 0.8483, 'f1_score_test': 0.8251}
XGBoost: {'accuracy_cv_mean': 0.8804, 'accuracy_cv_std': 0.0025, 'precision_cv_mean': 0.9051, 'precision_cv_std': 0.0049, 'recall_cv_mean': 0.85, 'recall_cv_std': 0.0045, 'f1_cv_mean': 0.8766, 'f1_cv_std': 0.0025, 'accuracy_test': 0.8985, 'precision_test': 0.7529, 'recall_test': 0.855, 'f1_score_test': 0.8007}
Logistic Regression: {'accuracy_cv_mean': 0.8777, 'accuracy_cv_std': 0.0021, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0035, 'recall_cv_mean': 0.8602, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8904, 'precision_test': 0.7272, 'recall_test': 0.8649, 'f1_score_test': 0.7901}
Naive Bayes: {'accuracy_cv_mean': 0.8475, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8729, 'precision_cv_std': 0.0071, 'recall_cv_mean': 0.8135, 'recall_cv_std': 0.008, 'f1_cv_mean': 0.8421, 'f1_cv_std': 0.0029, 'accuracy_test': 0.8689, 'precision_test': 0.6934, 'recall_test': 0.8078, 'f1_score_test': 0.7462}
Decision Tree: {'accuracy_cv_mean': 0.8266, 'accuracy_cv_std': 0.0012, 'precision_cv_mean': 0.883, 'precision_cv_std': 0.0148, 'recall_cv_mean': 0.7535, 'recall_cv_std': 0.0145, 'f1_cv_mean': 0.8129, 'f1_cv_std': 0.0024, 'accuracy_test': 0.8604, 'precision_test': 0.6871, 'recall_test': 0.762, 'f1_score_test': 0.7226}
Random Forest: {'accuracy_cv_mean': 0.8165, 'accuracy_cv_std': 0.0032, 'precision_cv_mean': 0.8523, 'precision_cv_std': 0.005, 'recall_cv_mean': 0.7657, 'recall_cv_std': 0.0028, 'f1_cv_mean': 0.8067, 'f1_cv_std': 0.0031, 'accuracy_test': 0.8423, 'precision_test': 0.6438, 'recall_test': 0.7593, 'f1_score_test': 0.6968}
SVM: {'accuracy_cv_mean': 0.7399, 'accuracy_cv_std': 0.0169, 'precision_cv_mean': 0.7167, 'precision_cv_std': 0.0405, 'recall_cv_mean': 0.8045, 'recall_cv_std': 0.049, 'f1_cv_mean': 0.7556, 'f1_cv_std': 0.0103, 'accuracy_test': 0.7508, 'precision_test': 0.4853, 'recall_test': 0.7382, 'f1_score_test': 0.5856}


EMBEDDINGS TYPE: LYRICS_BERT
MLP_1028097: {'accuracy_cv_mean': 0.8781, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8657, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.8958, 'recall_cv_std': 0.0162, 'f1_cv_mean': 0.8802, 'f1_cv_std': 0.0032, 'params': 1028097, 'accuracy_test': 0.9081, 'precision_test': 0.7896, 'recall_test': 0.838, 'f1_score_test': 0.8131}
MLP_10305: {'accuracy_cv_mean': 0.869, 'accuracy_cv_std': 0.0019, 'precision_cv_mean': 0.8677, 'precision_cv_std': 0.01, 'recall_cv_mean': 0.871, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8692, 'f1_cv_std': 0.0022, 'params': 10305, 'accuracy_test': 0.9013, 'precision_test': 0.8007, 'recall_test': 0.7808, 'f1_score_test': 0.7906}
XGBoost: {'accuracy_cv_mean': 0.8754, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8947, 'precision_cv_std': 0.0053, 'recall_cv_mean': 0.8511, 'recall_cv_std': 0.0035, 'f1_cv_mean': 0.8723, 'f1_cv_std': 0.0033, 'accuracy_test': 0.8901, 'precision_test': 0.7322, 'recall_test': 0.8506, 'f1_score_test': 0.787}
Random Forest: {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8851, 'precision_cv_std': 0.0055, 'recall_cv_mean': 0.8054, 'recall_cv_std': 0.0021, 'f1_cv_mean': 0.8434, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8726, 'precision_test': 0.7058, 'recall_test': 0.7992, 'f1_score_test': 0.7496}
Logistic Regression: {'accuracy_cv_mean': 0.8484, 'accuracy_cv_std': 0.0038, 'precision_cv_mean': 0.8629, 'precision_cv_std': 0.0074, 'recall_cv_mean': 0.8284, 'recall_cv_std': 0.0022, 'f1_cv_mean': 0.8453, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8583, 'precision_test': 0.6636, 'recall_test': 0.8236, 'f1_score_test': 0.735}
Decision Tree: {'accuracy_cv_mean': 0.7889, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.811, 'precision_cv_std': 0.0086, 'recall_cv_mean': 0.7536, 'recall_cv_std': 0.0064, 'f1_cv_mean': 0.7812, 'f1_cv_std': 0.0019, 'accuracy_test': 0.8199, 'precision_test': 0.598, 'recall_test': 0.7484, 'f1_score_test': 0.6648}
Naive Bayes: {'accuracy_cv_mean': 0.7767, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.7608, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.8072, 'recall_cv_std': 0.0031, 'f1_cv_mean': 0.7833, 'f1_cv_std': 0.0029, 'accuracy_test': 0.7589, 'precision_test': 0.4968, 'recall_test': 0.8006, 'f1_score_test': 0.6131}
SVM: {'accuracy_cv_mean': 0.6338, 'accuracy_cv_std': 0.0331, 'precision_cv_mean': 0.6112, 'precision_cv_std': 0.0387, 'recall_cv_mean': 0.7564, 'recall_cv_std': 0.0342, 'f1_cv_mean': 0.6743, 'f1_cv_std': 0.0143, 'accuracy_test': 0.6307, 'precision_test': 0.3568, 'recall_test': 0.6826, 'f1_score_test': 0.4686}


EMBEDDINGS TYPE: GPT
MLP_2293761: {'accuracy_cv_mean': 0.8772, 'accuracy_cv_std': 0.0049, 'precision_cv_mean': 0.8739, 'precision_cv_std': 0.015, 'recall_cv_mean': 0.8822, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.8778, 'f1_cv_std': 0.0033, 'params': 2293761, 'accuracy_test': 0.9028, 'precision_test': 0.7823, 'recall_test': 0.8209, 'f1_score_test': 0.8011}
MLP_49857: {'accuracy_cv_mean': 0.8659, 'accuracy_cv_std': 0.0031, 'precision_cv_mean': 0.8565, 'precision_cv_std': 0.0133, 'recall_cv_mean': 0.8797, 'recall_cv_std': 0.014, 'f1_cv_mean': 0.8678, 'f1_cv_std': 0.0022, 'params': 49857, 'accuracy_test': 0.8971, 'precision_test': 0.7786, 'recall_test': 0.7948, 'f1_score_test': 0.7866}
XGBoost: {'accuracy_cv_mean': 0.8654, 'accuracy_cv_std': 0.0023, 'precision_cv_mean': 0.8861, 'precision_cv_std': 0.004, 'recall_cv_mean': 0.8386, 'recall_cv_std': 0.0033, 'f1_cv_mean': 0.8616, 'f1_cv_std': 0.0023, 'accuracy_test': 0.8809, 'precision_test': 0.7099, 'recall_test': 0.8471, 'f1_score_test': 0.7725}
Logistic Regression: {'accuracy_cv_mean': 0.8513, 'accuracy_cv_std': 0.0026, 'precision_cv_mean': 0.8584, 'precision_cv_std': 0.0018, 'recall_cv_mean': 0.8415, 'recall_cv_std': 0.0065, 'f1_cv_mean': 0.8498, 'f1_cv_std': 0.0032, 'accuracy_test': 0.8576, 'precision_test': 0.6555, 'recall_test': 0.8494, 'f1_score_test': 0.74}
Random Forest: {'accuracy_cv_mean': 0.8189, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.8574, 'precision_cv_std': 0.0039, 'recall_cv_mean': 0.765, 'recall_cv_std': 0.0062, 'f1_cv_mean': 0.8085, 'f1_cv_std': 0.0047, 'accuracy_test': 0.8445, 'precision_test': 0.6461, 'recall_test': 0.7703, 'f1_score_test': 0.7028}
Naive Bayes: {'accuracy_cv_mean': 0.8003, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8589, 'precision_cv_std': 0.0042, 'recall_cv_mean': 0.7186, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.7825, 'f1_cv_std': 0.0046, 'accuracy_test': 0.84, 'precision_test': 0.6467, 'recall_test': 0.7267, 'f1_score_test': 0.6844}
Decision Tree: {'accuracy_cv_mean': 0.7848, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.7921, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7725, 'recall_cv_std': 0.0087, 'f1_cv_mean': 0.7821, 'f1_cv_std': 0.0046, 'accuracy_test': 0.8034, 'precision_test': 0.5641, 'recall_test': 0.7748, 'f1_score_test': 0.6528}
SVM: {'accuracy_cv_mean': 0.7218, 'accuracy_cv_std': 0.0093, 'precision_cv_mean': 0.6986, 'precision_cv_std': 0.0168, 'recall_cv_mean': 0.783, 'recall_cv_std': 0.0413, 'f1_cv_mean': 0.7375, 'f1_cv_std': 0.0133, 'accuracy_test': 0.6305, 'precision_test': 0.3716, 'recall_test': 0.794, 'f1_score_test': 0.5063}
Diccionario global guardado en: outputs_without_artist/4/gpt/global_metrics.json

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
====================================

