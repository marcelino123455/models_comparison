2025-09-19 02:57:48.068836: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-19 02:57:48.133540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-19 02:57:51.723925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_2.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
For TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'Artist(s)', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
After removing some columns that doesn't love me, for TF-IDF embbedings you are selecteing this columns:
--> ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
After removing some columns that doesn't love me, for numeric cols you are selecteing this columns:
--> ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 5000), y: (108138,)
Shape filtrado  X: (108125, 5000), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 5020)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 5020)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [5020, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4716, Test Loss: 0.4213, F1: 0.7879, AUC: 0.8931
Epoch [10/30] Train Loss: 0.2311, Test Loss: 0.2793, F1: 0.8817, AUC: 0.9554
Epoch [20/30] Train Loss: 0.1838, Test Loss: 0.2724, F1: 0.8880, AUC: 0.9570
Mejores resultados en la época:  26
f1-score 0.8893642305407011
AUC según el mejor F1-score 0.9586365835417792

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4569, Test Loss: 0.5332, F1: 0.6858, AUC: 0.8972
Epoch [10/30] Train Loss: 0.2190, Test Loss: 0.2768, F1: 0.8778, AUC: 0.9542
Epoch [20/30] Train Loss: 0.1806, Test Loss: 0.2964, F1: 0.8803, AUC: 0.9542
Mejores resultados en la época:  25
f1-score 0.8856070693620627
AUC según el mejor F1-score 0.957151552453278

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4751, Test Loss: 0.4285, F1: 0.8248, AUC: 0.8958
Epoch [10/30] Train Loss: 0.2279, Test Loss: 0.2722, F1: 0.8847, AUC: 0.9551
Epoch [20/30] Train Loss: 0.1811, Test Loss: 0.2736, F1: 0.8878, AUC: 0.9575
Mejores resultados en la época:  26
f1-score 0.8896047577747491
AUC según el mejor F1-score 0.9578618944267924

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4691, Test Loss: 0.4014, F1: 0.8205, AUC: 0.9018
Epoch [10/30] Train Loss: 0.2341, Test Loss: 0.2982, F1: 0.8798, AUC: 0.9572
Epoch [20/30] Train Loss: 0.1821, Test Loss: 0.2692, F1: 0.8911, AUC: 0.9586
Mejores resultados en la época:  29
f1-score 0.8944159960985125
AUC según el mejor F1-score 0.9607528496871613

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4691, Test Loss: 0.4179, F1: 0.8135, AUC: 0.8919
Epoch [10/30] Train Loss: 0.2278, Test Loss: 0.2746, F1: 0.8789, AUC: 0.9537
Epoch [20/30] Train Loss: 0.1805, Test Loss: 0.2783, F1: 0.8888, AUC: 0.9558
Mejores resultados en la época:  20
f1-score 0.8887542413960252
AUC según el mejor F1-score 0.9557665134874705
Epoch [0/30] Train Loss: 0.4519, Test Loss: 0.3768, F1: 0.7289, AUC: 0.9111
Epoch [10/30] Train Loss: 0.2249, Test Loss: 0.3789, F1: 0.7285, AUC: 0.9560
Epoch [20/30] Train Loss: 0.1834, Test Loss: 0.2234, F1: 0.8176, AUC: 0.9588
Mejores resultados en la época:  20
f1-score 0.8176341206847088
AUC según el mejor F1-score 0.9587956365040242
Confusion matrix Test saved: outputs_without_artist/2/tfidf/cm_mlp_1.png

========================================
Entrenando red 6 con capas [5020, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4607, Test Loss: 0.3831, F1: 0.8301, AUC: 0.9131
Epoch [10/30] Train Loss: 0.2097, Test Loss: 0.2971, F1: 0.8691, AUC: 0.9554
Epoch [20/30] Train Loss: 0.1451, Test Loss: 0.3616, F1: 0.8794, AUC: 0.9592
Mejores resultados en la época:  27
f1-score 0.8998519980266404
AUC según el mejor F1-score 0.9653027185302866

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4524, Test Loss: 0.3896, F1: 0.8205, AUC: 0.9120
Epoch [10/30] Train Loss: 0.2081, Test Loss: 0.3227, F1: 0.8561, AUC: 0.9545
Epoch [20/30] Train Loss: 0.1436, Test Loss: 0.3063, F1: 0.8854, AUC: 0.9558
Mejores resultados en la época:  24
f1-score 0.894704955773658
AUC según el mejor F1-score 0.9613425378207441

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4654, Test Loss: 0.3996, F1: 0.8127, AUC: 0.9180
Epoch [10/30] Train Loss: 0.2138, Test Loss: 0.3086, F1: 0.8783, AUC: 0.9519
Epoch [20/30] Train Loss: 0.1429, Test Loss: 0.2997, F1: 0.8979, AUC: 0.9615
Mejores resultados en la época:  23
f1-score 0.8985993056386927
AUC según el mejor F1-score 0.9612772517332943

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4712, Test Loss: 0.3986, F1: 0.8380, AUC: 0.9150
Epoch [10/30] Train Loss: 0.2113, Test Loss: 0.2661, F1: 0.8931, AUC: 0.9609
Epoch [20/30] Train Loss: 0.1329, Test Loss: 0.2690, F1: 0.8929, AUC: 0.9604
Mejores resultados en la época:  19
f1-score 0.8974178403755868
AUC según el mejor F1-score 0.9624767906751344

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4663, Test Loss: 0.4813, F1: 0.7015, AUC: 0.9030
Epoch [10/30] Train Loss: 0.2166, Test Loss: 0.2767, F1: 0.8831, AUC: 0.9551
Epoch [20/30] Train Loss: 0.1473, Test Loss: 0.3505, F1: 0.8896, AUC: 0.9595
Mejores resultados en la época:  22
f1-score 0.8956076657540769
AUC según el mejor F1-score 0.962975814639085
Epoch [0/30] Train Loss: 0.4502, Test Loss: 0.3800, F1: 0.7228, AUC: 0.9239
Epoch [10/30] Train Loss: 0.2037, Test Loss: 0.3237, F1: 0.7726, AUC: 0.9588
Epoch [20/30] Train Loss: 0.1313, Test Loss: 0.2934, F1: 0.8162, AUC: 0.9652
Mejores resultados en la época:  18
f1-score 0.819834094510206
AUC según el mejor F1-score 0.9606011577294566
Confusion matrix Test saved: outputs_without_artist/2/tfidf/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}}}
Saved on: outputs_without_artist/2/tfidf

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061}
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:43:29] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:46:17] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:49:04] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:54:36] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [03:57:28] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 44, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.86      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/2/tfidf/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 44, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.67      0.77     16465
           1       0.43      0.80      0.56      5160

    accuracy                           0.70     21625
   macro avg       0.67      0.73      0.66     21625
weighted avg       0.80      0.70      0.72     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/2/tfidf/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 44, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.92      0.92     16465
           1       0.75      0.72      0.74      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.82      0.83     21625
weighted avg       0.88      0.88      0.88     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/2/tfidf/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 44, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.89     16465
           1       0.64      0.77      0.70      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.82      0.80     21625
weighted avg       0.86      0.84      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/2/tfidf/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 44, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.92      0.93     16465
           1       0.76      0.84      0.80      5160

    accuracy                           0.90     21625
   macro avg       0.85      0.88      0.87     21625
weighted avg       0.90      0.90      0.90     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/2/tfidf/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057}
Hiperparámetros: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     16465
           1       0.68      0.80      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.81      0.84      0.82     21625
weighted avg       0.87      0.86      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/2/tfidf/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/2/tfidf/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}
Logistic Regression: {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}
Naive Bayes: {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}
Decision Tree: {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}
/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_2.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
Random Forest: {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}
SVM: {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}, 'Logistic Regression': {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}, 'SVM': {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}, 'Decision Tree': {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}, 'Random Forest': {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}, 'XGBoost': {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}, 'Naive Bayes': {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}}}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)
Se eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El valor de y[0] es 108138
Shape original X: (108138, 300), y: (108138,)
Shape filtrado  X: (108125, 300), y: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 320)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 320)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [320, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4853, Test Loss: 0.4020, F1: 0.8207, AUC: 0.8969
Epoch [10/30] Train Loss: 0.3354, Test Loss: 0.3500, F1: 0.8477, AUC: 0.9279
Epoch [20/30] Train Loss: 0.3088, Test Loss: 0.3363, F1: 0.8536, AUC: 0.9343
Mejores resultados en la época:  26
f1-score 0.8599784766232214
AUC según el mejor F1-score 0.9368706714590468

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4677, Test Loss: 0.4137, F1: 0.8099, AUC: 0.8929
Epoch [10/30] Train Loss: 0.3307, Test Loss: 0.3426, F1: 0.8374, AUC: 0.9276
Epoch [20/30] Train Loss: 0.3061, Test Loss: 0.3220, F1: 0.8546, AUC: 0.9362
Mejores resultados en la época:  27
f1-score 0.8594445112420344
AUC según el mejor F1-score 0.9364886964988581

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4681, Test Loss: 0.4274, F1: 0.7855, AUC: 0.9032
Epoch [10/30] Train Loss: 0.3281, Test Loss: 0.3256, F1: 0.8581, AUC: 0.9341
Epoch [20/30] Train Loss: 0.3013, Test Loss: 0.3211, F1: 0.8627, AUC: 0.9367
Mejores resultados en la época:  29
f1-score 0.8711407795923233
AUC según el mejor F1-score 0.9428360886703022

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4630, Test Loss: 0.4014, F1: 0.8298, AUC: 0.9016
Epoch [10/30] Train Loss: 0.3325, Test Loss: 0.3366, F1: 0.8522, AUC: 0.9294
Epoch [20/30] Train Loss: 0.3011, Test Loss: 0.3143, F1: 0.8679, AUC: 0.9395
Mejores resultados en la época:  26
f1-score 0.8682227084852906
AUC según el mejor F1-score 0.9400091193745855

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4571, Test Loss: 0.4081, F1: 0.8121, AUC: 0.8975
Epoch [10/30] Train Loss: 0.3291, Test Loss: 0.3587, F1: 0.8497, AUC: 0.9322
Epoch [20/30] Train Loss: 0.3023, Test Loss: 0.3199, F1: 0.8590, AUC: 0.9368
Mejores resultados en la época:  28
f1-score 0.8679245283018868
AUC según el mejor F1-score 0.9420745086244303
Epoch [0/30] Train Loss: 0.4590, Test Loss: 0.4265, F1: 0.6981, AUC: 0.9088
Epoch [10/30] Train Loss: 0.3164, Test Loss: 0.3372, F1: 0.7506, AUC: 0.9367
Epoch [20/30] Train Loss: 0.2861, Test Loss: 0.2537, F1: 0.7958, AUC: 0.9429
Mejores resultados en la época:  20
f1-score 0.7957760124006975
AUC según el mejor F1-score 0.9428996202892205
Confusion matrix Test saved: outputs_without_artist/2/lyrics_bert/cm_mlp_1.png

========================================
Entrenando red 6 con capas [320, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4546, Test Loss: 0.3882, F1: 0.8222, AUC: 0.9042
Epoch [10/30] Train Loss: 0.2974, Test Loss: 0.3299, F1: 0.8547, AUC: 0.9380
Epoch [20/30] Train Loss: 0.2400, Test Loss: 0.3268, F1: 0.8619, AUC: 0.9430
Mejores resultados en la época:  21
f1-score 0.8722094847351273
AUC según el mejor F1-score 0.9469068302686138

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4411, Test Loss: 0.4296, F1: 0.7802, AUC: 0.9015
Epoch [10/30] Train Loss: 0.2931, Test Loss: 0.3066, F1: 0.8570, AUC: 0.9421
Epoch [20/30] Train Loss: 0.2424, Test Loss: 0.3060, F1: 0.8696, AUC: 0.9454
Mejores resultados en la época:  22
f1-score 0.8740631527214645
AUC según el mejor F1-score 0.9477801967373506

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4471, Test Loss: 0.4033, F1: 0.8371, AUC: 0.9117
Epoch [10/30] Train Loss: 0.2966, Test Loss: 0.3425, F1: 0.8258, AUC: 0.9395
Epoch [20/30] Train Loss: 0.2433, Test Loss: 0.3451, F1: 0.8678, AUC: 0.9437
Mejores resultados en la época:  28
f1-score 0.8823955566288336
AUC según el mejor F1-score 0.9494112045831831

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4476, Test Loss: 0.3926, F1: 0.8126, AUC: 0.9101
Epoch [10/30] Train Loss: 0.2945, Test Loss: 0.3140, F1: 0.8637, AUC: 0.9392
Epoch [20/30] Train Loss: 0.2445, Test Loss: 0.2918, F1: 0.8766, AUC: 0.9487
Mejores resultados en la época:  19
f1-score 0.8799043062200957
AUC según el mejor F1-score 0.949182613832523

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4432, Test Loss: 0.3796, F1: 0.8227, AUC: 0.9082
Epoch [10/30] Train Loss: 0.2897, Test Loss: 0.3137, F1: 0.8611, AUC: 0.9388
Epoch [20/30] Train Loss: 0.2378, Test Loss: 0.3124, F1: 0.8704, AUC: 0.9445
Mejores resultados en la época:  29
f1-score 0.8762812872467223
AUC según el mejor F1-score 0.9490499849262654
Epoch [0/30] Train Loss: 0.4322, Test Loss: 0.3962, F1: 0.7417, AUC: 0.9141
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
Epoch [10/30] Train Loss: 0.2855, Test Loss: 0.3225, F1: 0.7543, AUC: 0.9431
Epoch [20/30] Train Loss: 0.2305, Test Loss: 0.3210, F1: 0.7841, AUC: 0.9499
Mejores resultados en la época:  29
f1-score 0.8039233660280503
AUC según el mejor F1-score 0.9530345141326327
Confusion matrix Test saved: outputs_without_artist/2/lyrics_bert/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}, 'Logistic Regression': {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}, 'SVM': {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}, 'Decision Tree': {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}, 'Random Forest': {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}, 'XGBoost': {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}, 'Naive Bayes': {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8644, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8595, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8713, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8653, 'f1_cv_std': 0.0047, 'params': 10305, 'accuracy_test': 0.9025, 'precision_test': 0.7956, 'recall_test': 0.7959, 'f1_score_test': 0.7958}, 'MLP_1028097': {'accuracy_cv_mean': 0.8764, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8734, 'precision_cv_std': 0.0087, 'recall_cv_mean': 0.8808, 'recall_cv_std': 0.0111, 'f1_cv_mean': 0.877, 'f1_cv_std': 0.0037, 'params': 1028097, 'accuracy_test': 0.9011, 'precision_test': 0.7627, 'recall_test': 0.8498, 'f1_score_test': 0.8039}}}
Saved on: outputs_without_artist/2/lyrics_bert

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 44, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91     16465
           1       0.68      0.83      0.75      5160

    accuracy                           0.86     21625
   macro avg       0.81      0.85      0.83     21625
weighted avg       0.88      0.86      0.87     21625

Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 44, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.86      0.64      0.73     16465
           1       0.36      0.66      0.47      5160

    accuracy                           0.64     21625
   macro avg       0.61      0.65      0.60     21625
weighted avg       0.74      0.64      0.67     21625

Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 44, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.84      0.88     16465
           1       0.60      0.75      0.67      5160

    accuracy                           0.82     21625
   macro avg       0.76      0.80      0.77     21625
weighted avg       0.84      0.82      0.83     21625

Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 44, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.94      0.90      0.92     16465
           1       0.72      0.81      0.76      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.85      0.84     21625
weighted avg       0.88      0.88      0.88     21625

/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:23:28] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:23:59] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:24:29] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:01] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:25:32] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [04:26:04] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 44, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.90      0.93     16465
           1       0.73      0.85      0.79      5160

    accuracy                           0.89     21625
   macro avg       0.84      0.88      0.86     21625
weighted avg       0.90      0.89      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.7816, 'f1_cv_std': 0.0054}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.74      0.82     16465
           1       0.50      0.81      0.62      5160

    accuracy                           0.76     21625
   macro avg       0.71      0.78      0.72     21625
weighted avg       0.82      0.76      0.77     21625

Confusion matrix Test saved as: outputs_without_artist/2/lyrics_bert/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/2/lyrics_bert/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055, 'accuracy_test': 0.8907, 'precision_test': 0.7341, 'recall_test': 0.8498, 'f1_score_test': 0.7877}
Random Forest: {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074, 'accuracy_test': 0.8785, 'precision_test': 0.7191, 'recall_test': 0.8052, 'f1_score_test': 0.7597}
Logistic Regression: {'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8648, 'precision_test': 0.6772, 'recall_test': 0.8279, 'f1_score_test': 0.745}
Decision Tree: {'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009, 'accuracy_test': 0.8218, 'precision_test': 0.6019, 'recall_test': 0.7483, 'f1_score_test': 0.6671}
Naive Bayes: {'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.7816, 'f1_cv_std': 0.0054, 'accuracy_test': 0.759, 'precision_test': 0.4969, 'recall_test': 0.8076, 'f1_score_test': 0.6152}
SVM: {'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201, 'accuracy_test': 0.6435, 'precision_test': 0.3645, 'recall_test': 0.6647, 'f1_score_test': 0.4708}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}, 'Logistic Regression': {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}, 'SVM': {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}, 'Decision Tree': {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}, 'Random Forest': {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}, 'XGBoost': {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}, 'Naive Bayes': {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8644, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8595, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8713, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8653, 'f1_cv_std': 0.0047, 'params': 10305, 'accuracy_test': 0.9025, 'precision_test': 0.7956, 'recall_test': 0.7959, 'f1_score_test': 0.7958}, 'MLP_1028097': {'accuracy_cv_mean': 0.8764, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8734, 'precision_cv_std': 0.0087, 'recall_cv_mean': 0.8808, 'recall_cv_std': 0.0111, 'f1_cv_mean': 0.877, 'f1_cv_std': 0.0037, 'params': 1028097, 'accuracy_test': 0.9011, 'precision_test': 0.7627, 'recall_test': 0.8498, 'f1_score_test': 0.8039}, 'Logistic Regression': {'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8648, 'precision_test': 0.6772, 'recall_test': 0.8279, 'f1_score_test': 0.745}, 'SVM': {'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201, 'accuracy_test': 0.6435, 'precision_test': 0.3645, 'recall_test': 0.6647, 'f1_score_test': 0.4708}, 'Decision Tree': {'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009, 'accuracy_test': 0.8218, 'precision_test': 0.6019, 'recall_test': 0.7483, 'f1_score_test': 0.6671}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074, 'accuracy_test': 0.8785, 'precision_test': 0.7191, 'recall_test': 0.8052, 'f1_score_test': 0.7597}, 'XGBoost': {'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055, 'accuracy_test': 0.8907, 'precision_test': 0.7341, 'recall_test': 0.8498, 'f1_score_test': 0.7877}, 'Naive Bayes': {'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_/home/marcelino.maita/musica_ia_workshop/models_comparison/baseline_clean/No_text/main_complete_without_artist_2.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  .apply(lambda grp: grp.sample(n=n_min, random_state=RANDOM_STATE))
cv_mean': 0.7816, 'f1_cv_std': 0.0054, 'accuracy_test': 0.759, 'precision_test': 0.4969, 'recall_test': 0.8076, 'f1_score_test': 0.6152}}}

##################################################
Running experiment with GPT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
E eliminarán los siguientes indices [9681, 13382, 27808, 38450, 46753, 53015, 53018, 53102, 53137, 57281, 70666, 75102, 98849]
El último valor de eliminar es:  98849
Shape original y: (108138,)
Shape filtrado  y: (108125,)
Label distribution: {0: 82336, 1: 25802}
X shape: (108125, 1536)
y shape: (108125,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65861, 1: 20639}
Label distribution en TEST: {0: 16465, 1: 5160}


==================================================
Data antes del undersampling ...
X: (86500, 1556)
y: (86500,)
Apliying UNDERSAMPLE
20639
Label distribution: {0: 20639, 1: 20639}
X shape: (41278, 1556)
y shape: (41278,)
Comenzando trainning de MLP...

========================================
Entrenando red 1 con capas [1556, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4178, Test Loss: 0.3937, F1: 0.8328, AUC: 0.9131
Epoch [10/30] Train Loss: 0.3266, Test Loss: 0.3505, F1: 0.8355, AUC: 0.9317
Epoch [20/30] Train Loss: 0.3144, Test Loss: 0.3272, F1: 0.8627, AUC: 0.9357
Mejores resultados en la época:  22
f1-score 0.8631501291036517
AUC según el mejor F1-score 0.9363159304391263

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4184, Test Loss: 0.3878, F1: 0.8081, AUC: 0.9101
Epoch [10/30] Train Loss: 0.3274, Test Loss: 0.3726, F1: 0.8187, AUC: 0.9314
Epoch [20/30] Train Loss: 0.3064, Test Loss: 0.3226, F1: 0.8640, AUC: 0.9365
Mejores resultados en la época:  29
f1-score 0.8657613267636102
AUC según el mejor F1-score 0.9375347410011418

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4469, Test Loss: 0.3782, F1: 0.8283, AUC: 0.9120
Epoch [10/30] Train Loss: 0.3271, Test Loss: 0.3376, F1: 0.8450, AUC: 0.9341
Epoch [20/30] Train Loss: 0.3114, Test Loss: 0.3214, F1: 0.8661, AUC: 0.9378
Mejores resultados en la época:  25
f1-score 0.8713284994469707
AUC según el mejor F1-score 0.9396407674850519

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4264, Test Loss: 0.3976, F1: 0.8076, AUC: 0.9100
Epoch [10/30] Train Loss: 0.3297, Test Loss: 0.3265, F1: 0.8565, AUC: 0.9364
Epoch [20/30] Train Loss: 0.3126, Test Loss: 0.3359, F1: 0.8673, AUC: 0.9417
Mejores resultados en la época:  23
f1-score 0.871782818192502
AUC según el mejor F1-score 0.9413202936138082

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4215, Test Loss: 0.3866, F1: 0.8063, AUC: 0.9126
Epoch [10/30] Train Loss: 0.3226, Test Loss: 0.3337, F1: 0.8571, AUC: 0.9320
Epoch [20/30] Train Loss: 0.3044, Test Loss: 0.3462, F1: 0.8624, AUC: 0.9372
Mejores resultados en la época:  28
f1-score 0.8673358326278873
AUC según el mejor F1-score 0.9378463202243498
Epoch [0/30] Train Loss: 0.4225, Test Loss: 0.3990, F1: 0.7095, AUC: 0.9147
Epoch [10/30] Train Loss: 0.3235, Test Loss: 0.3137, F1: 0.7602, AUC: 0.9354
Epoch [20/30] Train Loss: 0.3052, Test Loss: 0.4099, F1: 0.7083, AUC: 0.9377
Mejores resultados en la época:  24
f1-score 0.7820035287198589
AUC según el mejor F1-score 0.9395256263580016
Confusion matrix Test saved: outputs_without_artist/2/gpt/cm_mlp_1.png

========================================
Entrenando red 6 con capas [1556, 1024, 512, 256, 128, 64, 32, 1]

--- Fold 1/5 ---
Epoch [0/30] Train Loss: 0.4222, Test Loss: 0.3670, F1: 0.8315, AUC: 0.9171
Epoch [10/30] Train Loss: 0.3191, Test Loss: 0.3294, F1: 0.8567, AUC: 0.9336
Epoch [20/30] Train Loss: 0.2816, Test Loss: 0.3293, F1: 0.8713, AUC: 0.9441
Mejores resultados en la época:  25
f1-score 0.876594700686948
AUC según el mejor F1-score 0.9460209934236224

--- Fold 2/5 ---
Epoch [0/30] Train Loss: 0.4275, Test Loss: 0.4011, F1: 0.8266, AUC: 0.9114
Epoch [10/30] Train Loss: 0.3166, Test Loss: 0.3411, F1: 0.8618, AUC: 0.9342
Epoch [20/30] Train Loss: 0.2775, Test Loss: 0.3516, F1: 0.8590, AUC: 0.9396
Mejores resultados en la época:  22
f1-score 0.8730426403276319
AUC según el mejor F1-score 0.9426262929286101

--- Fold 3/5 ---
Epoch [0/30] Train Loss: 0.4242, Test Loss: 0.3794, F1: 0.8234, AUC: 0.9162
Epoch [10/30] Train Loss: 0.3120, Test Loss: 0.3437, F1: 0.8388, AUC: 0.9384
Epoch [20/30] Train Loss: 0.2795, Test Loss: 0.3345, F1: 0.8619, AUC: 0.9384
Mejores resultados en la época:  26
f1-score 0.8781417510422871
AUC según el mejor F1-score 0.9460130123828194

--- Fold 4/5 ---
Epoch [0/30] Train Loss: 0.4322, Test Loss: 0.3713, F1: 0.8195, AUC: 0.9189
Epoch [10/30] Train Loss: 0.3195, Test Loss: 0.3242, F1: 0.8695, AUC: 0.9409
Epoch [20/30] Train Loss: 0.2845, Test Loss: 0.3223, F1: 0.8791, AUC: 0.9457
Mejores resultados en la época:  23
f1-score 0.8818878481936504
AUC según el mejor F1-score 0.9475791511937836

--- Fold 5/5 ---
Epoch [0/30] Train Loss: 0.4237, Test Loss: 0.3733, F1: 0.8326, AUC: 0.9183
Epoch [10/30] Train Loss: 0.3134, Test Loss: 0.3555, F1: 0.8558, AUC: 0.9355
Epoch [20/30] Train Loss: 0.2781, Test Loss: 0.3193, F1: 0.8693, AUC: 0.9391
Mejores resultados en la época:  27
f1-score 0.8776995585252356
AUC según el mejor F1-score 0.9448938487423528
Epoch [0/30] Train Loss: 0.4181, Test Loss: 0.3540, F1: 0.7263, AUC: 0.9185
Epoch [10/30] Train Loss: 0.3128, Test Loss: 0.2833, F1: 0.7723, AUC: 0.9393
Epoch [20/30] Train Loss: 0.2773, Test Loss: 0.3795, F1: 0.7432, AUC: 0.9458
Mejores resultados en la época:  22
f1-score 0.7942700970690793
AUC según el mejor F1-score 0.9467121530990097
Confusion matrix Test saved: outputs_without_artist/2/gpt/cm_mlp_6.png


resultados_globales con DL {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}, 'Logistic Regression': {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}, 'SVM': {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}, 'Decision Tree': {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}, 'Random Forest': {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}, 'XGBoost': {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}, 'Naive Bayes': {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8644, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8595, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8713, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8653, 'f1_cv_std': 0.0047, 'params': 10305, 'accuracy_test': 0.9025, 'precision_test': 0.7956, 'recall_test': 0.7959, 'f1_score_test': 0.7958}, 'MLP_1028097': {'accuracy_cv_mean': 0.8764, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8734, 'precision_cv_std': 0.0087, 'recall_cv_mean': 0.8808, 'recall_cv_std': 0.0111, 'f1_cv_mean': 0.877, 'f1_cv_std': 0.0037, 'params': 1028097, 'accuracy_test': 0.9011, 'precision_test': 0.7627, 'recall_test': 0.8498, 'f1_score_test': 0.8039}, 'Logistic Regression': {'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8648, 'precision_test': 0.6772, 'recall_test': 0.8279, 'f1_score_test': 0.745}, 'SVM': {'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201, 'accuracy_test': 0.6435, 'precision_test': 0.3645, 'recall_test': 0.6647, 'f1_score_test': 0.4708}, 'Decision Tree': {'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009, 'accuracy_test': 0.8218, 'precision_test': 0.6019, 'recall_test': 0.7483, 'f1_score_test': 0.6671}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074, 'accuracy_test': 0.8785, 'precision_test': 0.7191, 'recall_test': 0.8052, 'f1_score_test': 0.7597}, 'XGBoost': {'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055, 'accuracy_test': 0.8907, 'precision_test': 0.7341, 'recall_test': 0.8498, 'f1_score_test': 0.7877}, 'Naive Bayes': {'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:20:26] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:23:11] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:25:57] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:28:43] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:31:28] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/home/marcelino.maita/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [05:34:16] WARNING: /workspace/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
cv_mean': 0.7816, 'f1_cv_std': 0.0054, 'accuracy_test': 0.759, 'precision_test': 0.4969, 'recall_test': 0.8076, 'f1_score_test': 0.6152}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8676, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.8664, 'precision_cv_std': 0.0132, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.0164, 'f1_cv_mean': 0.8679, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8972, 'precision_test': 0.7912, 'recall_test': 0.7731, 'f1_score_test': 0.782}, 'MLP_2293761': {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.874, 'precision_cv_std': 0.0104, 'recall_cv_mean': 0.8811, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8775, 'f1_cv_std': 0.0028, 'params': 2293761, 'accuracy_test': 0.8991, 'precision_test': 0.7731, 'recall_test': 0.8167, 'f1_score_test': 0.7943}}}
Saved on: outputs_without_artist/2/gpt

==============================
Model: Logistic Regression

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.857, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8412, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.849, 'f1_cv_std': 0.0043}
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 44, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.86      0.90     16465
           1       0.65      0.85      0.74      5160

    accuracy                           0.86     21625
   macro avg       0.80      0.85      0.82     21625
weighted avg       0.88      0.86      0.86     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_logistic_regression.png
Modelo guardado como: outputs_without_artist/2/gpt/logistic_regression_model.pkl

==============================
Model: SVM

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7335, 'accuracy_cv_std': 0.0294, 'precision_cv_mean': 0.719, 'precision_cv_std': 0.0499, 'recall_cv_mean': 0.7793, 'recall_cv_std': 0.0302, 'f1_cv_mean': 0.7459, 'f1_cv_std': 0.0151}
Hiperparámetros: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 1000, 'probability': False, 'random_state': 44, 'shrinking': True, 'tol': 0.001, 'verbose': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.59      0.71     16465
           1       0.38      0.82      0.52      5160

    accuracy                           0.64     21625
   macro avg       0.65      0.70      0.62     21625
weighted avg       0.79      0.64      0.67     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_svm.png
Modelo guardado como: outputs_without_artist/2/gpt/svm_model.pkl

==============================
Model: Decision Tree

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7762, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.7807, 'precision_cv_std': 0.007, 'recall_cv_mean': 0.7683, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.7743, 'f1_cv_std': 0.0059}
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 44, 'splitter': 'best'}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.80      0.85     16465
           1       0.54      0.76      0.63      5160

    accuracy                           0.79     21625
   macro avg       0.73      0.78      0.74     21625
weighted avg       0.83      0.79      0.80     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_decision_tree.png
Modelo guardado como: outputs_without_artist/2/gpt/decision_tree_model.pkl

==============================
Model: Random Forest

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8191, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8561, 'precision_cv_std': 0.0041, 'recall_cv_mean': 0.7672, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8092, 'f1_cv_std': 0.0044}
Hiperparámetros: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': -1, 'oob_score': False, 'random_state': 44, 'verbose': 0, 'warm_start': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.92      0.87      0.90     16465
           1       0.65      0.77      0.70      5160

    accuracy                           0.85     21625
   macro avg       0.79      0.82      0.80     21625
weighted avg       0.86      0.85      0.85     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_random_forest.png
Modelo guardado como: outputs_without_artist/2/gpt/random_forest_model.pkl

==============================
Model: XGBoost

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.8662, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.8862, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8404, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8626, 'f1_cv_std': 0.0042}
Hiperparámetros: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 200, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 44, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.8, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.95      0.89      0.92     16465
           1       0.71      0.85      0.77      5160

    accuracy                           0.88     21625
   macro avg       0.83      0.87      0.85     21625
weighted avg       0.89      0.88      0.89     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_xgboost.png
Modelo guardado como: outputs_without_artist/2/gpt/xgboost_model.pkl

==============================
Model: Naive Bayes

Promedio CV (validación interna):
{'accuracy_cv_mean': 0.7989, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8557, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.7815, 'f1_cv_std': 0.0051}
Hiperparámetros: {'priors': None, 'var_smoothing': 1e-09}

Evaluación en TEST:
              precision    recall  f1-score   support

           0       0.91      0.88      0.89     16465
           1       0.65      0.72      0.68      5160

    accuracy                           0.84     21625
   macro avg       0.78      0.80      0.79     21625
weighted avg       0.85      0.84      0.84     21625

Confusion matrix Test saved as: outputs_without_artist/2/gpt/conf_matrix_test_naive_bayes.png
Modelo guardado como: outputs_without_artist/2/gpt/naive_bayes_model.pkl


Resumen Final:
XGBoost: {'accuracy_cv_mean': 0.8662, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.8862, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8404, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8626, 'f1_cv_std': 0.0042, 'accuracy_test': 0.8821, 'precision_test': 0.7125, 'recall_test': 0.8479, 'f1_score_test': 0.7743}
Logistic Regression: {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.857, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8412, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.849, 'f1_cv_std': 0.0043, 'accuracy_test': 0.8569, 'precision_test': 0.6545, 'recall_test': 0.8475, 'f1_score_test': 0.7386}
Random Forest: {'accuracy_cv_mean': 0.8191, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8561, 'precision_cv_std': 0.0041, 'recall_cv_mean': 0.7672, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8092, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8464, 'precision_test': 0.6511, 'recall_test': 0.768, 'f1_score_test': 0.7047}
Naive Bayes: {'accuracy_cv_mean': 0.7989, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8557, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.7815, 'f1_cv_std': 0.0051, 'accuracy_test': 0.8406, 'precision_test': 0.6497, 'recall_test': 0.72, 'f1_score_test': 0.683}
Decision Tree: {'accuracy_cv_mean': 0.7762, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.7807, 'precision_cv_std': 0.007, 'recall_cv_mean': 0.7683, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.7743, 'f1_cv_std': 0.0059, 'accuracy_test': 0.791, 'precision_test': 0.5447, 'recall_test': 0.7564, 'f1_score_test': 0.6333}
SVM: {'accuracy_cv_mean': 0.7335, 'accuracy_cv_std': 0.0294, 'precision_cv_mean': 0.719, 'precision_cv_std': 0.0499, 'recall_cv_mean': 0.7793, 'recall_cv_std': 0.0302, 'f1_cv_mean': 0.7459, 'f1_cv_std': 0.0151, 'accuracy_test': 0.6425, 'precision_test': 0.3838, 'recall_test': 0.8227, 'f1_score_test': 0.5234}
resultados_globales con ML {'tfidf': {'MLP_160705': {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}, 'MLP_5840897': {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}, 'Logistic Regression': {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}, 'SVM': {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}, 'Decision Tree': {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}, 'Random Forest': {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}, 'XGBoost': {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}, 'Naive Bayes': {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}}, 'lyrics_bert': {'MLP_10305': {'accuracy_cv_mean': 0.8644, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8595, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8713, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8653, 'f1_cv_std': 0.0047, 'params': 10305, 'accuracy_test': 0.9025, 'precision_test': 0.7956, 'recall_test': 0.7959, 'f1_score_test': 0.7958}, 'MLP_1028097': {'accuracy_cv_mean': 0.8764, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8734, 'precision_cv_std': 0.0087, 'recall_cv_mean': 0.8808, 'recall_cv_std': 0.0111, 'f1_cv_mean': 0.877, 'f1_cv_std': 0.0037, 'params': 1028097, 'accuracy_test': 0.9011, 'precision_test': 0.7627, 'recall_test': 0.8498, 'f1_score_test': 0.8039}, 'Logistic Regression': {'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8648, 'precision_test': 0.6772, 'recall_test': 0.8279, 'f1_score_test': 0.745}, 'SVM': {'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201, 'accuracy_test': 0.6435, 'precision_test': 0.3645, 'recall_test': 0.6647, 'f1_score_test': 0.4708}, 'Decision Tree': {'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009, 'accuracy_test': 0.8218, 'precision_test': 0.6019, 'recall_test': 0.7483, 'f1_score_test': 0.6671}, 'Random Forest': {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074, 'accuracy_test': 0.8785, 'precision_test': 0.7191, 'recall_test': 0.8052, 'f1_score_test': 0.7597}, 'XGBoost': {'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055, 'accuracy_test': 0.8907, 'precision_test': 0.7341, 'recall_test': 0.8498, 'f1_score_test': 0.7877}, 'Naive Bayes': {'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.7816, 'f1_cv_std': 0.0054, 'accuracy_test': 0.759, 'precision_test': 0.4969, 'recall_test': 0.8076, 'f1_score_test': 0.6152}}, 'gpt': {'MLP_49857': {'accuracy_cv_mean': 0.8676, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.8664, 'precision_cv_std': 0.0132, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.0164, 'f1_cv_mean': 0.8679, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8972, 'precision_test': 0.7912, 'recall_test': 0.7731, 'f1_score_test': 0.782}, 'MLP_2293761': {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.874, 'precision_cv_std': 0.0104, 'recall_cv_mean': 0.8811, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8775, 'f1_cv_std': 0.0028, 'params': 2293761, 'accuracy_test': 0.8991, 'precision_test': 0.7731, 'recall_test': 0.8167, 'f1_score_test': 0.7943}, 'Logistic Regression': {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.857, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8412, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.849, 'f1_cv_std': 0.0043, 'accuracy_test': 0.8569, 'precision_test': 0.6545, 'recall_test': 0.8475, 'f1_score_test': 0.7386}, 'SVM': {'accuracy_cv_mean': 0.7335, 'accuracy_cv_std': 0.0294, 'precision_cv_mean': 0.719, 'precision_cv_std': 0.0499, 'recall_cv_mean': 0.7793, 'recall_cv_std': 0.0302, 'f1_cv_mean': 0.7459, 'f1_cv_std': 0.0151, 'accuracy_test': 0.6425, 'precision_test': 0.3838, 'recall_test': 0.8227, 'f1_score_test': 0.5234}, 'Decision Tree': {'accuracy_cv_mean': 0.7762, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.7807, 'precision_cv_std': 0.007, 'recall_cv_mean': 0.7683, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.7743, 'f1_cv_std': 0.0059, 'accuracy_test': 0.791, 'precision_test': 0.5447, 'recall_test': 0.7564, 'f1_score_test': 0.6333}, 'Random Forest': {'accuracy_cv_mean': 0.8191, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8561, 'precision_cv_std': 0.0041, 'recall_cv_mean': 0.7672, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8092, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8464, 'precision_test': 0.6511, 'recall_test': 0.768, 'f1_score_test': 0.7047}, 'XGBoost': {'accuracy_cv_mean': 0.8662, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.8862, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8404, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8626, 'f1_cv_std': 0.0042, 'accuracy_test': 0.8821, 'precision_test': 0.7125, 'recall_test': 0.8479, 'f1_score_test': 0.7743}, 'Naive Bayes': {'accuracy_cv_mean': 0.7989, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8557, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.7815, 'f1_cv_std': 0.0051, 'accuracy_test': 0.8406, 'precision_test': 0.6497, 'recall_test': 0.72, 'f1_score_test': 0.683}}}


Resumen GLOBAL de métricas:


EMBEDDINGS TYPE: TFIDF
MLP_5840897: {'accuracy_cv_mean': 0.8963, 'accuracy_cv_std': 0.0029, 'precision_cv_mean': 0.8901, 'precision_cv_std': 0.0156, 'recall_cv_mean': 0.905, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.8972, 'f1_cv_std': 0.0019, 'params': 5840897, 'accuracy_test': 0.9106, 'precision_test': 0.7897, 'recall_test': 0.8523, 'f1_score_test': 0.8198}
MLP_160705: {'accuracy_cv_mean': 0.8897, 'accuracy_cv_std': 0.0034, 'precision_cv_mean': 0.8915, 'precision_cv_std': 0.0129, 'recall_cv_mean': 0.8879, 'recall_cv_std': 0.0117, 'f1_cv_mean': 0.8895, 'f1_cv_std': 0.0028, 'params': 160705, 'accuracy_test': 0.9118, 'precision_test': 0.8071, 'recall_test': 0.8285, 'f1_score_test': 0.8176}
XGBoost: {'accuracy_cv_mean': 0.8782, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.9046, 'precision_cv_std': 0.0043, 'recall_cv_mean': 0.8456, 'recall_cv_std': 0.0085, 'f1_cv_mean': 0.8741, 'f1_cv_std': 0.0054, 'accuracy_test': 0.8988, 'precision_test': 0.7588, 'recall_test': 0.8442, 'f1_score_test': 0.7992}
Logistic Regression: {'accuracy_cv_mean': 0.8778, 'accuracy_cv_std': 0.0056, 'precision_cv_mean': 0.8918, 'precision_cv_std': 0.0044, 'recall_cv_mean': 0.8598, 'recall_cv_std': 0.0094, 'f1_cv_mean': 0.8755, 'f1_cv_std': 0.0061, 'accuracy_test': 0.89, 'precision_test': 0.7286, 'recall_test': 0.8593, 'f1_score_test': 0.7885}
Naive Bayes: {'accuracy_cv_mean': 0.8448, 'accuracy_cv_std': 0.0053, 'precision_cv_mean': 0.87, 'precision_cv_std': 0.0064, 'recall_cv_mean': 0.8107, 'recall_cv_std': 0.0081, 'f1_cv_mean': 0.8393, 'f1_cv_std': 0.0057, 'accuracy_test': 0.8641, 'precision_test': 0.6827, 'recall_test': 0.8047, 'f1_score_test': 0.7387}
Decision Tree: {'accuracy_cv_mean': 0.8251, 'accuracy_cv_std': 0.0087, 'precision_cv_mean': 0.8883, 'precision_cv_std': 0.0171, 'recall_cv_mean': 0.7445, 'recall_cv_std': 0.0251, 'f1_cv_mean': 0.8096, 'f1_cv_std': 0.0118, 'accuracy_test': 0.8768, 'precision_test': 0.7502, 'recall_test': 0.725, 'f1_score_test': 0.7374}
Random Forest: {'accuracy_cv_mean': 0.8202, 'accuracy_cv_std': 0.0069, 'precision_cv_mean': 0.8531, 'precision_cv_std': 0.0102, 'recall_cv_mean': 0.7739, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8115, 'f1_cv_std': 0.007, 'accuracy_test': 0.8429, 'precision_test': 0.6422, 'recall_test': 0.7711, 'f1_score_test': 0.7008}
SVM: {'accuracy_cv_mean': 0.7442, 'accuracy_cv_std': 0.0191, 'precision_cv_mean': 0.7398, 'precision_cv_std': 0.0465, 'recall_cv_mean': 0.7679, 'recall_cv_std': 0.0837, 'f1_cv_mean': 0.7484, 'f1_cv_std': 0.0292, 'accuracy_test': 0.6969, 'precision_test': 0.4276, 'recall_test': 0.7981, 'f1_score_test': 0.5568}


EMBEDDINGS TYPE: LYRICS_BERT
MLP_1028097: {'accuracy_cv_mean': 0.8764, 'accuracy_cv_std': 0.0035, 'precision_cv_mean': 0.8734, 'precision_cv_std': 0.0087, 'recall_cv_mean': 0.8808, 'recall_cv_std': 0.0111, 'f1_cv_mean': 0.877, 'f1_cv_std': 0.0037, 'params': 1028097, 'accuracy_test': 0.9011, 'precision_test': 0.7627, 'recall_test': 0.8498, 'f1_score_test': 0.8039}
MLP_10305: {'accuracy_cv_mean': 0.8644, 'accuracy_cv_std': 0.005, 'precision_cv_mean': 0.8595, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.8713, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.8653, 'f1_cv_std': 0.0047, 'params': 10305, 'accuracy_test': 0.9025, 'precision_test': 0.7956, 'recall_test': 0.7959, 'f1_score_test': 0.7958}
XGBoost: {'accuracy_cv_mean': 0.8743, 'accuracy_cv_std': 0.0048, 'precision_cv_mean': 0.8933, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8501, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8711, 'f1_cv_std': 0.0055, 'accuracy_test': 0.8907, 'precision_test': 0.7341, 'recall_test': 0.8498, 'f1_score_test': 0.7877}
Random Forest: {'accuracy_cv_mean': 0.8497, 'accuracy_cv_std': 0.0063, 'precision_cv_mean': 0.8847, 'precision_cv_std': 0.0052, 'recall_cv_mean': 0.8042, 'recall_cv_std': 0.0124, 'f1_cv_mean': 0.8425, 'f1_cv_std': 0.0074, 'accuracy_test': 0.8785, 'precision_test': 0.7191, 'recall_test': 0.8052, 'f1_score_test': 0.7597}
Logistic Regression: {'accuracy_cv_mean': 0.8459, 'accuracy_cv_std': 0.0047, 'precision_cv_mean': 0.86, 'precision_cv_std': 0.0046, 'recall_cv_mean': 0.8263, 'recall_cv_std': 0.0088, 'f1_cv_mean': 0.8428, 'f1_cv_std': 0.0053, 'accuracy_test': 0.8648, 'precision_test': 0.6772, 'recall_test': 0.8279, 'f1_score_test': 0.745}
Decision Tree: {'accuracy_cv_mean': 0.7853, 'accuracy_cv_std': 0.0054, 'precision_cv_mean': 0.8172, 'precision_cv_std': 0.0082, 'recall_cv_mean': 0.7354, 'recall_cv_std': 0.021, 'f1_cv_mean': 0.7739, 'f1_cv_std': 0.009, 'accuracy_test': 0.8218, 'precision_test': 0.6019, 'recall_test': 0.7483, 'f1_score_test': 0.6671}
Naive Bayes: {'accuracy_cv_mean': 0.7744, 'accuracy_cv_std': 0.0042, 'precision_cv_mean': 0.7572, 'precision_cv_std': 0.002, 'recall_cv_mean': 0.8076, 'recall_cv_std': 0.0109, 'f1_cv_mean': 0.7816, 'f1_cv_std': 0.0054, 'accuracy_test': 0.759, 'precision_test': 0.4969, 'recall_test': 0.8076, 'f1_score_test': 0.6152}
SVM: {'accuracy_cv_mean': 0.6541, 'accuracy_cv_std': 0.032, 'precision_cv_mean': 0.6241, 'precision_cv_std': 0.0318, 'recall_cv_mean': 0.7842, 'recall_cv_std': 0.0237, 'f1_cv_mean': 0.6944, 'f1_cv_std': 0.0201, 'accuracy_test': 0.6435, 'precision_test': 0.3645, 'recall_test': 0.6647, 'f1_score_test': 0.4708}


EMBEDDINGS TYPE: GPT
MLP_2293761: {'accuracy_cv_mean': 0.877, 'accuracy_cv_std': 0.0033, 'precision_cv_mean': 0.874, 'precision_cv_std': 0.0104, 'recall_cv_mean': 0.8811, 'recall_cv_std': 0.01, 'f1_cv_mean': 0.8775, 'f1_cv_std': 0.0028, 'params': 2293761, 'accuracy_test': 0.8991, 'precision_test': 0.7731, 'recall_test': 0.8167, 'f1_score_test': 0.7943}
MLP_49857: {'accuracy_cv_mean': 0.8676, 'accuracy_cv_std': 0.003, 'precision_cv_mean': 0.8664, 'precision_cv_std': 0.0132, 'recall_cv_mean': 0.8698, 'recall_cv_std': 0.0164, 'f1_cv_mean': 0.8679, 'f1_cv_std': 0.0033, 'params': 49857, 'accuracy_test': 0.8972, 'precision_test': 0.7912, 'recall_test': 0.7731, 'f1_score_test': 0.782}
XGBoost: {'accuracy_cv_mean': 0.8662, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.8862, 'precision_cv_std': 0.0048, 'recall_cv_mean': 0.8404, 'recall_cv_std': 0.0069, 'f1_cv_mean': 0.8626, 'f1_cv_std': 0.0042, 'accuracy_test': 0.8821, 'precision_test': 0.7125, 'recall_test': 0.8479, 'f1_score_test': 0.7743}
Logistic Regression: {'accuracy_cv_mean': 0.8504, 'accuracy_cv_std': 0.0039, 'precision_cv_mean': 0.857, 'precision_cv_std': 0.0037, 'recall_cv_mean': 0.8412, 'recall_cv_std': 0.0073, 'f1_cv_mean': 0.849, 'f1_cv_std': 0.0043, 'accuracy_test': 0.8569, 'precision_test': 0.6545, 'recall_test': 0.8475, 'f1_score_test': 0.7386}
Random Forest: {'accuracy_cv_mean': 0.8191, 'accuracy_cv_std': 0.004, 'precision_cv_mean': 0.8561, 'precision_cv_std': 0.0041, 'recall_cv_mean': 0.7672, 'recall_cv_std': 0.0051, 'f1_cv_mean': 0.8092, 'f1_cv_std': 0.0044, 'accuracy_test': 0.8464, 'precision_test': 0.6511, 'recall_test': 0.768, 'f1_score_test': 0.7047}
Naive Bayes: {'accuracy_cv_mean': 0.7989, 'accuracy_cv_std': 0.0044, 'precision_cv_mean': 0.8557, 'precision_cv_std': 0.0045, 'recall_cv_mean': 0.7191, 'recall_cv_std': 0.006, 'f1_cv_mean': 0.7815, 'f1_cv_std': 0.0051, 'accuracy_test': 0.8406, 'precision_test': 0.6497, 'recall_test': 0.72, 'f1_score_test': 0.683}
Decision Tree: {'accuracy_cv_mean': 0.7762, 'accuracy_cv_std': 0.0041, 'precision_cv_mean': 0.7807, 'precision_cv_std': 0.007, 'recall_cv_mean': 0.7683, 'recall_cv_std': 0.0147, 'f1_cv_mean': 0.7743, 'f1_cv_std': 0.0059, 'accuracy_test': 0.791, 'precision_test': 0.5447, 'recall_test': 0.7564, 'f1_score_test': 0.6333}
SVM: {'accuracy_cv_mean': 0.7335, 'accuracy_cv_std': 0.0294, 'precision_cv_mean': 0.719, 'precision_cv_std': 0.0499, 'recall_cv_mean': 0.7793, 'recall_cv_std': 0.0302, 'f1_cv_mean': 0.7459, 'f1_cv_std': 0.0151, 'accuracy_test': 0.6425, 'precision_test': 0.3838, 'recall_test': 0.8227, 'f1_score_test': 0.5234}
Diccionario global guardado en: outputs_without_artist/2/gpt/global_metrics.json

========== CONFIGURATIONS ==========
TESTING: False
UNDERSAMPLING: True
USE_SMOTE: False
SCALED: True
STEAMING: True
REMOVE_STOPWORDS: True
NUMERIC_COLS: True
MAX_FEATURES_TFIDF: 5000
TF-IDF Columns: ['emotion', 'Time signature', 'song', 'Genre', 'Album', 'Release Date', 'Key', 'Similar Song 1', 'Similar Song 2', 'Similar Song 3', 'song_normalized', 'artist_normalized']
Numeric Columns: ['Tempo', 'Length', 'Loudness (db)', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
====================================

