/home/marcelino.maita/.venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.
  warnings.warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/marcelino.maita/.venv/lib/python3.13/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.
  warnings.warn(
For TF-IDF embbedings you are selecteing this columns:
--> ['Artist(s)', 'song', 'emotion', 'Genre', 'Album', 'Similar Artist 1', 'Similar Song 1', 'Similar Artist 2', 'Similar Song 2', 'Similar Artist 3', 'Similar Song 3', 'song_normalized', 'artist_normalized']
For both embbedings your are adding this columns: 
--> ['Tempo', 'Popularity', 'Energy', 'Danceability', 'Positiveness', 'Speechiness', 'Liveness', 'Acousticness', 'Instrumentalness', 'Good for Party', 'Good for Work/Study', 'Good for Relaxation/Meditation', 'Good for Exercise', 'Good for Running', 'Good for Yoga/Stretching', 'Good for Driving', 'Good for Social Gatherings', 'Good for Morning Routine']
You are executing with [ALL] dataset
--> PaTH:  ../../data/embbedings_khipu/LB_fuss/lb_khipu_B.npy

##################################################
Running experiment with TFIDF embeddings
Preprocessing text...
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 5000)
y shape: (108138,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65868, 1: 20642}
Label distribution en TEST: {0: 16468, 1: 5160}




Aplicando SMOTE oversampling...
Nueva distribución de clases: {0: 65868, 1: 65868}

==============================
Model: Logistic Regression
Accuracy:  0.5219
Precision: 0.2528
Recall:    0.5134
F1-score:  0.3388
              precision    recall  f1-score   support

           0       0.77      0.52      0.63     16468
           1       0.25      0.51      0.34      5160

    accuracy                           0.52     21628
   macro avg       0.51      0.52      0.48     21628
weighted avg       0.65      0.52      0.56     21628

[[8639 7829]
 [2511 2649]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/logistic_regression_model.pkl
Gráfico guardado en outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/decision_boundary_logistic_regression.png

==============================
Model: Decision Tree
Accuracy:  0.7695
Precision: 0.5144
Recall:    0.6031
F1-score:  0.5552
              precision    recall  f1-score   support

           0       0.87      0.82      0.84     16468
           1       0.51      0.60      0.56      5160

    accuracy                           0.77     21628
   macro avg       0.69      0.71      0.70     21628
weighted avg       0.78      0.77      0.78     21628

[[13530  2938]
 [ 2048  3112]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/conf_matrix_decision_tree.png
Modelo guardado como: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/decision_tree_model.pkl
Gráfico guardado en outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/tfidf/decision_boundary_decision_tree.png


Resumen de métricas:
Decision Tree: {'accuracy': 0.7695, 'precision': 0.5144, 'recall': 0.6031, 'f1_score': 0.5552}
Logistic Regression: {'accuracy': 0.5219, 'precision': 0.2528, 'recall': 0.5134, 'f1_score': 0.3388}

##################################################
Running experiment with LYRICS_BERT embeddings
Loading Lb vectors from:  ../../data/spotify_dataset_sin_duplicados_4.csv
Label distribution: {0: 82336, 1: 25802}
X shape: (108138, 300)
y shape: (108138,)

Splitting data...

Data con el spliting...
Label distribution en TRAIN: {0: 65868, 1: 20642}
Label distribution en TEST: {0: 16468, 1: 5160}




Aplicando SMOTE oversampling...
Nueva distribución de clases: {0: 65868, 1: 65868}

==============================
Model: Logistic Regression
Accuracy:  0.5381
Precision: 0.2682
Recall:    0.5417
F1-score:  0.3588
              precision    recall  f1-score   support

           0       0.79      0.54      0.64     16468
           1       0.27      0.54      0.36      5160

    accuracy                           0.54     21628
   macro avg       0.53      0.54      0.50     21628
weighted avg       0.66      0.54      0.57     21628

[[8842 7626]
 [2365 2795]]
Hiperparámetros: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
Confusion matrix saved as: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/conf_matrix_logistic_regression.png
Modelo guardado como: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/logistic_regression_model.pkl
Gráfico guardado en outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/decision_boundary_logistic_regression.png

==============================
Model: Decision Tree
Accuracy:  0.7959
Precision: 0.5672
Recall:    0.6095
F1-score:  0.5876
              precision    recall  f1-score   support

           0       0.87      0.85      0.86     16468
           1       0.57      0.61      0.59      5160

    accuracy                           0.80     21628
   macro avg       0.72      0.73      0.73     21628
weighted avg       0.80      0.80      0.80     21628

[[14068  2400]
 [ 2015  3145]]
Hiperparámetros: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}
Confusion matrix saved as: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/conf_matrix_decision_tree.png
Modelo guardado como: outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/decision_tree_model.pkl
Gráfico guardado en outputs_limi/undersample_False_scaled_True_steaming_True_removestw_True_numeric_True_useSmote_True_+_5000_tfidf_B/lyrics_bert/decision_boundary_decision_tree.png


Resumen de métricas:
Decision Tree: {'accuracy': 0.7959, 'precision': 0.5672, 'recall': 0.6095, 'f1_score': 0.5876}
Logistic Regression: {'accuracy': 0.5381, 'precision': 0.2682, 'recall': 0.5417, 'f1_score': 0.3588}

You are executing with this configuration: undersample_False_scaled_True_removestw_True_5000tfidf
