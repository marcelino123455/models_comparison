{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf228eb",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd89201",
   "metadata": {
    "papermill": {
     "duration": 0.004422,
     "end_time": "2025-08-27T08:39:52.611818",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.607396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are going to process the lyrics of a song using the batches Api to reduce the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed34933",
   "metadata": {
    "papermill": {
     "duration": 0.003619,
     "end_time": "2025-08-27T08:39:52.619437",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.615818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creaci칩n del batch file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881b8e3",
   "metadata": {
    "papermill": {
     "duration": 0.003591,
     "end_time": "2025-08-27T08:39:52.626361",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.622770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Rate limits\n",
    "Batch API rate limits are separate from existing per-model rate limits. The Batch API has two new types of rate limits:\n",
    "\n",
    "Per-batch limits: A single batch may include up to 50,000 requests, and a batch input file can be up to 200 MB in size. Note that /v1/embeddings batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.\n",
    "Enqueued prompt tokens per model: Each model has a maximum number of enqueued prompt tokens allowed for batch processing. You can find these limits on the Platform Settings page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4c127",
   "metadata": {
    "papermill": {
     "duration": 0.003269,
     "end_time": "2025-08-27T08:39:52.633457",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.630188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) Creaci칩n del archivo jsonl for batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b3f759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:52.641050Z",
     "iopub.status.busy": "2025-08-27T08:39:52.640886Z",
     "iopub.status.idle": "2025-08-27T08:39:52.643214Z",
     "shell.execute_reply": "2025-08-27T08:39:52.642836Z"
    },
    "papermill": {
     "duration": 0.007295,
     "end_time": "2025-08-27T08:39:52.644232",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.636937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model\tCost\tBatch cost\n",
    "# text-embedding-3-small\t$0.01\t$0.0001\n",
    "# text-embedding-3-large\t$0.065\t$0.00013\n",
    "# text-embedding-ada-002\t$0.05\t$0.0004\n",
    "# https://platform.openai.com/docs/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641e894f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:52.662545Z",
     "iopub.status.busy": "2025-08-27T08:39:52.662361Z",
     "iopub.status.idle": "2025-08-27T08:39:53.354502Z",
     "shell.execute_reply": "2025-08-27T08:39:53.353787Z"
    },
    "papermill": {
     "duration": 0.707943,
     "end_time": "2025-08-27T08:39:53.355692",
     "exception": false,
     "start_time": "2025-08-27T08:39:52.647749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import json \n",
    "import tiktoken\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989e39d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:53.364434Z",
     "iopub.status.busy": "2025-08-27T08:39:53.363707Z",
     "iopub.status.idle": "2025-08-27T08:39:55.723369Z",
     "shell.execute_reply": "2025-08-27T08:39:55.722552Z"
    },
    "papermill": {
     "duration": 2.365294,
     "end_time": "2025-08-27T08:39:55.724607",
     "exception": false,
     "start_time": "2025-08-27T08:39:53.359313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "url = \"/v1/embeddings\"\n",
    "path_data = \"../../../../data\"\n",
    "path_df =os.path.join(path_data, \"spotify_dataset_sin_duplicados_4.csv\")\n",
    "df = pd.read_csv(path_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704faaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:55.733560Z",
     "iopub.status.busy": "2025-08-27T08:39:55.732852Z",
     "iopub.status.idle": "2025-08-27T08:39:55.754200Z",
     "shell.execute_reply": "2025-08-27T08:39:55.753846Z"
    },
    "papermill": {
     "duration": 0.026674,
     "end_time": "2025-08-27T08:39:55.755104",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.728430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Function to count the number of tokens\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    # print(\"Comezando en la funci칩n\")\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    # print(\"Encoding obtenido\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    # print(\"Conteo listo\")\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "# Function that see how much the does the file weigh\n",
    "def get_file_size(filepath):\n",
    "    size_bytes = os.path.getsize(filepath)\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    print(f\"File size: {size_bytes} bytes ({size_mb:.2f} MB)\")\n",
    "    return size_mb\n",
    "\n",
    "\n",
    "# In ram\n",
    "def get_jsons_size(json_list):\n",
    "    total_bytes = 0\n",
    "    for j in json_list:\n",
    "        line = json.dumps(j, ensure_ascii=False) + \"\\n\"  \n",
    "        total_bytes += len(line.encode(\"utf-8\"))         \n",
    "    \n",
    "    return total_bytes / (1024 * 1024)    \n",
    "# 0) Create a single json file \n",
    "\n",
    "def crear_single_json(text, idx, model=\"text-embedding-3-small\"):\n",
    "    request = {\n",
    "        \"custom_id\": f\"request-{idx}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/embeddings\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"input\": text\n",
    "        }\n",
    "    }\n",
    "    return request  \n",
    "# Function that take a start and a end to create the jsonl file \n",
    "#1) create bath file\n",
    "def guardar_jsons(json_list, start, end, output_dir=\"./\"):\n",
    "    # Nombre de salida con el rango\n",
    "    filename = f\"{output_dir}/embeddings_{start}_{end}.jsonl\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for obj in json_list:\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(f\"Archivo guardado: {filename} con {len(json_list)} requests\")\n",
    "    return filename\n",
    "\n",
    "#2) upload\n",
    "def upload_batch_file_to_openai(jsonl_path, api_key=None):\n",
    "    print(\"Subiendo el archivo de la ruta:\", jsonl_path)\n",
    "    # Validar ruta\n",
    "    if not os.path.exists(jsonl_path):\n",
    "        raise FileNotFoundError(f\"El archivo no existe: {jsonl_path}\")\n",
    "    if not os.path.isfile(jsonl_path):\n",
    "        raise ValueError(f\"La ruta no es un archivo v치lido: {jsonl_path}\")\n",
    "\n",
    "    # Cliente\n",
    "    if api_key:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        client = OpenAI()\n",
    "\n",
    "    # Subir archivo\n",
    "    with open(jsonl_path, \"rb\") as f:\n",
    "        batch_input_file = client.files.create(\n",
    "            file=f,\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "    \n",
    "    return batch_input_file\n",
    "#3 Create the batch  \n",
    "def create_openai_batch(batch_input_file, endpoint=\"/v1/embeddings\", completion_window=\"24h\", metadata=None, api_key=None):\n",
    "    from openai import OpenAI\n",
    "\n",
    "    if api_key:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        client = OpenAI()\n",
    "\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    response = client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=endpoint,\n",
    "        completion_window=completion_window,\n",
    "        metadata=metadata or {\"description\": \"nightly eval job\"}\n",
    "    )\n",
    "    # print(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "#4 Check the satus \n",
    "def check_openai_batch(batch_id, api_key=None):\n",
    "    from openai import OpenAI\n",
    "\n",
    "    if api_key:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        client = OpenAI()\n",
    "\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    # print(batch)\n",
    "    return batch\n",
    "\n",
    "\n",
    "#5 Retreive or doload the results\n",
    "def download_results(batch_id, api_key=None):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    file_response = client.files.content(batch_id)\n",
    "    print(file_response.text)\n",
    "    return file_response.text\n",
    "\n",
    "\n",
    "# 6 save the results\n",
    "def saveResult(file_response, start, end, output_path=\"../../../../data/gpt_responses\"):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(f\"{output_path}/{start}_{end}.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(file_response)\n",
    "    \n",
    "    print(f\"Resultados guardados en: {output_path}\")\n",
    "\n",
    "\n",
    "def save_embeddings_only(file_response_text,  start=0, end=0, output_path=\"../../../../data/gpt_responses\"):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file = f\"{output_path}/{start}_{end}_embeddings_only.jsonl\"\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in file_response_text.splitlines():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                j = json.loads(line)\n",
    "                custom_id = j[\"custom_id\"]\n",
    "                embedding = j[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "                # Guardar como JSON en una sola l칤nea\n",
    "                f.write(json.dumps({\"custom_id\": custom_id, \"embedding\": embedding}, ensure_ascii=False) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando l칤nea: {e}\")\n",
    "\n",
    "    print(f\"Embeddings guardados solo con custom_id en: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def load_embeddings_and_check_dim(file_path):\n",
    "    embeddings = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            j = json.loads(line)\n",
    "            embeddings.append(j[\"embedding\"])\n",
    "    \n",
    "    if embeddings:\n",
    "        print(f\"N칰mero de embeddings: {len(embeddings)}\")\n",
    "        print(f\"Dimensi칩n del primer embedding: {len(embeddings[0])}\")\n",
    "    else:\n",
    "        print(\"No se encontraron embeddings en el archivo.\")\n",
    "\n",
    "    return embeddings\n",
    "# Ejemplo de uso\n",
    "texts = [\n",
    "    \"El sol brilla sobre las monta침as.\",\n",
    "    \"La inteligencia artificial est치 transformando el mundo.\",\n",
    "    \"Los datos son el nuevo petr칩leo.\"\n",
    "]\n",
    "\n",
    "def save_batch_metadata(start, end, batch_file_id, batch_id, output_dir=\"../../../../data/gpt_to_check\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    metadata = {\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"batch_file_id\": batch_file_id,\n",
    "        \"batch_id\": batch_id\n",
    "    }\n",
    "\n",
    "    # Nombre del archivo de metadatos\n",
    "    filename = f\"{output_dir}/batch_metadata_{start}_{end}.json\"\n",
    "    \n",
    "    # Guardar en disco\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        print(f\"Metadatos del batch guardados en {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error guardando metadatos del batch: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "# Function that clean text\n",
    "\n",
    "def limpiar_letras(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Elimina anotaciones como [Intro ...], [Chorus ...], [Verse 1: ...], \n",
    "    [Part 2 ...], [Hook ...], [Interlude ...], [Skit ...], [Produced ...], \n",
    "    [Track 1 ...], [Refrain ...], [Pre-Chorus ...], [Company ...], \n",
    "    [Backing vocals ...], [Sample ...], [Segue from ...], [Interview ...], \n",
    "    [2Pac ...], etc.\n",
    "    \"\"\"\n",
    "    patron = r\"\"\"\n",
    "        \\[                                   # abre corchete\n",
    "        (?:                                  # grupo de opciones\n",
    "            Intro\\s*\\d*\n",
    "          | Chorus\\s*\\d*\n",
    "          | Verse\\s*\\d*\n",
    "          | Vers\\s*\\d*\n",
    "          | Hook\\s*\\d*\n",
    "          | Part\\s*\\d*\n",
    "          | Interlude\\s*\\d*\n",
    "          | Skit\\s*\\d*\n",
    "          | Produced\\s*\\d*\n",
    "          | Track\\s*\\d*\n",
    "          | Refrain\\s*\\d*\n",
    "          | Pre-?Chorus\\s*\\d*\n",
    "          | Company\\s*\\d*\n",
    "          | Backing\\s+vocals\n",
    "          | Sample\\s*\\d*\n",
    "          | Segue\\s+from\n",
    "          | Instrumental\n",
    "          | Pre-Hook\n",
    "          | Pre Hook\n",
    "          | Lyrical\n",
    "          | Beat\n",
    "          | Interview\\s*\\d*\n",
    "        )[^\\]]*                              # cualquier cosa hasta ]\n",
    "        \\]                                   # cierra corchete\n",
    "    \"\"\"\n",
    "    return re.sub(patron, \"\", texto, flags=re.IGNORECASE | re.VERBOSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480de22",
   "metadata": {
    "papermill": {
     "duration": 0.003659,
     "end_time": "2025-08-27T08:39:55.762209",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.758550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1) Conteo de canciones que pasan el limite de tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b8ceea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:55.770846Z",
     "iopub.status.busy": "2025-08-27T08:39:55.770195Z",
     "iopub.status.idle": "2025-08-27T08:39:55.773786Z",
     "shell.execute_reply": "2025-08-27T08:39:55.772755Z"
    },
    "papermill": {
     "duration": 0.008447,
     "end_time": "2025-08-27T08:39:55.774636",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.766189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# df[\"n_tokens\"] = df[\"text\"].apply(lambda x: num_tokens_from_string(x))\n",
    "\n",
    "# # Cuenta cu치ntos superan el l칤mite\n",
    "# exceden = (df[\"n_tokens\"] > 8190).sum()\n",
    "\n",
    "# print(f\"Cantidad de textos que superan 8190 tokens: {exceden}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f712e9",
   "metadata": {
    "papermill": {
     "duration": 0.003947,
     "end_time": "2025-08-27T08:39:55.781811",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.777864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) Pruebas con textos largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ac10a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:55.790215Z",
     "iopub.status.busy": "2025-08-27T08:39:55.789921Z",
     "iopub.status.idle": "2025-08-27T08:39:55.792494Z",
     "shell.execute_reply": "2025-08-27T08:39:55.792108Z"
    },
    "papermill": {
     "duration": 0.007872,
     "end_time": "2025-08-27T08:39:55.793379",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.785507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_model = \"text-embedding-3-small\"\n",
    "# embedding_encoding = \"cl100k_base\"\n",
    "# max_tokens = 8191  # the maximum for text-embedding-3-small is 8191\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv() \n",
    "# API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# # Cnaciones m치s largas\n",
    "\n",
    "# with open(\"cancion_large.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     cancion_mas_larga = f.read()\n",
    "\n",
    "# with open(\"cancion_large_in_chars.txt\", \"r\", encoding=\"utf-8\") as f2:\n",
    "#     cancion_large_in_chars = f2.read()\n",
    "\n",
    "# words = cancion_mas_larga.split(\" \")\n",
    "# print(f\"Longitud de la canci칩n m치s larga: {len(words)} caracteres\")\n",
    "\n",
    "# words2 = cancion_large_in_chars.split(\" \")\n",
    "# print(f\"Longitud de la canci칩n m치s larga: {len(words2)} caracteres\")\n",
    "\n",
    "# print(\"La cancion mas larga en words: \",num_tokens_from_string(cancion_mas_larga) )\n",
    "# print(\"La cancion mas larga en chars: \",num_tokens_from_string(cancion_large_in_chars))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d4b45",
   "metadata": {
    "papermill": {
     "duration": 0.003933,
     "end_time": "2025-08-27T08:39:55.801222",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.797289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, only are 13 songs that exceed the limit that's wahy we are only going to process the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826d5fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:55.812720Z",
     "iopub.status.busy": "2025-08-27T08:39:55.812562Z",
     "iopub.status.idle": "2025-08-27T08:39:55.814729Z",
     "shell.execute_reply": "2025-08-27T08:39:55.814351Z"
    },
    "papermill": {
     "duration": 0.010824,
     "end_time": "2025-08-27T08:39:55.816009",
     "exception": false,
     "start_time": "2025-08-27T08:39:55.805185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#     model=embedding_model,   \n",
    "#     input=cancion_mas_larga,\n",
    "#     encoding_format=\"float\"\n",
    "# )\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# # Si solo quieres ver el embedding:\n",
    "# print(\"Dimensi칩n del embedding:\", len(response.data[0].embedding))\n",
    "# print(\"Primeros 10 valores:\", response.data[0].embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff9a93",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680ef5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T08:39:55.824774Z",
     "iopub.status.busy": "2025-08-27T08:39:55.824603Z",
     "iopub.status.idle": "2025-08-27T08:40:00.289068Z",
     "shell.execute_reply": "2025-08-27T08:40:00.287443Z"
    },
    "papermill": {
     "duration": 4.469781,
     "end_time": "2025-08-27T08:40:00.289770",
     "exception": true,
     "start_time": "2025-08-27T08:39:55.819989",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7feb6b4152b0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -2] Name or service not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/util/connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/ohpc/pub/libs/gnu12/python3/3.13.2/lib/python3.13/socket.py:977\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    976\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    978\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno -2] Name or service not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x7feb6b4152b0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7feb6b4152b0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m song = limpiar_letras(song)\n\u001b[32m     63\u001b[39m end = idx \u001b[38;5;66;03m# Solo si se procesra sera este end\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mnum_tokens_from_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong\u001b[49m\u001b[43m)\u001b[49m > max_tokens):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLa canci칩n \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m excede el l칤mite de tokens (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_tokens_from_string(song)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens). Se omitir치.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m     songs_passed_limit.append(idx)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mnum_tokens_from_string\u001b[39m\u001b[34m(string, encoding_name)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the number of tokens in a text string.\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# print(\"Comezando en la funci칩n\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m encoding = \u001b[43mtiktoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(\"Encoding obtenido\")\u001b[39;00m\n\u001b[32m      8\u001b[39m num_tokens = \u001b[38;5;28mlen\u001b[39m(encoding.encode(string))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/tiktoken/registry.py:86\u001b[39m, in \u001b[36mget_encoding\u001b[39m\u001b[34m(encoding_name)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     80\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown encoding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlugins found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_available_plugin_modules()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtiktoken version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtiktoken.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (are you on latest?)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m     )\n\u001b[32m     85\u001b[39m constructor = ENCODING_CONSTRUCTORS[encoding_name]\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m enc = Encoding(**\u001b[43mconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     87\u001b[39m ENCODINGS[encoding_name] = enc\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m enc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/tiktoken_ext/openai_public.py:76\u001b[39m, in \u001b[36mcl100k_base\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcl100k_base\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     mergeable_ranks = \u001b[43mload_tiktoken_bpe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m223921b76ee99bde995b7ff738513eef100fb51d18c93597a113bcffe865b2a7\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     special_tokens = {\n\u001b[32m     81\u001b[39m         ENDOFTEXT: \u001b[32m100257\u001b[39m,\n\u001b[32m     82\u001b[39m         FIM_PREFIX: \u001b[32m100258\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m         ENDOFPROMPT: \u001b[32m100276\u001b[39m,\n\u001b[32m     86\u001b[39m     }\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcl100k_base\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpat_str\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mr\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(?i:[sdmt]|ll|ve|re)|[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{L}\u001b[39;00m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{N}\u001b[39;00m\u001b[33m]?+\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{L}\u001b[39;00m\u001b[33m++|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{N}\u001b[39;00m\u001b[33m{\u001b[39m\u001b[33m1,3}+| ?[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{L}\u001b[39;00m\u001b[33m\\\u001b[39m\u001b[33mp\u001b[39m\u001b[38;5;132;01m{N}\u001b[39;00m\u001b[33m]++[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn]*+|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms++$|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn]|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+(?!\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mS)|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\"\"\u001b[39m,\n\u001b[32m     90\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmergeable_ranks\u001b[39m\u001b[33m\"\u001b[39m: mergeable_ranks,\n\u001b[32m     91\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mspecial_tokens\u001b[39m\u001b[33m\"\u001b[39m: special_tokens,\n\u001b[32m     92\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/tiktoken/load.py:158\u001b[39m, in \u001b[36mload_tiktoken_bpe\u001b[39m\u001b[34m(tiktoken_bpe_file, expected_hash)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_tiktoken_bpe\u001b[39m(tiktoken_bpe_file: \u001b[38;5;28mstr\u001b[39m, expected_hash: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# NB: do not add caching to this function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     contents = \u001b[43mread_file_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiktoken_bpe_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hash\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     ret = {}\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m contents.splitlines():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/tiktoken/load.py:63\u001b[39m, in \u001b[36mread_file_cached\u001b[39m\u001b[34m(blobpath, expected_hash)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m contents = \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblobpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expected_hash \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_hash(contents, expected_hash):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     66\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHash mismatch for data downloaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblobpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis may indicate a corrupted download. Please try again.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/tiktoken/load.py:22\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(blobpath)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# avoiding blobfile for public files helps avoid auth issues, like MFA prompts.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblobpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m resp.raise_for_status()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    703\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7feb6b4152b0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -2] Name or service not known)\"))"
     ]
    }
   ],
   "source": [
    "\n",
    "# start = 0\n",
    "# end = 0\n",
    "\n",
    "# Consider limits of thew official page aaaa (All embbedings are equal) \n",
    "# text-embedding-3-small\n",
    "# Rate limits\n",
    "# - Tokens per minute (TPM): 40,000\n",
    "# - Requests per minute (RPM): 100\n",
    "# - Requests per day (RPD): 2,000\n",
    "\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8191 \n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "\n",
    "TESTING = False\n",
    "\n",
    "\n",
    "# CONFIGURATIONS\n",
    "# https://platform.openai.com/docs/guides/batch#rate-limits\n",
    "TPM = 40000\n",
    "RPM = 100\n",
    "RPD = 2000\n",
    "limit_size = 190 # In MB\n",
    "# limit_request_in_file_batch = 50000\n",
    "limit_request_in_file_batch = 15000 # Segun mi regla de 3 simple [900-3MB]\n",
    "chunksize = 100 # For simplicity a multiple of limit_request_in_file_batch \n",
    "chunk_id = 0\n",
    "\n",
    "\n",
    "if TESTING:\n",
    "    limit_request_in_file_batch = 900\n",
    "    # limit_size = 0.5\n",
    "    second = False\n",
    "END = False\n",
    "\n",
    "path_embbedings = \"../../../../data/gpt/embeddings\"\n",
    "# path_errors = \"../../../../data/gpt/embeddings_errors\"\n",
    "\n",
    "os.makedirs(path_embbedings, exist_ok=True)\n",
    "# os.makedirs(path_errors, exist_ok=True)\n",
    "\n",
    "it_n = 0\n",
    "start = 46805\n",
    "end = None\n",
    "songs_RAM  = []  \n",
    "songs_passed_limit = []\n",
    "for chunk in pd.read_csv(path_df, chunksize=chunksize):\n",
    "    texts = chunk['text'].fillna(\"\")\n",
    "    for idx, song in enumerate(texts, start=chunk_id * chunksize ):\n",
    "        if idx < start:\n",
    "            continue\n",
    "        if idx%1800==0:\n",
    "            print(\"Procesando la canci칩n: \", idx)\n",
    "        song = limpiar_letras(song)\n",
    "        end = idx # Solo si se procesra sera este end\n",
    "        if(num_tokens_from_string(song) > max_tokens):\n",
    "            print(f\"La canci칩n {idx} excede el l칤mite de tokens ({num_tokens_from_string(song)} tokens). Se omitir치.\")\n",
    "            songs_passed_limit.append(idx)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if get_jsons_size(songs_RAM) > limit_size or len(songs_RAM) >= limit_request_in_file_batch:\n",
    "                end = idx-1 # Si no se procesa es el anterior\n",
    "                it_n+=1\n",
    "                print(\"Size en RAM: \", get_jsons_size(songs_RAM))\n",
    "                # Limpiar songs RAM y guardarlo \n",
    "                if get_jsons_size(songs_RAM) > limit_size:\n",
    "                    print(\"Song in RAM esta lleno\")\n",
    "                \n",
    "                # Realizamos el guardado del file\n",
    "                saved_in = guardar_jsons(songs_RAM, start, end, output_dir=path_embbedings)\n",
    "                print(\"Tama침o real al guardar:\",get_file_size(saved_in) )\n",
    "                print(f\"Archivo guardado en {saved_in}\")\n",
    "                \n",
    "                \n",
    "                # ---Inicio de los paso de gpt ----\n",
    "                # 1) upload_batch_file_to_openai\n",
    "                batch_input_file = upload_batch_file_to_openai(saved_in, API_KEY)\n",
    "                print(\"Archivo subido con 칠xito:\", batch_input_file.id) # file ID\n",
    "                # 2) Create the batch \n",
    "                response = create_openai_batch(batch_input_file, endpoint=\"/v1/embeddings\", completion_window=\"24h\", metadata=None, api_key=API_KEY)\n",
    "                print(response)\n",
    "                print(f\"Batch creado con ID: {response.id}\") # Batch ID\n",
    "\n",
    "                # Esto ya para mas despues\n",
    "                # 3) check status\n",
    "                # status_ = check_openai_batch(response.id, API_KEY)\n",
    "                \n",
    "                # print(f\"Estado del batch: {status_.status}\")\n",
    "                # Esperar a que el estado del batch sea completed\n",
    "                # if (check_openai_batch(response.id, API_KEY).status != \"completed\"):\n",
    "                #     time.sleep(600) # Dormir 10 minutos\n",
    "\n",
    "                if (check_openai_batch(response.id, API_KEY).status == \"completed\"):\n",
    "                    print(f\"Estado del batch completed\")\n",
    "                    output_file_id = check_openai_batch(response.id, API_KEY).output_file_id\n",
    "                    pta = download_results(output_file_id, API_KEY)\n",
    "                    saved_file = save_embeddings_only(pta,start,end)\n",
    "                    print(f\"File guardado en: {saved_file}\")\n",
    "                else:\n",
    "                    # Guardar start, end, asociado a batch_input_file.id y response.id\n",
    "                    print(\"Trankilo guardaremos lo necesario para obtener los embbedings\")\n",
    "                    save_batch_metadata(start, end, batch_input_file.id, response.id)\n",
    "\n",
    "                # ---Fin de los paso de gpt ----\n",
    "                print(\"Sleeping 1 minute\")\n",
    "                time.sleep(60) # Dormir 1 minuto porciacasito\n",
    "                songs_RAM = []\n",
    "                \n",
    "                start = end + 1\n",
    "                \n",
    "                # Falta guardar la cancion current \n",
    "                json_request = crear_single_json(song, idx)\n",
    "                songs_RAM.append(json_request)\n",
    "                    \n",
    "\n",
    "\n",
    "                # For testing\n",
    "                if TESTING and it_n == 2:\n",
    "                    END = True\n",
    "                    break\n",
    "            else:\n",
    "                # A침adir la cancion al json file\n",
    "                json_request = crear_single_json(song, idx)\n",
    "                songs_RAM.append(json_request)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la canci칩n {idx}: {e}\")\n",
    "\n",
    "    chunk_id+=1\n",
    "    \n",
    "    if END:\n",
    "        print(\"Termino el testing\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a532487",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = check_openai_batch(\"batch_68aea8e4452481909a37f98cefa35431\", API_KEY)\n",
    "print(status.status)\n",
    "print(\"Output file ID:\", output_file_id)\n",
    "\n",
    "if status.status == \"completed\":\n",
    "    print(\"Completed\")\n",
    "    output_file_id = status.output_file_id\n",
    "    print(\"Output file ID:\", output_file_id)\n",
    "    # print(\"Descargando resultados...\")\n",
    "    # pta = download_results(output_file_id, API_KEY)\n",
    "    # # saveResult(pta,0,2)\n",
    "    # save_embeddings_only(pta,0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fac675",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_embeddings_only(pta,0,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391eb9e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_path = \"../../../../data/gpt_responses/0_4_embeddings_only.jsonl\"\n",
    "# embeddings = load_embeddings_and_check_dim(file_path)\n",
    "\n",
    "# for embb in embeddings:\n",
    "#     print(embb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.97772,
   "end_time": "2025-08-27T08:40:00.911572",
   "environment_variables": {},
   "exception": true,
   "input_path": "generate_gptEmbb.ipynb",
   "output_path": "ejecutado_rn_20250827_033950.ipynb",
   "parameters": {},
   "start_time": "2025-08-27T08:39:50.933852",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}