{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b266e01b",
   "metadata": {},
   "source": [
    "A copy file to check the 91663 song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d22f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import json \n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "load_dotenv() \n",
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Check the satus \n",
    "def check_openai_batch(batch_id, api_key=None):\n",
    "    from openai import OpenAI\n",
    "\n",
    "    if api_key:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        client = OpenAI()\n",
    "\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    # print(batch)\n",
    "    return batch\n",
    "#5 Retreive or doload the results\n",
    "def download_results(batch_id, api_key=None):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    file_response = client.files.content(batch_id)\n",
    "    # print(file_response.text)\n",
    "    return file_response.text\n",
    "\n",
    "\n",
    "def save_embeddings_only(file_response_text,  start=0, end=0, output_path=\"../../../../data/gpt_responses\"):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file = f\"{output_path}/{start}_{end}_embeddings_only.jsonl\"\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in file_response_text.splitlines():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                j = json.loads(line)\n",
    "                custom_id = j[\"custom_id\"]\n",
    "                embedding = j[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "                # Guardar como JSON en una sola línea\n",
    "                f.write(json.dumps({\"custom_id\": custom_id, \"embedding\": embedding}, ensure_ascii=False) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando línea: {e}\")\n",
    "\n",
    "    print(f\"Embeddings guardados solo con custom_id en: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def get_first_number(filename):\n",
    "    match = re.search(r\"(\\d+)\", filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "def get_second_number(filename: str) -> int:\n",
    "    matches = re.findall(r\"(\\d+)\", filename)\n",
    "    if len(matches) >= 2:\n",
    "        return int(matches[1])  # el segundo número\n",
    "    return float('inf')  # si no lo encuentra\n",
    "\n",
    "def get_data(filepath: str) -> str:\n",
    "    \"\"\"Abre un archivo JSON y devuelve el batch_id si existe\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98017ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# gpt_responses_path = \"../../../../data/new_gpt/metadata_butches_files\"\n",
    "# data = get_data(os.path.join(gpt_responses_path, \"batch_metadata_96814_1068124.json\"))\n",
    "# status = check_openai_batch(data.get(\"batch_id\"), API_KEY)\n",
    "# if status.status == \"completed\":\n",
    "#     print(\"Completed\")\n",
    "# else : \n",
    "#     print(status.status)\n",
    "#     print(\"Aun sigue esperando we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedf3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_metadata_0_91663.json']\n",
      "batch_metadata_0_91663.json\n",
      "batch_metadata_0_91663.json .... Completed\n",
      "Ready para descargar\n"
     ]
    }
   ],
   "source": [
    "# Datapath of the GPT responses\n",
    "# gpt_responses_path = \"../../../../data/new_gpt/metadata_butches_files\"\n",
    "gpt_responses_path = \"../../../../data/new_gpt_np/metadata_butches_files\"\n",
    "files = os.listdir(gpt_responses_path)\n",
    "files_sorted = sorted(files, key=get_first_number)\n",
    "# print(files)\n",
    "print(files_sorted)\n",
    "all_completed = True\n",
    "# Save the result with custom id and embbeding\n",
    "for file_embb in files_sorted:\n",
    "    print(file_embb)\n",
    "    start = get_first_number(file_embb)\n",
    "    end = get_second_number(file_embb)\n",
    "    # Verficar end\n",
    "    data = get_data(os.path.join(gpt_responses_path, file_embb))\n",
    "    status = check_openai_batch(data.get(\"batch_id\"), API_KEY)\n",
    "    if status.status == \"completed\":\n",
    "        print(f\"{file_embb} .... Completed\")\n",
    "    else:\n",
    "        all_completed = False\n",
    "        break\n",
    "if all_completed:\n",
    "    print(\"Ready para descargar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df589a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All butches are completed, let's dowload with id to sorted them\n",
      "['batch_metadata_0_91663.json']\n",
      "batch_metadata_0_91663.json\n",
      "Completed\n",
      "Embeddings guardados solo con custom_id en: ../../../../data/new_gpt_np/embeddings_with_id/0_91663_embeddings_only.jsonl\n"
     ]
    }
   ],
   "source": [
    "if all_completed:\n",
    "    print(\"All butches are completed, let's dowload with id to sorted them\")\n",
    "    # Datapath of the GPT responses\n",
    "    gpt_responses_path = \"../../../../data/new_gpt_np/metadata_butches_files\"\n",
    "    path_de_descarga = \"../../../../data/new_gpt_np/embeddings_with_id\"\n",
    "    os.makedirs(path_de_descarga, exist_ok=True)\n",
    "    files = os.listdir(gpt_responses_path)\n",
    "    files_sorted = sorted(files, key=get_first_number)\n",
    "    # print(files)\n",
    "    print(files_sorted)\n",
    "\n",
    "    # Save the result with custom id and embbeding\n",
    "    for file_embb in files_sorted:\n",
    "        print(file_embb)\n",
    "        start = get_first_number(file_embb)\n",
    "        end = get_second_number(file_embb)\n",
    "        # Verficar end\n",
    "        data = get_data(os.path.join(gpt_responses_path, file_embb))\n",
    "        status = check_openai_batch(data.get(\"batch_id\"), API_KEY)\n",
    "        if status.status == \"completed\":\n",
    "            print(\"Completed\")\n",
    "            output_file_id = status.output_file_id\n",
    "            pta = download_results(output_file_id, API_KEY)\n",
    "            save_embeddings_only(pta, start=start, end=end, output_path=path_de_descarga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
