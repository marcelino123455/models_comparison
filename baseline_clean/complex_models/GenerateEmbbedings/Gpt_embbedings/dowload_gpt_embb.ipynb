{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d22f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import json \n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "load_dotenv() \n",
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Check the satus \n",
    "def check_openai_batch(batch_id, api_key=None):\n",
    "    from openai import OpenAI\n",
    "\n",
    "    if api_key:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        client = OpenAI()\n",
    "\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    # print(batch)\n",
    "    return batch\n",
    "#5 Retreive or doload the results\n",
    "def download_results(batch_id, api_key=None):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    file_response = client.files.content(batch_id)\n",
    "    # print(file_response.text)\n",
    "    return file_response.text\n",
    "\n",
    "\n",
    "def save_embeddings_only(file_response_text,  start=0, end=0, output_path=\"../../../../data/gpt_responses\"):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file = f\"{output_path}/{start}_{end}_embeddings_only.jsonl\"\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in file_response_text.splitlines():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                j = json.loads(line)\n",
    "                custom_id = j[\"custom_id\"]\n",
    "                embedding = j[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "                # Guardar como JSON en una sola línea\n",
    "                f.write(json.dumps({\"custom_id\": custom_id, \"embedding\": embedding}, ensure_ascii=False) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando línea: {e}\")\n",
    "\n",
    "    print(f\"Embeddings guardados solo con custom_id en: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def get_first_number(filename):\n",
    "    match = re.search(r\"(\\d+)\", filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "def get_second_number(filename: str) -> int:\n",
    "    matches = re.findall(r\"(\\d+)\", filename)\n",
    "    if len(matches) >= 2:\n",
    "        return int(matches[1])  # el segundo número\n",
    "    return float('inf')  # si no lo encuentra\n",
    "\n",
    "def get_data(filepath: str) -> str:\n",
    "    \"\"\"Abre un archivo JSON y devuelve el batch_id si existe\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98017ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "gpt_responses_path = \"../../../../data/gpt_to_check\"\n",
    "data = get_data(os.path.join(gpt_responses_path, \"batch_metadata_96814_1068124.json\"))\n",
    "status = check_openai_batch(data.get(\"batch_id\"), API_KEY)\n",
    "if status.status == \"completed\":\n",
    "    print(\"Completed\")\n",
    "else : \n",
    "    print(status.status)\n",
    "    print(\"Aun sigue esperando we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df589a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_metadata_0_899.json', 'batch_metadata_900_1799.json', 'batch_metadata_1800_16801.json', 'batch_metadata_16802_31802.json', 'batch_metadata_31803_46804.json', 'batch_metadata_46805_61809.json', 'batch_metadata_61810_76811.json', 'batch_metadata_76812_91811.json', 'batch_metadata_91812_106812.json', 'batch_metadata_96814_1068124.json', 'batch_metadata_106813_108137.json']\n",
      "batch_metadata_0_899.json\n",
      "batch_metadata_900_1799.json\n",
      "batch_metadata_1800_16801.json\n",
      "batch_metadata_16802_31802.json\n",
      "batch_metadata_31803_46804.json\n",
      "batch_metadata_46805_61809.json\n",
      "batch_metadata_61810_76811.json\n",
      "batch_metadata_76812_91811.json\n",
      "batch_metadata_91812_106812.json\n",
      "batch_metadata_96814_1068124.json\n",
      "Completed\n",
      "Embeddings guardados solo con custom_id en: ../../../../data/embeddings_only/96814_1068124_embeddings_only.jsonl\n",
      "batch_metadata_106813_108137.json\n"
     ]
    }
   ],
   "source": [
    "# Datapath of the GPT responses\n",
    "gpt_responses_path = \"../../../../data/gpt_to_check\"\n",
    "files = os.listdir(gpt_responses_path)\n",
    "files_sorted = sorted(files, key=get_first_number)\n",
    "# print(files)\n",
    "print(files_sorted)\n",
    "\n",
    "# Save the result with custom id and embbeding\n",
    "for file_embb in files_sorted:\n",
    "    print(file_embb)\n",
    "    start = get_first_number(file_embb)\n",
    "    end = get_second_number(file_embb)\n",
    "    if start!=96814:\n",
    "        continue\n",
    "    # Verficar end\n",
    "    data = get_data(os.path.join(gpt_responses_path, file_embb))\n",
    "    status = check_openai_batch(data.get(\"batch_id\"), API_KEY)\n",
    "    if status.status == \"completed\":\n",
    "        print(\"Completed\")\n",
    "        output_file_id = status.output_file_id\n",
    "        pta = download_results(output_file_id, API_KEY)\n",
    "        save_embeddings_only(pta, start=start, end=end, output_path=\"../../../../data/embeddings_only\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
